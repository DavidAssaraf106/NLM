{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FeedForwardNN import Feedforward\n",
    "from Toy_Datasets import two_clusters_gaussian\n",
    "from Neural_Network import NLM\n",
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "import matplotlib.pyplot as plt\n",
    "from autograd.misc.optimizers import adam\n",
    "from Bayesian_pdf import get_log_prior, get_log_likelihood\n",
    "from Hamiltonian_MC import hmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_clusters_gaussian(params, n_samples, test_points=None):\n",
    "    \"\"\"\n",
    "    :param params: should be a list of length K, K being the number of classes you wish to create\n",
    "    for every class 0 <= k <=K-1, params[k] should be a dictionnary containing two keys: mean and covariance_matrix.\n",
    "    The shapes expected for mean are D and covariance_matrix are D*D where D is the number of features for every\n",
    "    datapoint.\n",
    "    :param n_samples: number of samples you wish to create for every cluster\n",
    "    :param test_points: OOD points\n",
    "    :return: x of len(K*n_samples, n_features) and y of shape (K*n_samples). For both x and y, the features pertain\n",
    "    sequentially to every class 0 <= k <= K-1\n",
    "    \"\"\"\n",
    "    if params:\n",
    "        if isinstance(params, list):  # params is a list\n",
    "            K = len(params)\n",
    "        else:  # params is a numpy array\n",
    "            K = params.shape[0]\t\n",
    "        x = np.array([0, 0])\n",
    "        for k, param in enumerate(params):\n",
    "            param_k = params[k]\n",
    "            try:\n",
    "                mean_k, cov_k = param_k['mean'], param_k['covariance_matrix']\n",
    "            except KeyError:\n",
    "                raise KeyError('The parameters for class ' + str(k) + 'are not in the right dictionnary format. Please use mean and covariance_matrix')\n",
    "            assert len(mean_k) == cov_k.shape[0] == cov_k.shape[1], 'Wrong shapes for the parameters of class ' + str(k)\n",
    "            samples_class_k = np.random.multivariate_normal(mean_k, cov_k, n_samples)\n",
    "            x = np.vstack((x, samples_class_k))\n",
    "        y = np.array([[k] * n_samples for k in range(K)])\n",
    "        return x[1:, :], np.array(y).flatten()\n",
    "    else:\n",
    "        raise BaseException().args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(x, y, models, ax, poly_degree=1, test_points=None, shaded=True):\n",
    "    '''\n",
    "    plot_decision_boundary plots the training data and the decision boundary of the classifier.\n",
    "    input:\n",
    "       x - a numpy array of size N x 2, each row is a patient, each column is a biomarker\n",
    "       y - a numpy array of length N, each entry is either 0 (no cancer) or 1 (cancerous)\n",
    "       models - an array of classification models\n",
    "       ax - axis to plot on\n",
    "       poly_degree - the degree of polynomial features used to fit the model\n",
    "       test_points - test data\n",
    "       shaded - whether or not the two sides of the decision boundary are shaded\n",
    "    returns: \n",
    "       ax - the axis with the scatter plot\n",
    "\n",
    "    '''\n",
    "    # Plot data\n",
    "    ax.scatter(x[y == 1, 0], x[y == 1, 1], alpha=0.2, c='red', label='class 1')\n",
    "    ax.scatter(x[y == 0, 0], x[y == 0, 1], alpha=0.2, c='blue', label='class 0')\n",
    "    ax.scatter(x[y == 2, 0], x[y == 2, 1], alpha=0.2, color='green', label='class 2')\n",
    "\n",
    "\n",
    "    # Create mesh\n",
    "    interval = np.arange(-5, 5, 0.1)\n",
    "    n = np.size(interval)\n",
    "    print(n)\n",
    "    x1, x2 = np.meshgrid(interval, interval)\n",
    "    x1 = x1.reshape(-1, 1)\n",
    "    x2 = x2.reshape(-1, 1)\n",
    "    xx = np.concatenate((x1, x2), axis=1)\n",
    "\n",
    "    # Predict on mesh points\n",
    "    if(poly_degree > 1):\n",
    "        polynomial_features = PolynomialFeatures(degree=poly_degree, include_bias=True)\n",
    "        xx = polynomial_features.fit_transform(xx)\n",
    "\n",
    "    if len(models) > 1:\n",
    "        alpha_line = 0.1\n",
    "        linewidths=0.1\n",
    "    else:\n",
    "        alpha_line = 0.8\n",
    "        linewidths=0.5\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for model in models:\n",
    "        yy = model.predict(xx)  \n",
    "        yy = yy.reshape((n, n))\n",
    "\n",
    "        # Plot decision surface\n",
    "        x1 = x1.reshape(n, n)\n",
    "        x2 = x2.reshape(n, n)\n",
    "        if shaded:\n",
    "            ax.contourf(x1, x2, yy, alpha=0.1 * 1. / (i + 1)**2, cmap='bwr')\n",
    "        ax.contour(x1, x2, yy, colors='black', linewidths=linewidths, alpha=alpha_line)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    if test_points is not None:\n",
    "        for i in range(len(test_points)):\n",
    "            pt = test_points[i]\n",
    "            if i == 0:\n",
    "                ax.scatter(pt[0], pt[1], alpha=1., s=50, color='black', label='test data')\n",
    "            else:\n",
    "                ax.scatter(pt[0], pt[1], alpha=1., s=50, color='black')\n",
    "\n",
    "    ax.set_xlim((-5.5, 5.5))\n",
    "    ax.set_ylim((-5.5, 5.5))\n",
    "    ax.set_xlabel('x_1')\n",
    "    ax.set_ylabel('x_2')\n",
    "    ax.legend(loc='best')\n",
    "    return ax\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class Bayesian_logistic_regression:\n",
    "    def __init__(self, intercept, slopes):\n",
    "        self.intercept = intercept\n",
    "        self.slopes = slopes\n",
    "\n",
    "    def predict(self, x):\n",
    "        print(x.shape)\n",
    "        print(self.slopes.shape)\n",
    "        #y = sigmoid((x.reshape(-1,20)).dot(self.slopes) + self.intercept)\n",
    "        y = sigmoid((x).dot(self.slopes) + self.intercept)\n",
    "        return (y > 0.5).astype(np.int_)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        return sigmoid(x.dot(self.slopes) + self.intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "params_1 = {'mean': [2, 2], 'covariance_matrix': 0.5*np.eye(2)}\n",
    "params_2 = {'mean': [-2, -2], 'covariance_matrix': 0.5 * np.eye(2)}\n",
    "params_3 = {'mean': [0, 0], 'covariance_matrix': 0.5 * np.eye(2)}\n",
    "params = [params_1, params_2,params_3]\n",
    "x, y = two_clusters_gaussian(params, 200)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "ax.scatter(x[y == 0, 0], x[y == 0, 1], alpha=0.3, color='blue', label='class 0')\n",
    "ax.scatter(x[y == 1, 0], x[y == 1, 1], alpha=0.3, color='red', label='class 1')\n",
    "ax.scatter(x[y == 2, 0], x[y == 2, 1], alpha=0.3, color='green', label='class 2')\n",
    "\n",
    "ax.set_xlabel('x_1')\n",
    "ax.set_ylabel('x_2')\n",
    "ax.set_title('toy classification data')\n",
    "ax.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test BNN\n",
    "* 3 classes\n",
    "* output dim =1\n",
    "* 2000 samples, step size 1e-2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "###relu activation\n",
    "activation_fn_type = 'relu'\n",
    "activation_fn = lambda x: np.maximum(np.zeros(x.shape), x)\n",
    "\n",
    "\n",
    "###neural network model design choices\n",
    "width = 5\n",
    "hidden_layers = 1\n",
    "input_dim = 2\n",
    "output_dim = 1\n",
    "\n",
    "architecture = {'width': width,\n",
    "               'hidden_layers': hidden_layers,\n",
    "               'input_dim': input_dim,\n",
    "               'output_dim': output_dim,\n",
    "               'activation_fn_type': 'relu',\n",
    "               'activation_fn_params': 'rate=1',\n",
    "               'activation_fn': activation_fn}\n",
    "\n",
    "#set random state to make the experiments replicable\n",
    "rand_state = 0\n",
    "random = np.random.RandomState(rand_state)\n",
    "\n",
    "#instantiate a Feedforward neural network object\n",
    "nn = Feedforward(architecture, random=random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 lower bound [2878.58142705]; gradient mag: 1792.341722249051\n",
      "Iteration 100 lower bound [2345.53392195]; gradient mag: 1652.732104526413\n",
      "Iteration 200 lower bound [1837.72600291]; gradient mag: 1535.9597845965454\n",
      "Iteration 300 lower bound [1381.67497463]; gradient mag: 1268.5559520992047\n",
      "Iteration 400 lower bound [1063.0000556]; gradient mag: 854.6612670635143\n",
      "Iteration 500 lower bound [833.91835352]; gradient mag: 705.18438901048\n",
      "Iteration 600 lower bound [562.67301339]; gradient mag: 767.588951598304\n",
      "Iteration 700 lower bound [227.77019326]; gradient mag: 831.5919232076081\n",
      "Iteration 800 lower bound [-61.74577746]; gradient mag: 770.1890785272813\n",
      "Iteration 900 lower bound [-275.66181284]; gradient mag: 688.2818670636366\n",
      "Iteration 1000 lower bound [-446.58983265]; gradient mag: 648.1653759215062\n",
      "Iteration 1100 lower bound [-602.87025054]; gradient mag: 642.1251258295978\n",
      "Iteration 1200 lower bound [-759.02700536]; gradient mag: 655.579822186196\n",
      "Iteration 1300 lower bound [-922.96839479]; gradient mag: 683.7721185115665\n",
      "Iteration 1400 lower bound [-1101.19989085]; gradient mag: 720.8295093173699\n",
      "Iteration 1500 lower bound [-1296.47214063]; gradient mag: 763.0435347902245\n",
      "Iteration 1600 lower bound [-1511.0080628]; gradient mag: 809.8650874868023\n",
      "Iteration 1700 lower bound [-1745.98445449]; gradient mag: 859.0731939688154\n",
      "Iteration 1800 lower bound [-2002.02744587]; gradient mag: 910.5037693053224\n",
      "Iteration 1900 lower bound [-2278.37080147]; gradient mag: 964.0951933515565\n",
      "Iteration 2000 lower bound [-2575.31038982]; gradient mag: 1019.3869785028181\n",
      "Iteration 2100 lower bound [-2892.46449573]; gradient mag: 1074.882887203103\n",
      "Iteration 2200 lower bound [-3229.6494452]; gradient mag: 1131.0188257911695\n",
      "Iteration 2300 lower bound [-3585.52268747]; gradient mag: 1188.5322382755196\n",
      "Iteration 2400 lower bound [-3959.2688707]; gradient mag: 1246.4615169255635\n",
      "Iteration 2500 lower bound [-4350.28572543]; gradient mag: 1304.586041601217\n",
      "Iteration 2600 lower bound [-4753.66258495]; gradient mag: 1331.9208824846226\n",
      "Iteration 2700 lower bound [-5130.98039343]; gradient mag: 1294.5796518648988\n",
      "Iteration 2800 lower bound [-5445.97685634]; gradient mag: 1166.1269314422595\n",
      "Iteration 2900 lower bound [-5712.34995412]; gradient mag: 1040.5527912668244\n",
      "Iteration 3000 lower bound [-5925.86537186]; gradient mag: 896.463561383396\n",
      "Iteration 3100 lower bound [-6097.52712974]; gradient mag: 763.6842063113448\n",
      "Iteration 3200 lower bound [-6224.82218705]; gradient mag: 639.3445610629186\n",
      "Iteration 3300 lower bound [-6314.83644601]; gradient mag: 475.2436415203741\n",
      "Iteration 3400 lower bound [-6373.43183979]; gradient mag: 372.62847059432795\n",
      "Iteration 3500 lower bound [-6418.04679926]; gradient mag: 298.5320828023367\n",
      "Iteration 3600 lower bound [-6453.62918234]; gradient mag: 242.45966073616145\n",
      "Iteration 3700 lower bound [-6479.05951737]; gradient mag: 191.01932014170268\n",
      "Iteration 3800 lower bound [-6502.22202507]; gradient mag: 174.1810072720403\n",
      "Iteration 3900 lower bound [-6521.41380494]; gradient mag: 133.8628070225874\n",
      "Iteration 4000 lower bound [-6537.64757853]; gradient mag: 124.01702362662812\n",
      "Iteration 4100 lower bound [-6552.26172771]; gradient mag: 118.24192857459587\n",
      "Iteration 4200 lower bound [-6564.91747423]; gradient mag: 101.38359177047664\n",
      "Iteration 4300 lower bound [-6574.73694339]; gradient mag: 90.03595908893382\n",
      "Iteration 4400 lower bound [-6583.71243895]; gradient mag: 84.38516555072823\n",
      "Iteration 4500 lower bound [-6591.77029945]; gradient mag: 80.39623273541734\n",
      "Iteration 4600 lower bound [-6598.78075736]; gradient mag: 67.99710816001013\n",
      "Iteration 4700 lower bound [-6604.62823147]; gradient mag: 56.357706936007936\n",
      "Iteration 4800 lower bound [-6609.33900545]; gradient mag: 56.008139153379524\n",
      "Iteration 4900 lower bound [-6613.22244378]; gradient mag: 38.28230128844178\n",
      "Iteration 5000 lower bound [-6616.35495273]; gradient mag: 38.40122161467306\n",
      "Iteration 5100 lower bound [-6619.02620751]; gradient mag: 33.97043697037226\n",
      "Iteration 5200 lower bound [-6621.33290165]; gradient mag: 33.75389097682903\n",
      "Iteration 5300 lower bound [-6623.58651715]; gradient mag: 27.842384621558445\n",
      "Iteration 5400 lower bound [-6625.45470322]; gradient mag: 27.81010090740227\n",
      "Iteration 5500 lower bound [-6627.3503229]; gradient mag: 28.240163884738312\n",
      "Iteration 5600 lower bound [-6629.25620848]; gradient mag: 28.682321085175357\n",
      "Iteration 5700 lower bound [-6631.21026397]; gradient mag: 28.68371226233911\n",
      "Iteration 5800 lower bound [-6633.38314889]; gradient mag: 29.396436917061052\n",
      "Iteration 5900 lower bound [-6635.15913706]; gradient mag: 23.01978003404088\n",
      "Iteration 6000 lower bound [-6636.87118107]; gradient mag: 29.85416889457314\n",
      "Iteration 6100 lower bound [-6638.72569129]; gradient mag: 19.264774252267664\n",
      "Iteration 6200 lower bound [-6640.17994034]; gradient mag: 17.22799432067721\n",
      "Iteration 6300 lower bound [-6641.45005499]; gradient mag: 15.312234405175493\n",
      "Iteration 6400 lower bound [-6642.18409332]; gradient mag: 25.341024411876198\n",
      "Iteration 6500 lower bound [-6643.33759125]; gradient mag: 18.89187101424539\n",
      "Iteration 6600 lower bound [-6644.57242661]; gradient mag: 19.154594179386986\n",
      "Iteration 6700 lower bound [-6645.80342882]; gradient mag: 14.917521231747383\n",
      "Iteration 6800 lower bound [-6647.47586889]; gradient mag: 19.899599818322287\n",
      "Iteration 6900 lower bound [-6649.19719254]; gradient mag: 14.064831925737108\n",
      "Iteration 7000 lower bound [-6650.15941572]; gradient mag: 20.37709744092624\n",
      "Iteration 7100 lower bound [-6651.34386239]; gradient mag: 14.313961606349626\n",
      "Iteration 7200 lower bound [-6652.41228075]; gradient mag: 9.436686201766092\n",
      "Iteration 7300 lower bound [-6653.03625229]; gradient mag: 11.466908666040029\n",
      "Iteration 7400 lower bound [-6654.76195023]; gradient mag: 10.578837600359064\n",
      "Iteration 7500 lower bound [-6656.15576032]; gradient mag: 10.69375902275633\n",
      "Iteration 7600 lower bound [-6657.33537113]; gradient mag: 10.523438910035035\n",
      "Iteration 7700 lower bound [-6658.71006808]; gradient mag: 10.168112103967756\n",
      "Iteration 7800 lower bound [-6659.81048268]; gradient mag: 10.23496385631739\n",
      "Iteration 7900 lower bound [-6661.75868525]; gradient mag: 15.675145596920157\n",
      "Iteration 8000 lower bound [-6663.71077377]; gradient mag: 15.840123867892771\n",
      "Iteration 8100 lower bound [-6665.64204045]; gradient mag: 15.558213530753513\n",
      "Iteration 8200 lower bound [-6667.63587923]; gradient mag: 15.645080576843924\n",
      "Iteration 8300 lower bound [-6669.71768278]; gradient mag: 13.584276910673776\n",
      "Iteration 8400 lower bound [-6671.23666254]; gradient mag: 10.34867263941852\n",
      "Iteration 8500 lower bound [-6672.45956253]; gradient mag: 10.562558898363969\n",
      "Iteration 8600 lower bound [-6673.7246546]; gradient mag: 10.657600314809788\n",
      "Iteration 8700 lower bound [-6675.05115963]; gradient mag: 13.367893472863255\n",
      "Iteration 8800 lower bound [-6676.44588277]; gradient mag: 13.449942833353873\n",
      "Iteration 8900 lower bound [-6677.91470968]; gradient mag: 13.548961263284799\n",
      "Iteration 9000 lower bound [-6680.74246851]; gradient mag: 11.757252097545223\n",
      "Iteration 9100 lower bound [-6683.46627885]; gradient mag: 12.773923348980173\n",
      "Iteration 9200 lower bound [-6686.26380396]; gradient mag: 14.814209928204876\n",
      "Iteration 9300 lower bound [-6688.87908549]; gradient mag: 14.450318544355715\n",
      "Iteration 9400 lower bound [-6691.26049509]; gradient mag: 15.288426223450521\n",
      "Iteration 9500 lower bound [-6693.34415275]; gradient mag: 14.008560868915291\n",
      "Iteration 9600 lower bound [-6695.53128588]; gradient mag: 15.571585205924467\n",
      "Iteration 9700 lower bound [-6696.86896587]; gradient mag: 8.722717913441878\n",
      "Iteration 9800 lower bound [-6697.99697792]; gradient mag: 8.849670390215103\n",
      "Iteration 9900 lower bound [-6699.09954888]; gradient mag: 11.718707512881263\n",
      "Iteration 10000 lower bound [-6700.24853469]; gradient mag: 10.513462384330122\n",
      "Iteration 10100 lower bound [-6701.44538874]; gradient mag: 10.597432199892262\n",
      "Iteration 10200 lower bound [-6702.69942535]; gradient mag: 9.74036893979737\n",
      "Iteration 10300 lower bound [-6704.02689712]; gradient mag: 11.720534518877821\n",
      "Iteration 10400 lower bound [-6705.35870822]; gradient mag: 12.087139561637743\n",
      "Iteration 10500 lower bound [-6706.70583097]; gradient mag: 11.459005676908378\n",
      "Iteration 10600 lower bound [-6707.99640441]; gradient mag: 10.559361720035374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10700 lower bound [-6709.11139537]; gradient mag: 10.606838862161787\n",
      "Iteration 10800 lower bound [-6710.46125256]; gradient mag: 28.326370801734583\n",
      "Iteration 10900 lower bound [-6711.37106792]; gradient mag: 13.957284039450316\n",
      "Iteration 11000 lower bound [-6712.25684582]; gradient mag: 13.67816309301631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaelancel/anaconda3/lib/python3.5/site-packages/autograd/numpy/numpy_vjps.py:53: RuntimeWarning: overflow encountered in square\n",
      "  lambda ans, x, y : unbroadcast_f(y, lambda g: - g * x / y**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11100 lower bound [-6713.21912724]; gradient mag: 15.80625790952774\n",
      "Iteration 11200 lower bound [-6714.07401444]; gradient mag: 16.292140609832927\n",
      "Iteration 11300 lower bound [-6715.09396662]; gradient mag: 28.47643623964849\n",
      "Iteration 11400 lower bound [-6715.86613733]; gradient mag: 20.712023358012985\n",
      "Iteration 11500 lower bound [-6716.55540958]; gradient mag: 6.201623652005573\n",
      "Iteration 11600 lower bound [-6717.28796723]; gradient mag: 16.54093248252807\n",
      "Iteration 11700 lower bound [-6717.80374243]; gradient mag: 11.881393568452731\n",
      "Iteration 11800 lower bound [-6718.503306]; gradient mag: 13.3280618488312\n",
      "Iteration 11900 lower bound [-6719.05042741]; gradient mag: 13.779563671296282\n",
      "Iteration 12000 lower bound [-6719.52733969]; gradient mag: 10.142055342250552\n",
      "Iteration 12100 lower bound [-6720.11347525]; gradient mag: 10.4802123012541\n",
      "Iteration 12200 lower bound [-6720.74752152]; gradient mag: 12.44467179374495\n",
      "Iteration 12300 lower bound [-6721.27188932]; gradient mag: 11.31795260608155\n",
      "Iteration 12400 lower bound [-6721.65279152]; gradient mag: 12.452443171519475\n",
      "Iteration 12500 lower bound [-6722.21724372]; gradient mag: 13.672325655670862\n",
      "Iteration 12600 lower bound [-6722.66206275]; gradient mag: 9.79693114796591\n",
      "Iteration 12700 lower bound [-6723.09768326]; gradient mag: 9.604878454126988\n",
      "Iteration 12800 lower bound [-6723.43401945]; gradient mag: 16.517669410682323\n",
      "Iteration 12900 lower bound [-6724.05260195]; gradient mag: 25.708837444986525\n",
      "Iteration 13000 lower bound [-6724.37061061]; gradient mag: 16.35878753602045\n",
      "Iteration 13100 lower bound [-6724.68958575]; gradient mag: 17.372668614435526\n",
      "Iteration 13200 lower bound [-6725.13737041]; gradient mag: 18.71040725509645\n",
      "Iteration 13300 lower bound [-6725.5635323]; gradient mag: 19.224471905773616\n",
      "Iteration 13400 lower bound [-6726.04525853]; gradient mag: 11.986152570025624\n",
      "Iteration 13500 lower bound [-6726.40758392]; gradient mag: 19.87949542202715\n",
      "Iteration 13600 lower bound [-6726.81211863]; gradient mag: 19.660536367731915\n",
      "Iteration 13700 lower bound [-6727.21540944]; gradient mag: 19.513498839080295\n",
      "Iteration 13800 lower bound [-6727.60659094]; gradient mag: 19.472605868483843\n",
      "Iteration 13900 lower bound [-6728.00095768]; gradient mag: 20.393241063480925\n",
      "Iteration 14000 lower bound [-6728.34708949]; gradient mag: 19.9686772060465\n",
      "Iteration 14100 lower bound [-6728.7693316]; gradient mag: 7.223760704823891\n",
      "Iteration 14200 lower bound [-6729.19293542]; gradient mag: 24.2986227437423\n",
      "Iteration 14300 lower bound [-6729.41826488]; gradient mag: 12.12228409052287\n",
      "Iteration 14400 lower bound [-6729.83488115]; gradient mag: 24.46491769780763\n",
      "Iteration 14500 lower bound [-6729.97965655]; gradient mag: 22.21382049467659\n",
      "Iteration 14600 lower bound [-6730.42215134]; gradient mag: 7.002062699530459\n",
      "Iteration 14700 lower bound [-6730.68299769]; gradient mag: 23.40808854340065\n",
      "Iteration 14800 lower bound [-6731.107812]; gradient mag: 10.135229476165495\n",
      "Iteration 14900 lower bound [-6731.35858714]; gradient mag: 22.919658804130506\n"
     ]
    }
   ],
   "source": [
    "###define design choices in gradient descent\n",
    "params = {'step_size':1e-3, \n",
    "          'max_iteration':15000, \n",
    "          'random_restarts':1}\n",
    "\n",
    "#fit my neural network to minimize MSE on the given data\n",
    "nn.fit(x.T, y.reshape(1,-1), params)\n",
    "#nn.fit(x.T, y.reshape(3,-1), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.71933538e-010, 9.10227913e-082, 2.96278218e-091,\n",
       "        2.55964933e-174, 1.07414765e-076, 4.00206113e-097,\n",
       "        1.41976838e-021, 1.00000000e+000, 3.27052385e-049,\n",
       "        9.92799291e-080, 3.80269484e-040, 5.63807066e-060,\n",
       "        4.15416060e-114, 1.53970185e-127, 7.95798543e-136,\n",
       "        1.76074853e-037, 4.37944870e-173, 9.47127570e-055,\n",
       "        6.79222699e-071, 1.54465344e-128, 1.51030456e-167,\n",
       "        4.26829466e-126, 2.48907921e-029, 1.54276083e-102,\n",
       "        6.54203122e-135, 1.57240765e-066, 1.15481781e-114,\n",
       "        4.21356480e-050, 2.21165271e-096, 1.30945028e-092,\n",
       "        4.42520306e-044, 1.74832946e-049, 1.88681836e-061,\n",
       "        2.07934134e-089, 2.82115022e-113, 4.25855819e-129,\n",
       "        8.30128796e-096, 1.12652314e-070, 1.51969942e-087,\n",
       "        2.73595580e-081, 3.73316323e-140, 1.30606994e-111,\n",
       "        1.37105717e-118, 3.51463065e-153, 3.36381151e-073,\n",
       "        2.24115465e-047, 3.47111907e-123, 1.66949131e-106,\n",
       "        3.96580904e-022, 9.16374285e-052, 6.47060599e-060,\n",
       "        3.19669857e-096, 1.37690190e-102, 2.10290165e-125,\n",
       "        1.64281837e-063, 1.31484818e-058, 1.85360625e-075,\n",
       "        8.85036712e-235, 3.55160656e-130, 7.00229419e-073,\n",
       "        2.97427725e-053, 1.03774088e-138, 7.62126256e-071,\n",
       "        2.12498984e-019, 4.10880970e-112, 1.09816700e-090,\n",
       "        5.73964833e-085, 8.35304845e-141, 9.25693457e-087,\n",
       "        2.15778587e-094, 5.71609260e-140, 1.10065702e-020,\n",
       "        7.85655063e-122, 6.10668904e-114, 2.39909219e-119,\n",
       "        2.48880685e-086, 1.48967447e-113, 1.19866096e-109,\n",
       "        1.36956287e-109, 5.06520358e-131, 1.35164824e-009,\n",
       "        2.89713881e-073, 2.45939138e-029, 6.74353314e-072,\n",
       "        2.12674708e-063, 3.81140209e-029, 1.55480984e-083,\n",
       "        1.88300794e-165, 4.02984741e-022, 4.99666946e-139,\n",
       "        4.09103411e-047, 1.13145187e-074, 2.05846667e-027,\n",
       "        1.04159455e-047, 4.43966805e-050, 3.49806120e-091,\n",
       "        2.25833731e-131, 8.39367251e-081, 1.56254555e-145,\n",
       "        1.03434798e-004, 3.01835794e-086, 2.22791186e-099,\n",
       "        1.95035712e-157, 1.95479446e-039, 2.00179433e-109,\n",
       "        2.51340987e-166, 7.63371347e-018, 9.23143904e-052,\n",
       "        7.27243019e-058, 5.78250596e-162, 1.91895533e-090,\n",
       "        3.47246230e-108, 5.21931194e-022, 6.73251542e-082,\n",
       "        4.01828132e-065, 1.09206376e-068, 1.04477795e-009,\n",
       "        2.07038727e-064, 9.21438988e-131, 1.29285700e-075,\n",
       "        2.85106420e-075, 3.84951753e-097, 3.46118588e-018,\n",
       "        2.50339813e-124, 2.84410771e-094, 2.43296135e-135,\n",
       "        4.42029726e-083, 1.92253679e-135, 1.64823832e-143,\n",
       "        7.30840475e-073, 8.60035769e-001, 5.09183413e-093,\n",
       "        1.35789517e-079, 2.21646289e-127, 5.78773830e-049,\n",
       "        1.77036407e-132, 2.85251023e-122, 2.82383764e-048,\n",
       "        1.80313096e-063, 2.69283162e-164, 1.18272502e-106,\n",
       "        7.02937126e-128, 9.99999862e-001, 8.38797013e-077,\n",
       "        9.35145816e-095, 7.54479695e-146, 2.02243603e-100,\n",
       "        2.60605796e-120, 6.89888800e-150, 2.00294264e-070,\n",
       "        1.07621640e-146, 1.95388077e-084, 2.50501097e-062,\n",
       "        4.50061412e-020, 8.78275717e-136, 2.35361816e-033,\n",
       "        8.03593403e-108, 2.21225885e-108, 8.01752603e-088,\n",
       "        2.07260156e-031, 2.45616839e-139, 3.90320532e-118,\n",
       "        8.76321562e-108, 1.22301503e-148, 3.48550377e-067,\n",
       "        8.29950896e-019, 2.46489317e-105, 7.89941162e-122,\n",
       "        9.77514002e-100, 2.97591689e-127, 1.36610963e-112,\n",
       "        3.37160574e-050, 3.67258633e-041, 1.00000000e+000,\n",
       "        3.89172501e-041, 1.67430403e-038, 4.20502577e-139,\n",
       "        4.92165551e-120, 1.79641079e-047, 1.00000000e+000,\n",
       "        9.95326368e-001, 7.85615365e-104, 8.36926168e-127,\n",
       "        1.99328041e-128, 2.23311188e-157, 3.22662658e-151,\n",
       "        4.59632615e-183, 9.76466464e-101, 3.39720261e-086,\n",
       "        4.42031279e-075, 1.34670076e-096, 6.49183146e-066,\n",
       "        1.92959760e-092, 3.53983437e-048, 7.35061013e-117,\n",
       "        5.63647425e-138, 1.74921337e-115, 9.01185206e-057,\n",
       "        4.09641659e-085, 2.83722475e-055],\n",
       "       [1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 9.82349783e-001, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 9.99999860e-001, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.forward(nn.weights,x.T).reshape(3,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_hmc={\n",
    "       'num_samples':2000,\n",
    "       'step_size':1e-2, \n",
    "       'L':20,\n",
    "       'init': nn.weights,\n",
    "       'burn':.1, \n",
    "       'thin':2,\n",
    "}\n",
    "\n",
    "\n",
    "def log_prior(W):\n",
    "    Sigma=25*np.eye(nn.D)\n",
    "    D_bayes=Sigma.shape[0]\n",
    "    Sigma_inv= np.linalg.inv(Sigma)\n",
    "    Sigma_det = np.linalg.det(Sigma)\n",
    "    constant_W = -0.5 * (D_bayes * np.log(2 * np.pi) + np.log(Sigma_det))\n",
    "    exponential_W = -0.5 * np.diag(np.dot(np.dot(W, Sigma_inv), W.T))\n",
    "    log_p_W = constant_W + exponential_W\n",
    "    return log_p_W\n",
    "\n",
    "def log_likelihood(W):\n",
    "    D_bayes=len(y.reshape((-1,1)))\n",
    "    sigma_y=0.5\n",
    "    constant = (-np.log(sigma_y) - 0.5 * np.log(2 * np.pi)) * D_bayes\n",
    "    exponential = -0.5 * sigma_y**-2 * np.sum((y.reshape((1, 1, D_bayes)) - nn.forward(W, x.T))**2, axis=2).flatten()\n",
    "    return constant + exponential\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q=hmc(log_prior, log_likelihood, **params_hmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'q' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a0bae05ab21e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mq_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BNN posterior'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'q' is not defined"
     ]
    }
   ],
   "source": [
    "q_=np.asarray(q).T\n",
    "plt.plot(range(len(q_[-1])),q_[-1] , color='r')\n",
    "plt.title('BNN posterior')\n",
    "plt.show()\n",
    "print(nn.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decision boundary for the learned model\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "model=Bayesian_logistic_regression(nn.weights[0][-1],nn.weights[0][:-1])\n",
    "ax = plot_decision_boundary(x, y, [model], ax, poly_degree=1,  shaded=True)\n",
    "ax.set_xlabel('x_1')\n",
    "ax.set_ylabel('x_2')\n",
    "ax.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test BNN\n",
    "* 3 classes\n",
    "* output dim =3\n",
    "* 2000 samples, step size 1e-2m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feedforward:\n",
    "\n",
    "    def __init__(self, architecture, random=None, weights=None):\n",
    "        self.params = {'H': architecture['width'],\n",
    "                       'L': architecture['hidden_layers'],\n",
    "                       'D_in': architecture['input_dim'],\n",
    "                       'D_out': architecture['output_dim'],\n",
    "                       'activation_type': architecture['activation_fn_type'],\n",
    "                       'activation_params': architecture['activation_fn_params']}\n",
    "\n",
    "        self.D = ((architecture['input_dim'] * architecture['width'] + architecture['width'])\n",
    "                  + (architecture['output_dim'] * architecture['width'] + architecture['output_dim'])\n",
    "                  + (architecture['hidden_layers'] - 1) * (architecture['width'] ** 2 + architecture['width'])\n",
    "                  )  # in order: input, output, hidden. Take into account the biases\n",
    "\n",
    "        if random is not None:\n",
    "            self.random = random\n",
    "        else:\n",
    "            self.random = np.random.RandomState(0)\n",
    "\n",
    "        self.h = architecture['activation_fn']\n",
    "\n",
    "        if weights is None:\n",
    "            self.weights = self.random.normal(0, 1, size=(1, self.D))\n",
    "        else:\n",
    "            self.weights = weights\n",
    "\n",
    "        self.objective_trace = np.empty((1, 1))\n",
    "        self.weight_trace = np.empty((1, self.D))\n",
    "\n",
    "    def forward(self, weights, x):\n",
    "        \"\"\" Forward pass given weights and input \"\"\"\n",
    "        H = self.params['H']\n",
    "        D_in = self.params['D_in']\n",
    "        D_out = self.params['D_out']\n",
    "        assert weights.shape[1] == self.D\n",
    "\n",
    "        if len(x.shape) == 2:\n",
    "            assert x.shape[0] == D_in\n",
    "            x = x.reshape((1, D_in, -1))\n",
    "        else:\n",
    "            assert x.shape[1] == D_in\n",
    "\n",
    "        weights = weights.T\n",
    "\n",
    "        # input to first hidden layer\n",
    "        W = weights[:H * D_in].T.reshape((-1, H, D_in))\n",
    "        b = weights[H * D_in:H * D_in + H].T.reshape((-1, H, 1))\n",
    "        input = self.h(np.matmul(W, x) + b)\n",
    "        index = H * D_in + H\n",
    "\n",
    "        assert input.shape[1] == H\n",
    "\n",
    "        # additional hidden layers\n",
    "        for _ in range(self.params['L'] - 1):\n",
    "            before = index\n",
    "            W = weights[index:index + H * H].T.reshape((-1, H, H))\n",
    "            index += H * H\n",
    "            b = weights[index:index + H].T.reshape((-1, H, 1))\n",
    "            index += H\n",
    "            output = np.matmul(W, input) + b\n",
    "            input = self.h(output)\n",
    "\n",
    "            assert input.shape[1] == H\n",
    "\n",
    "        def sigmoid(y):\n",
    "            return 1/(1 + np.exp(-y))\n",
    "\n",
    "\n",
    "        # output layer\n",
    "        W = weights[index:index + H * D_out].T.reshape((-1, D_out, H))\n",
    "        b = weights[index + H * D_out:].T.reshape((-1, D_out, 1))\n",
    "        output = sigmoid(np.matmul(W, input) + b)  # review that for training\n",
    "        assert output.shape[1] == self.params['D_out']\n",
    "\n",
    "        return output\n",
    "\n",
    "    def make_objective(self, x_train, y_train, reg_param):\n",
    "\n",
    "        def objective(W, t):\n",
    "            sigmoid_probability = self.forward(W, x_train)\n",
    "            sigmoid_probability = np.clip(sigmoid_probability, 1e-15, 1 - 1e-15)\n",
    "            bce = np.dot(y_train, np.log(sigmoid_probability)) + np.dot((1 - y_train), np.log(1 - sigmoid_probability))\n",
    "            if reg_param is None:\n",
    "                sum_error = bce\n",
    "                return -sum_error\n",
    "            else:\n",
    "                mean_error = bce + reg_param * np.linalg.norm(W)\n",
    "                return -mean_error\n",
    "\n",
    "        return objective, grad(objective)\n",
    "\n",
    "    def fit(self, x_train, y_train, params, reg_param=None):\n",
    "\n",
    "        assert x_train.shape[0] == self.params['D_in']\n",
    "        assert y_train.shape[0] == self.params['D_out']\n",
    "\n",
    "        ### make objective function for training\n",
    "        self.objective, self.gradient = self.make_objective(x_train, y_train, reg_param)\n",
    "\n",
    "        ### set up optimization\n",
    "        step_size = 0.01\n",
    "        max_iteration = 5000\n",
    "        check_point = 100\n",
    "        weights_init = self.weights.reshape((1, -1))\n",
    "        mass = None\n",
    "        optimizer = 'adam'\n",
    "        random_restarts = 5\n",
    "\n",
    "        if 'step_size' in params.keys():\n",
    "            step_size = params['step_size']\n",
    "        if 'max_iteration' in params.keys():\n",
    "            max_iteration = params['max_iteration']\n",
    "        if 'check_point' in params.keys():\n",
    "            self.check_point = params['check_point']\n",
    "        if 'init' in params.keys():\n",
    "            weights_init = params['init']\n",
    "        if 'call_back' in params.keys():\n",
    "            call_back = params['call_back']\n",
    "        if 'mass' in params.keys():\n",
    "            mass = params['mass']\n",
    "        if 'optimizer' in params.keys():\n",
    "            optimizer = params['optimizer']\n",
    "        if 'random_restarts' in params.keys():\n",
    "            random_restarts = params['random_restarts']\n",
    "\n",
    "        def call_back(weights, iteration, g):\n",
    "            ''' Actions per optimization step '''\n",
    "            objective = self.objective(weights, iteration)\n",
    "            self.objective_trace = np.vstack((self.objective_trace, objective))\n",
    "            self.weight_trace = np.vstack((self.weight_trace, weights))\n",
    "            if iteration % check_point == 0:\n",
    "                print(\"Iteration {} lower bound {}; gradient mag: {}\".format(iteration, objective, np.linalg.norm(\n",
    "                    self.gradient(weights, iteration))))\n",
    "\n",
    "        ### train with random restarts\n",
    "        optimal_obj = 1e16\n",
    "        optimal_weights = self.weights\n",
    "\n",
    "        for i in range(random_restarts):\n",
    "            if optimizer == 'adam':\n",
    "                adam(self.gradient, weights_init, step_size=step_size, num_iters=max_iteration, callback=call_back)\n",
    "            local_opt = np.min(self.objective_trace[-100:])\n",
    "            if local_opt < optimal_obj:\n",
    "                opt_index = np.argmin(self.objective_trace[-100:])\n",
    "                self.weights = self.weight_trace[-100:][opt_index].reshape((1, -1))\n",
    "            weights_init = self.random.normal(0, 1, size=(1, self.D))\n",
    "\n",
    "        self.objective_trace = self.objective_trace[1:]\n",
    "        self.weight_trace = self.weight_trace[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hahahaahahahahahahahah\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (3,200) and (1,3,600) not aligned: 200 (dim 1) != 3 (dim 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-9b84ae21ad3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#fit my neural network to minimize MSE on the given data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mnn2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-8be860a3bb21>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x_train, y_train, params, reg_param)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_restarts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                 \u001b[0madam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcall_back\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0mlocal_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective_trace\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlocal_opt\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0moptimal_obj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/autograd/misc/optimizers.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(grad, x0, callback, *args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0m_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_x0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/autograd/misc/optimizers.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(grad, x, callback, num_iters, step_size, b1, b2, eps)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mg\u001b[0m      \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm\u001b[0m  \u001b[0;31m# First  moment estimate.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/autograd/misc/optimizers.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, i)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_optimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0m_x0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munflatten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0m_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0m_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/autograd/wrap_util.py\u001b[0m in \u001b[0;36mnary_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0munary_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munary_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnary_op_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnary_op_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnary_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnary_operator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/autograd/differential_operators.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0marguments\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbut\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0minstead\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     should be scalar-valued. The gradient has the same type as the argument.\"\"\"\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         raise TypeError(\"Grad only applies to real scalar-output functions. \"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/autograd/core.py\u001b[0m in \u001b[0;36mmake_vjp\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstart_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVJPNode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mend_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_node\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mend_node\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(start_node, fun, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mstart_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mend_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_box\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_box\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstart_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/autograd/wrap_util.py\u001b[0m in \u001b[0;36munary_f\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0msubargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubvals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msubargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-8be860a3bb21>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(W, t)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0msigmoid_probability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0msigmoid_probability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigmoid_probability\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1e-15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mbce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigmoid_probability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msigmoid_probability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreg_param\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0msum_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mf_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mparents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mboxed_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0margnums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m   \u001b[0;32min\u001b[0m \u001b[0mboxed_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_wrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mf_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_autograd_primitive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (3,200) and (1,3,600) not aligned: 200 (dim 1) != 3 (dim 1)"
     ]
    }
   ],
   "source": [
    "###define design choices in gradient descent\n",
    "params = {'step_size':1e-3, \n",
    "          'max_iteration':15000, \n",
    "          'random_restarts':1}\n",
    "\n",
    "#fit my neural network to minimize MSE on the given data\n",
    "nn2.fit(x.T, y.reshape(3,-1), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###relu activation\n",
    "activation_fn_type = 'relu'\n",
    "activation_fn = lambda x: np.maximum(np.zeros(x.shape), x)\n",
    "\n",
    "\n",
    "###neural network model design choices\n",
    "width = 5\n",
    "hidden_layers = 1\n",
    "input_dim = 2\n",
    "output_dim = 3\n",
    "\n",
    "architecture = {'width': width,\n",
    "               'hidden_layers': hidden_layers,\n",
    "               'input_dim': input_dim,\n",
    "               'output_dim': output_dim,\n",
    "               'activation_fn_type': 'relu',\n",
    "               'activation_fn_params': 'rate=1',\n",
    "               'activation_fn': activation_fn}\n",
    "\n",
    "#set random state to make the experiments replicable\n",
    "rand_state = 0\n",
    "random = np.random.RandomState(rand_state)\n",
    "\n",
    "#instantiate a Feedforward neural network object\n",
    "nn2 = Feedforward(architecture, random=random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###relu activation\n",
    "activation_fn_type = 'relu'\n",
    "activation_fn = lambda x: np.maximum(np.zeros(x.shape), x)\n",
    "\n",
    "\n",
    "###neural network model design choices\n",
    "width = 5\n",
    "hidden_layers = 2\n",
    "input_dim = 2\n",
    "output_dim = 1\n",
    "\n",
    "architecture = {'width': width,\n",
    "               'hidden_layers': hidden_layers,\n",
    "               'input_dim': input_dim,\n",
    "               'output_dim': output_dim,\n",
    "               'activation_fn_type': 'relu',\n",
    "               'activation_fn_params': 'rate=1',\n",
    "               'prior': 'normal',\n",
    "               'prior_parameters':{'mean': np.array([1, 2]), 'covariance_matrix': np.eye(2)},\n",
    "               'likelihood': 'logistic',\n",
    "               'activation_fn': activation_fn}\n",
    "\n",
    "#set random state to make the experiments replicable\n",
    "rand_state = 0\n",
    "random = np.random.RandomState(rand_state)\n",
    "\n",
    "#instantiate a Feedforward neural network object\n",
    "nlm = NLM(architecture, random=random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 lower bound [2662.72465524]; gradient mag: 2255.761937133721\n",
      "Iteration 100 lower bound [1875.89160598]; gradient mag: 1698.7555870456565\n",
      "Iteration 200 lower bound [1294.01985718]; gradient mag: 1355.8417235930126\n",
      "Iteration 300 lower bound [498.40467034]; gradient mag: 1529.9786258862232\n",
      "Iteration 400 lower bound [-480.3442266]; gradient mag: 1324.6055207362049\n",
      "Iteration 500 lower bound [-1136.50809845]; gradient mag: 1467.877789894719\n",
      "Iteration 600 lower bound [-1940.46823471]; gradient mag: 1846.7458721716405\n",
      "Iteration 700 lower bound [-3012.65336735]; gradient mag: 2334.204147896267\n",
      "Iteration 800 lower bound [-4451.39891415]; gradient mag: 2921.7155098116623\n",
      "Iteration 900 lower bound [-6027.11900655]; gradient mag: 2142.5903539403444\n",
      "Iteration 1000 lower bound [-6317.26504113]; gradient mag: 737.3300790836616\n",
      "Iteration 1100 lower bound [-6420.16454811]; gradient mag: 533.6439984977413\n",
      "Iteration 1200 lower bound [-6492.90736283]; gradient mag: 438.0913975348303\n",
      "Iteration 1300 lower bound [-6545.01261817]; gradient mag: 307.94014168409535\n",
      "Iteration 1400 lower bound [-6582.25421562]; gradient mag: 248.8565445526601\n",
      "Iteration 1500 lower bound [-6606.10322497]; gradient mag: 191.5491831430678\n",
      "Iteration 1600 lower bound [-6622.81771082]; gradient mag: 175.24113538961487\n",
      "Iteration 1700 lower bound [-6638.60297458]; gradient mag: 182.5498058698283\n",
      "Iteration 1800 lower bound [-6655.81709613]; gradient mag: 186.72818241713964\n",
      "Iteration 1900 lower bound [-6670.56385192]; gradient mag: 141.92717984189875\n",
      "Iteration 2000 lower bound [-6681.99229065]; gradient mag: 134.90044981517676\n",
      "Iteration 2100 lower bound [-6691.33154928]; gradient mag: 124.24450064667717\n",
      "Iteration 2200 lower bound [-6698.09380746]; gradient mag: 90.72750729174139\n",
      "Iteration 2300 lower bound [-6704.46722154]; gradient mag: 92.00682425256507\n",
      "Iteration 2400 lower bound [-6710.37468324]; gradient mag: 83.43014050930447\n",
      "Iteration 2500 lower bound [-6715.5951161]; gradient mag: 78.36413519810155\n",
      "Iteration 2600 lower bound [-6721.0099491]; gradient mag: 86.25989702363213\n",
      "Iteration 2700 lower bound [-6726.74986258]; gradient mag: 82.58117336382962\n",
      "Iteration 2800 lower bound [-6732.51358524]; gradient mag: 69.49735271846741\n",
      "Iteration 2900 lower bound [-6738.08792288]; gradient mag: 88.9546051329993\n",
      "Iteration 3000 lower bound [-6744.33156121]; gradient mag: 76.32806613196647\n",
      "Iteration 3100 lower bound [-6750.37582827]; gradient mag: 72.42112645311391\n",
      "Iteration 3200 lower bound [-6755.40972709]; gradient mag: 61.879480192403335\n",
      "Iteration 3300 lower bound [-6760.04689413]; gradient mag: 68.20207773800537\n",
      "Iteration 3400 lower bound [-6764.54216804]; gradient mag: 51.760080099853944\n",
      "Iteration 3500 lower bound [-6768.02496518]; gradient mag: 50.386605574357354\n",
      "Iteration 3600 lower bound [-6771.12888053]; gradient mag: 73.37038967826896\n",
      "Iteration 3700 lower bound [-6774.17465257]; gradient mag: 39.6616481082144\n",
      "Iteration 3800 lower bound [-6776.9663167]; gradient mag: 39.8542924246472\n",
      "Iteration 3900 lower bound [-6778.93030146]; gradient mag: 60.45073056975161\n",
      "Iteration 4000 lower bound [-6780.83897672]; gradient mag: 31.01266474078606\n",
      "Iteration 4100 lower bound [-6782.59406912]; gradient mag: 35.00077834577869\n",
      "Iteration 4200 lower bound [-6783.59245296]; gradient mag: 62.811015263608\n",
      "Iteration 4300 lower bound [-6784.23157001]; gradient mag: 86.23139712707363\n",
      "Iteration 4400 lower bound [-6784.78560595]; gradient mag: 52.99718262739984\n",
      "Iteration 4500 lower bound [-6785.2389904]; gradient mag: 21.290120168347894\n",
      "Iteration 4600 lower bound [-6785.4379241]; gradient mag: 64.6094530167456\n",
      "Iteration 4700 lower bound [-6785.7763758]; gradient mag: 13.450627527481211\n",
      "Iteration 4800 lower bound [-6787.80877861]; gradient mag: 49.2119595319494\n",
      "Iteration 4900 lower bound [-6791.38899327]; gradient mag: 22.636410780507447\n",
      "Iteration 5000 lower bound [-6792.56657798]; gradient mag: 56.976691875880796\n",
      "Iteration 5100 lower bound [-6794.05806808]; gradient mag: 23.880374444458337\n",
      "Iteration 5200 lower bound [-6795.51189916]; gradient mag: 24.641797507482295\n",
      "Iteration 5300 lower bound [-6797.06311023]; gradient mag: 26.7321311367836\n",
      "Iteration 5400 lower bound [-6798.47234457]; gradient mag: 25.772920864575525\n",
      "Iteration 5500 lower bound [-6799.59747376]; gradient mag: 44.787936727090994\n",
      "Iteration 5600 lower bound [-6800.41845721]; gradient mag: 25.368758286666672\n",
      "Iteration 5700 lower bound [-6800.9285287]; gradient mag: 20.348472694480684\n",
      "Iteration 5800 lower bound [-6801.21598079]; gradient mag: 25.02770426384562\n",
      "Iteration 5900 lower bound [-6801.50536644]; gradient mag: 27.52399940792158\n",
      "Iteration 6000 lower bound [-6801.73657292]; gradient mag: 24.82863432989399\n",
      "Iteration 6100 lower bound [-6801.91855729]; gradient mag: 29.25095120472297\n",
      "Iteration 6200 lower bound [-6802.08311609]; gradient mag: 61.939250963625845\n",
      "Iteration 6300 lower bound [-6802.19914083]; gradient mag: 62.04968459222468\n",
      "Iteration 6400 lower bound [-6802.40198068]; gradient mag: 54.177766245197674\n",
      "Iteration 6500 lower bound [-6802.39083398]; gradient mag: 64.74855692627312\n",
      "Iteration 6600 lower bound [-6802.47895342]; gradient mag: 67.88342155308415\n",
      "Iteration 6700 lower bound [-6802.66523049]; gradient mag: 22.656167547819276\n",
      "Iteration 6800 lower bound [-6802.70980192]; gradient mag: 26.144491474590303\n",
      "Iteration 6900 lower bound [-6802.79510935]; gradient mag: 24.33304252004725\n",
      "Iteration 7000 lower bound [-6802.7074069]; gradient mag: 132.3827549087991\n",
      "Iteration 7100 lower bound [-6802.97535283]; gradient mag: 47.30950227964992\n",
      "Iteration 7200 lower bound [-6803.06872019]; gradient mag: 18.6677809949445\n",
      "Iteration 7300 lower bound [-6803.15226905]; gradient mag: 16.37386960954132\n",
      "Iteration 7400 lower bound [-6803.12927089]; gradient mag: 80.54518808294657\n",
      "Iteration 7500 lower bound [-6803.20811548]; gradient mag: 78.34801167819126\n",
      "Iteration 7600 lower bound [-6803.36108778]; gradient mag: 20.411673992946195\n",
      "Iteration 7700 lower bound [-6803.41400686]; gradient mag: 45.85445177663636\n",
      "Iteration 7800 lower bound [-6803.44142975]; gradient mag: 86.50943586512463\n",
      "Iteration 7900 lower bound [-6803.58231518]; gradient mag: 38.35153959296008\n",
      "Iteration 8000 lower bound [-6803.62528357]; gradient mag: 38.90113384111168\n",
      "Iteration 8100 lower bound [-6803.70497224]; gradient mag: 37.07229199675387\n",
      "Iteration 8200 lower bound [-6803.78524049]; gradient mag: 30.355558806741918\n",
      "Iteration 8300 lower bound [-6803.8177322]; gradient mag: 20.57302077066295\n",
      "Iteration 8400 lower bound [-6803.87722911]; gradient mag: 30.10734417868183\n",
      "Iteration 8500 lower bound [-6803.91205015]; gradient mag: 33.64727048772432\n",
      "Iteration 8600 lower bound [-6803.9938813]; gradient mag: 24.402345922753764\n",
      "Iteration 8700 lower bound [-6804.04223496]; gradient mag: 25.182979539678875\n",
      "Iteration 8800 lower bound [-6804.07879759]; gradient mag: 30.700383695183643\n",
      "Iteration 8900 lower bound [-6804.129936]; gradient mag: 30.11303180376442\n",
      "Iteration 9000 lower bound [-6804.19301102]; gradient mag: 24.827273958161083\n",
      "Iteration 9100 lower bound [-6804.2327649]; gradient mag: 27.934711256588862\n",
      "Iteration 9200 lower bound [-6804.27992892]; gradient mag: 31.652517900838344\n",
      "Iteration 9300 lower bound [-6804.2544658]; gradient mag: 76.7960326884969\n",
      "Iteration 9400 lower bound [-6804.40133912]; gradient mag: 33.5267023586126\n",
      "Iteration 9500 lower bound [-6804.45581166]; gradient mag: 22.024298436104278\n",
      "Iteration 9600 lower bound [-6804.50827316]; gradient mag: 29.849029397289875\n",
      "Iteration 9700 lower bound [-6804.54115207]; gradient mag: 26.85180300288214\n",
      "Iteration 9800 lower bound [-6804.61825504]; gradient mag: 15.787832833013283\n",
      "Iteration 9900 lower bound [-6804.5951453]; gradient mag: 51.44142543573467\n",
      "Iteration 10000 lower bound [-6804.65734789]; gradient mag: 38.18645440771612\n",
      "Iteration 10100 lower bound [-6804.74887145]; gradient mag: 24.903011384448806\n",
      "Iteration 10200 lower bound [-6804.80101806]; gradient mag: 50.20177033692119\n",
      "Iteration 10300 lower bound [-6804.84448232]; gradient mag: 24.99745098858212\n",
      "Iteration 10400 lower bound [-6804.90343332]; gradient mag: 19.65630691010965\n",
      "Iteration 10500 lower bound [-6804.97057512]; gradient mag: 14.904921328816554\n",
      "Iteration 10600 lower bound [-6805.02344639]; gradient mag: 13.590805660601232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10700 lower bound [-6805.05677924]; gradient mag: 52.438504127881956\n",
      "Iteration 10800 lower bound [-6805.12201678]; gradient mag: 12.279489371247854\n",
      "Iteration 10900 lower bound [-6805.1739802]; gradient mag: 10.725391159907108\n",
      "Iteration 11000 lower bound [-6805.22612016]; gradient mag: 7.132057743153289\n",
      "Iteration 11100 lower bound [-6805.27549571]; gradient mag: 9.02874119443721\n",
      "Iteration 11200 lower bound [-6805.32669356]; gradient mag: 10.207558602812265\n",
      "Iteration 11300 lower bound [-6805.38429046]; gradient mag: 6.669379600109954\n",
      "Iteration 11400 lower bound [-6805.43584586]; gradient mag: 10.167714640905517\n",
      "Iteration 11500 lower bound [-6805.49457968]; gradient mag: 10.616153050769174\n",
      "Iteration 11600 lower bound [-6805.55774407]; gradient mag: 8.230648758988195\n",
      "Iteration 11700 lower bound [-6805.61690639]; gradient mag: 12.714485021444965\n",
      "Iteration 11800 lower bound [-6805.68141505]; gradient mag: 12.898879549499538\n",
      "Iteration 11900 lower bound [-6805.7596695]; gradient mag: 3.691402986539271\n",
      "Iteration 12000 lower bound [-6805.82808857]; gradient mag: 5.491408988255994\n",
      "Iteration 12100 lower bound [-6805.9006299]; gradient mag: 4.379149095482941\n",
      "Iteration 12200 lower bound [-6805.97661246]; gradient mag: 4.633410346190872\n",
      "Iteration 12300 lower bound [-6806.05674183]; gradient mag: 5.331094060223194\n",
      "Iteration 12400 lower bound [-6806.14205675]; gradient mag: 6.182587857818058\n",
      "Iteration 12500 lower bound [-6806.23271555]; gradient mag: 4.6823459547111845\n",
      "Iteration 12600 lower bound [-6806.32862818]; gradient mag: 6.8380335211318455\n",
      "Iteration 12700 lower bound [-6806.43138114]; gradient mag: 4.3378360926755715\n",
      "Iteration 12800 lower bound [-6806.53892395]; gradient mag: 5.665277323176766\n",
      "Iteration 12900 lower bound [-6806.655172]; gradient mag: 6.589668130969319\n",
      "Iteration 13000 lower bound [-6806.77707109]; gradient mag: 7.443047427801033\n",
      "Iteration 13100 lower bound [-6806.9074988]; gradient mag: 4.259116219879041\n",
      "Iteration 13200 lower bound [-6807.04652468]; gradient mag: 3.8751545777885723\n",
      "Iteration 13300 lower bound [-6807.19253422]; gradient mag: 5.7158045336732775\n",
      "Iteration 13400 lower bound [-6807.34933967]; gradient mag: 9.280172288120392\n",
      "Iteration 13500 lower bound [-6807.51614714]; gradient mag: 5.379065057917372\n",
      "Iteration 13600 lower bound [-6807.69485377]; gradient mag: 4.191246718794914\n",
      "Iteration 13700 lower bound [-6807.88439607]; gradient mag: 8.470905814199632\n",
      "Iteration 13800 lower bound [-6808.0863496]; gradient mag: 8.787032464993684\n",
      "Iteration 13900 lower bound [-6808.30153149]; gradient mag: 3.1253735699679317\n",
      "Iteration 14000 lower bound [-6808.53075171]; gradient mag: 2.9260240410253546\n",
      "Iteration 14100 lower bound [-6808.77438564]; gradient mag: 4.788598414640199\n",
      "Iteration 14200 lower bound [-6809.03601189]; gradient mag: 9.888792257644262\n",
      "Iteration 14300 lower bound [-6809.31587016]; gradient mag: 2.202779840931461\n",
      "Iteration 14400 lower bound [-6809.61452762]; gradient mag: 2.2758165740910146\n",
      "Iteration 14500 lower bound [-6809.93457918]; gradient mag: 2.3171398812979427\n",
      "Iteration 14600 lower bound [-6810.27825871]; gradient mag: 2.403117959625716\n",
      "Iteration 14700 lower bound [-6810.64761075]; gradient mag: 2.4619090755655737\n",
      "Iteration 14800 lower bound [-6811.04487031]; gradient mag: 2.5153376954320867\n",
      "Iteration 14900 lower bound [-6811.47242248]; gradient mag: 2.6092316577257852\n"
     ]
    }
   ],
   "source": [
    "###define design choices in gradient descent\n",
    "params = {'step_size':1e-3, \n",
    "          'max_iteration':15000, \n",
    "          'random_restarts':1}\n",
    "\n",
    "#fit my neural network to minimize MSE on the given data\n",
    "nlm.fit_MLE(x.T, y.reshape(1,-1), params)\n",
    "#nn.fit(x.T, y.reshape(3,-1), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 6.91395238, 28.13668575, 12.3688079 , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.28180738,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ..., 55.78227254,\n",
       "         34.00920903, 44.75928647],\n",
       "        [ 6.16139048, 24.29050362, 10.94355711, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [17.49643282,  9.20204779, 14.64422404, ..., 28.12989186,\n",
       "         15.47262043, 24.449011  ]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_hmc={\n",
    "       'num_samples':2000,\n",
    "       'step_size':1e-2, \n",
    "       'L':20,\n",
    "       'init': nlm.weights,\n",
    "       'burn':.1, \n",
    "       'thin':2,}\n",
    "\n",
    "nlm.forward(nlm.weights, x.T, partial=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.75469226  2.22279988  0.52700595  1.62922515  1.27863505 -2.31701038\n",
      "  -0.84254271 -1.1966194  -1.11257003 -1.0497113  -2.70184033  3.22081534\n",
      "   3.24389478  2.42148178  2.75780403  1.945124    1.31133411 -1.74291854\n",
      "  -1.54407656 -2.39211771 -2.71356602  0.26749426  0.30769142 -1.78487549\n",
      "   1.57900088 -5.08346065  2.3055914   1.9011165   5.67258978  5.27256092\n",
      "   1.83110197  0.5243378  -1.59516327 -3.67941958 -0.89543646 -1.25452568\n",
      "   2.24853396  3.22904627  1.09447038  0.92902592 -1.81367272 -1.94609244\n",
      "   0.46838689  1.68328361  0.41303743 -1.57079903 -0.77676314  5.86990981\n",
      "  -1.95306752  1.18578762 -0.23927832]]\n",
      "[[[ 6.91395238 28.13668575 12.3688079  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.28180738\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ... 55.78227254 34.00920903\n",
      "   44.75928647]\n",
      "  [ 6.16139048 24.29050362 10.94355711 ...  0.          0.\n",
      "    0.        ]\n",
      "  [17.49643282  9.20204779 14.64422404 ... 28.12989186 15.47262043\n",
      "   24.449011  ]]] (1, 5, 600)\n",
      "[[ 1.38154979  2.53748431  1.47866358 ... -0.23123712 -0.98643768\n",
      "  -0.00486842]\n",
      " [ 0.82850712  2.09605016  1.17564113 ... -0.91168676  1.33831384\n",
      "  -0.18403527]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 51 into shape (5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3d45c5791443>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_NLM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhmc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams_hmc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/Fall/Experiments/Neural_Network.py\u001b[0m in \u001b[0;36mfit_NLM\u001b[0;34m(self, x_train, y_train, hmc, params_hmc)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mlog_prior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_log_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prior_distribution'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prior_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mlog_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'likelihood_distribution'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'likelihood_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhmc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_likelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams_hmc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/Fall/Experiments/Hamiltonian_MC.py\u001b[0m in \u001b[0;36mhmc\u001b[0;34m(log_prior, log_likelihood, num_samples, step_size, L, init, burn, thin)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m# half-step update for momentum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mp_step_t_half\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_proposal\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep_size\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad_U\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_proposal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0;31m# full step update for position\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mq_proposal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mstep_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp_step_t_half\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/autograd/wrap_util.py\u001b[0m in \u001b[0;36mnary_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0munary_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munary_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnary_op_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnary_op_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnary_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnary_operator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/autograd/differential_operators.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0marguments\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbut\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0minstead\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     should be scalar-valued. The gradient has the same type as the argument.\"\"\"\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         raise TypeError(\"Grad only applies to real scalar-output functions. \"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/autograd/core.py\u001b[0m in \u001b[0;36mmake_vjp\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstart_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVJPNode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mend_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_node\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mend_node\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(start_node, fun, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mstart_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mend_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_box\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_box\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstart_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/autograd/wrap_util.py\u001b[0m in \u001b[0;36munary_f\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0msubargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubvals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msubargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/Fall/Experiments/Hamiltonian_MC.py\u001b[0m in \u001b[0;36mU\u001b[0;34m(W)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \"\"\"\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlog_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlog_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/Fall/Experiments/Bayesian_pdf.py\u001b[0m in \u001b[0;36mlog_logistic\u001b[0;34m(W)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmapped_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mdot_product\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapped_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_product\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1e-15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/autograd/numpy/numpy_vjps.py\u001b[0m in \u001b[0;36mwrapped_reshape\u001b[0;34m(x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;31m# The reshape function doesn't support both ways, so we have to wrap it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mf_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mparents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mboxed_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0margnums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m   \u001b[0;32min\u001b[0m \u001b[0mboxed_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_wrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mf_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_autograd_primitive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    255\u001b[0m            [5, 6]])\n\u001b[1;32m    256\u001b[0m     \"\"\"\n\u001b[0;32m--> 257\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 51 into shape (5)"
     ]
    }
   ],
   "source": [
    "print(nlm.weights)\n",
    "nlm.fit_NLM(x.T, y.reshape(1,-1),hmc,params_hmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
