{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FeedForwardNN import Feedforward\n",
    "from Toy_Datasets import two_clusters_gaussian\n",
    "from Neural_Network import NLM\n",
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "import matplotlib.pyplot as plt\n",
    "from autograd.misc.optimizers import adam\n",
    "from Bayesian_pdf import get_log_prior, get_log_likelihood\n",
    "from Hamiltonian_MC import hmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_clusters_gaussian(params, n_samples, test_points=None):\n",
    "    \"\"\"\n",
    "    :param params: should be a list of length K, K being the number of classes you wish to create\n",
    "    for every class 0 <= k <=K-1, params[k] should be a dictionnary containing two keys: mean and covariance_matrix.\n",
    "    The shapes expected for mean are D and covariance_matrix are D*D where D is the number of features for every\n",
    "    datapoint.\n",
    "    :param n_samples: number of samples you wish to create for every cluster\n",
    "    :param test_points: OOD points\n",
    "    :return: x of len(K*n_samples, n_features) and y of shape (K*n_samples). For both x and y, the features pertain\n",
    "    sequentially to every class 0 <= k <= K-1\n",
    "    \"\"\"\n",
    "    if params:\n",
    "        if isinstance(params, list):  # params is a list\n",
    "            K = len(params)\n",
    "        else:  # params is a numpy array\n",
    "            K = params.shape[0]\t\n",
    "        x = np.array([0, 0])\n",
    "        for k, param in enumerate(params):\n",
    "            param_k = params[k]\n",
    "            try:\n",
    "                mean_k, cov_k = param_k['mean'], param_k['covariance_matrix']\n",
    "            except KeyError:\n",
    "                raise KeyError('The parameters for class ' + str(k) + 'are not in the right dictionnary format. Please use mean and covariance_matrix')\n",
    "            assert len(mean_k) == cov_k.shape[0] == cov_k.shape[1], 'Wrong shapes for the parameters of class ' + str(k)\n",
    "            samples_class_k = np.random.multivariate_normal(mean_k, cov_k, n_samples)\n",
    "            x = np.vstack((x, samples_class_k))\n",
    "        y = np.array([[k] * n_samples for k in range(K)])\n",
    "        return x[1:, :], np.array(y).flatten()\n",
    "    else:\n",
    "        raise BaseException().args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(x, y, models, ax, poly_degree=1, test_points=None, shaded=True):\n",
    "    '''\n",
    "    plot_decision_boundary plots the training data and the decision boundary of the classifier.\n",
    "    input:\n",
    "       x - a numpy array of size N x 2, each row is a patient, each column is a biomarker\n",
    "       y - a numpy array of length N, each entry is either 0 (no cancer) or 1 (cancerous)\n",
    "       models - an array of classification models\n",
    "       ax - axis to plot on\n",
    "       poly_degree - the degree of polynomial features used to fit the model\n",
    "       test_points - test data\n",
    "       shaded - whether or not the two sides of the decision boundary are shaded\n",
    "    returns: \n",
    "       ax - the axis with the scatter plot\n",
    "\n",
    "    '''\n",
    "    # Plot data\n",
    "    ax.scatter(x[y == 1, 0], x[y == 1, 1], alpha=0.2, c='red', label='class 1')\n",
    "    ax.scatter(x[y == 0, 0], x[y == 0, 1], alpha=0.2, c='blue', label='class 0')\n",
    "    ax.scatter(x[y == 2, 0], x[y == 2, 1], alpha=0.2, color='green', label='class 2')\n",
    "\n",
    "\n",
    "    # Create mesh\n",
    "    interval = np.arange(-5, 5, 0.1)\n",
    "    n = np.size(interval)\n",
    "    print(n)\n",
    "    x1, x2 = np.meshgrid(interval, interval)\n",
    "    x1 = x1.reshape(-1, 1)\n",
    "    x2 = x2.reshape(-1, 1)\n",
    "    xx = np.concatenate((x1, x2), axis=1)\n",
    "\n",
    "    # Predict on mesh points\n",
    "    if(poly_degree > 1):\n",
    "        polynomial_features = PolynomialFeatures(degree=poly_degree, include_bias=True)\n",
    "        xx = polynomial_features.fit_transform(xx)\n",
    "\n",
    "    if len(models) > 1:\n",
    "        alpha_line = 0.1\n",
    "        linewidths=0.1\n",
    "    else:\n",
    "        alpha_line = 0.8\n",
    "        linewidths=0.5\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for model in models:\n",
    "        yy = model.predict(xx)  \n",
    "        yy = yy.reshape((n, n))\n",
    "\n",
    "        # Plot decision surface\n",
    "        x1 = x1.reshape(n, n)\n",
    "        x2 = x2.reshape(n, n)\n",
    "        if shaded:\n",
    "            ax.contourf(x1, x2, yy, alpha=0.1 * 1. / (i + 1)**2, cmap='bwr')\n",
    "        ax.contour(x1, x2, yy, colors='black', linewidths=linewidths, alpha=alpha_line)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    if test_points is not None:\n",
    "        for i in range(len(test_points)):\n",
    "            pt = test_points[i]\n",
    "            if i == 0:\n",
    "                ax.scatter(pt[0], pt[1], alpha=1., s=50, color='black', label='test data')\n",
    "            else:\n",
    "                ax.scatter(pt[0], pt[1], alpha=1., s=50, color='black')\n",
    "\n",
    "    ax.set_xlim((-5.5, 5.5))\n",
    "    ax.set_ylim((-5.5, 5.5))\n",
    "    ax.set_xlabel('x_1')\n",
    "    ax.set_ylabel('x_2')\n",
    "    ax.legend(loc='best')\n",
    "    return ax\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class Bayesian_logistic_regression:\n",
    "    def __init__(self, intercept, slopes):\n",
    "        self.intercept = intercept\n",
    "        self.slopes = slopes\n",
    "\n",
    "    def predict(self, x):\n",
    "        print(x.shape)\n",
    "        print(self.slopes.shape)\n",
    "        #y = sigmoid((x.reshape(-1,20)).dot(self.slopes) + self.intercept)\n",
    "        y = sigmoid((x).dot(self.slopes) + self.intercept)\n",
    "        return (y > 0.5).astype(np.int_)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        return sigmoid(x.dot(self.slopes) + self.intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAFOCAYAAAAozgFxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzsvXtUW/eZ7/39SSAkIUCAZC4WxhfwJcbGccA0dRzH404Tp019kqY9Z9qm8Zw39jpda5LM6qTzrjPJatK06dt25Zy2b/K+09c+mebS9KTJZKjTmdjuTNzc3NgWSezY+IaxjZExWFwESCAB4vf+8bDRBd0vSMDzWasLs7X3b//23mr2l+d5ft9HSCnBMAzDMAzDZA5VpifAMAzDMAyz0GFBxjAMwzAMk2FYkDEMwzAMw2QYFmQMwzAMwzAZhgUZwzAMwzBMhmFBxjAMwzAMk2FYkDEMkxGEELuEEB+mcfwDQogH/X7/kRCiVwjRLYRYIoRwCiHUaTivUwixPNXjhjjPi0KIH6X7PAzDzA4syBiGgRDiihDiC5meRyqRUu6QUr4EAEKIKgB/B+AmKWW5lPKqlNIgpfQmcw4hxLtCiIeCzmuQUl5KZtxUE2qeDMNkFyzIGIZZCFQD6JNS3sj0RBiGYULBgoxhFjhCiFcALAHwh6l0299Pbf+KEKJVCOGYirCsmdr+PSHEm0FjPCeE+EWY8auEEP8ihLALIfqEEM+H2e+XQohOIcSQEOJjIcQWv882CSFapj7rEUL8z6ntWiHEb6bGdQghrEKIsqnP3hVCPDQV+ft3AJVT1/eiEGKpEEIKIXKm9i0RQvxaCNElhBgQQvx+anuxEOJfp+Y+MPVvy9RnzwDYAuD5qXGfn9ouhRA1U/8uEkK8PHV8hxDiCSGEauqzXUKID4UQz06NfVkIsSPCc7pZCPGJEGJYCPE7AFq/zxKZZ9j7zTDM7MOCjGEWOFLKBwBcBXDPVLrtZ0KIlQD+N4C/BWAG8DZIsGkA/AbAXUIIIwBMiZr/DOCV4LGnarT+FUAHgKUAFgN4LcxUrAA2ACgB8FsAbwghFNHxSwC/lFIWAlgB4PWp7Q8CKAJQBaAUwH8DMBp0ff8BYAeArqnr2xXi3K8A0ANYC2ARgJ9PbVcB+DUowrZkauznp8Z9HMAHAP5maty/CTHuc1PzWw5gK4BvA/hrv8+bAJwHYALwMwAvCCFE8CBT9/33U/MsAfAGgK/67ZLIPCPdb4ZhZhkWZAzDhOI/A/g3KeW/SynHATwLQAfg81LK6wDeB/C1qX3vAtArpfw4xDibAFQC+J6U0iWldEspQxbySyl/I6Xsk1JOSCn/B4A8AKumPh4HUCOEMEkpnVLKo37bSwHUSCm9UsqPpZRD8VyoEKICJNj+m5RyQEo5LqV8b2pOfVLKN6WUI1LKYQDPgIRVLOOqQffxv0sph6WUVwD8DwAP+O3WIaXcN1XL9hKACgBlIYb7HIBcAL+Ymt8/gwQVEp1nlPvNMMwsw4KMYZhQVIKiWgAAKeUkgE5QhAsg8fCtqX9/CyGiY1NUgUTHRLQTCiH+TghxVggxKIRwgCJLpqmP/w8AKwGcm0pLfnlq+ysADgF4bSrd+DMhRG7MV+mbY7+UciDEnPRCiP9vKt04BBKixhhXZ5oAaOB3H6f+vdjv927lH1LKkal/GkKMVQngmpRSBo2V8Dyj3G+GYWYZFmQMwwCADPq9C5T+AgBMpdGqAFyb2vR7AOuFEHUAvgzg1TDjdgJYotRqhWOqfun/BPB1AMVSSiOAQQACAKSUbVLKvwKlE38K4J+FEPlT0aIfSClvAvD5qbl8O8Zr9p9jiZKCDeLvQFGjpql06e3KlKd+Bt83f3pBEbxqv21L4LuH8XAdwOKgdOaSROcZ7X4zDDP7sCBjGAYAekB1TgqvA/iSEGL7VMTp7wB4APwZAKSUbgD/DKo9Oi6lvBpm3OMgMfETIUT+VBH+5hD7FQCYAGAHkCOE+D6AQuVDIcS3hBDmqUidY2qzVwixTQixbioSNAQSQHFZWUylYA8A+H+niuNzhRCKoCkA1WM5hBAlAJ4MOjz4vvmP6wXdx2eEEAVCiGoA3wXV4MXLR6D784gQIkcIcR8oHawQ7zwj3m+GYWYfFmQMwwDA/wXgiamVio9JKc+DUpHPgSI994CK/sf8jnkJwDqET1cqouQeADWghQM2UF1VMIdAougCKBXnBkWuFO4C0CqEcIIK/P/LlCgsBwnDIQBnAbyHxATPAyAxdw7ADdBiBgD4Bah2rhfAUQAHg477JYD7p1Y2/t8hxn0YgAvAJQAfggTsP8U7uan7fh+AXQAGQPfwX/x2iXee0e43wzCzjAgsSWAYhokNIcQSkIApj7eQnmEYhgmEI2QMw8TNlJfWdwG8xmKMYRgmeSIW2jIMwwQjhMgH1SR1gFKJDMMwTJJwypJhGIZhGCbDcMqSYRiGYRgmw7AgYxiGYRiGyTBzrobMZDLJpUuXZnoaDMMwDMMwUfn44497pZTmaPvNOUG2dOlStLS0ZHoaDMMwDMMwURFCdETfi1OWDMMwDMMwGYcFGcMwDMMwTIZhQcYwDMMwDJNh5lwNGcMwDMMwmWN8fBw2mw1utzvTU8kqtFotLBYLcnNzEzqeBRnDMAzDMDFjs9lQUFCApUuXQgiR6elkBVJK9PX1wWazYdmyZQmNwSlLhmEYhmFixu12o7S0lMWYH0IIlJaWJhU1ZEHGMAzDMExcsBibSbL3hAUZwzAMwzBznqeeegrPPvtsWsb++OOPsW7dOtTU1OCRRx5BOvqAZ4UgE0KohRCfCiH+NdNzYRiGYZhUYbMBzc3A3r3002bL9IyYRPjOd76DvXv3oq2tDW1tbTh48GDKz5EVggzAowDOZnoSDMMwcwl+2Wc3Nhuwfz8wMgKUldHP/fsX3nNKx/f05Zdfxvr161FfX48HHnhgxuf79u1DY2Mj6uvr8dWvfhUjIyMAgDfeeAN1dXWor6/H7bffDgBobW3Fpk2bsGHDBqxfvx5tbW0BY12/fh1DQ0O49dZbIYTAt7/9bfz+979P/iKCyLggE0JYAHwJwP/K9FwYhmHmCvyyz36sVsBoBAoLAZWKfhqNtH2hkI7vaWtrK5555hkcPnwYJ0+exC9/+csZ+9x3332wWq04efIk1qxZgxdeeAEA8PTTT+PQoUM4efIk3nrrLQDAr371Kzz66KM4ceIEWlpaYLFYAsa6du1awDaLxYJr164lfgFhyLggA/ALAH8PYDLTE2EYhpkr8Ms++7HbAYMhcJvBQNsXCun4nh4+fBj3338/TCYTAKCkpGTGPqdPn8aWLVuwbt06vPrqq2htbQUAbN68Gbt27cK+ffvg9XoBALfeeit+/OMf46c//Sk6Ojqg0+kCxgpVL5aORQ0ZFWRCiC8DuCGl/DjKfnuEEC1CiBb7QvomMwzDhIFf9tmP2Qw4nYHbnE7avlBIx/dUShlVEO3atQvPP/88Tp06hSeffHLajuJXv/oVfvSjH6GzsxMbNmxAX18fvvGNb+Ctt96CTqfDnXfeicOHDweMZbFYYPML6dlsNlRWViZ+AWHIdIRsM4CvCCGuAHgNwF8IIX4TvJOUcq+UskFK2WBeSN9khmGYMPDLPvtpbAQcDmBoCJicpJ8OB21fKKTje7p9+3a8/vrr6OvrAwD09/fP2Gd4eBgVFRUYHx/Hq6++Or29vb0dTU1NePrpp2EymdDZ2YlLly5h+fLleOSRR/CVr3wFn332WcBYFRUVKCgowNGjRyGlxMsvv4ydO3cmfgFhyKggk1L+dymlRUq5FMB/AXBYSvmtTM6JYRhmLsAv++zHYgF27gT0eqCnh37u3EnbFwrp+J6uXbsWjz/+OLZu3Yr6+np897vfnbHPD3/4QzQ1NeEv//IvsXr16unt3/ve97Bu3TrU1dXh9ttvR319PX73u9+hrq4OGzZswLlz5/Dtb397xnj/+I//iIceegg1NTVYsWIFduzYkfgFhEGkw0sjEYQQdwB4TEr55Uj7NTQ0yJaWltmZFMMwTBZjs1Etjt1OEYfGxoX1smcyw9mzZ7FmzZqY919I39NQ90YI8bGUsiHasVnTy1JK+S6AdzM8DYZhmDmDxTJ/X2zM/IG/p7GRNYKMYRiGYeY6CykaxKQWFmQMwzDMnCJbRY/iuWU0kueW00m/L7S6MSYxMr3KkmEYhmFiJpsNcdkbjkkGFmQMwzDMnCGbRQ97wzHJwIKMYRiGmTNks+hhbzgmGViQMQzDzCPme8PxbBY97A2XWZ566ik8++yzaRn78ccfR1VVFQzBfw2kEBZkDMMw84Rsq69KhzjMZtHDRrDzl3vuuQfHjx9P6zlYkDEMw8wTsqm+Kl3iMNtFj8UC3HsvsGcP/cyWeWWUNCjzl19+GevXr0d9fT0eeOCBGZ/v27cPjY2NqK+vx1e/+lWMjIwAAN544w3U1dWhvr4et99+OwCgtbUVmzZtwoYNG7B+/Xq0tbXNGO9zn/scKioqkp53JNj2gmEYZp5gt5P48cdgIOEy2/iLQ8D302pNXqTEajSarfYYC4o0eIG0trbimWeewZEjR2AymUL2srzvvvuwe/duAMATTzyBF154AQ8//DCefvppHDp0CIsXL4bD4QBADccfffRRfPOb38TY2Bi8Xm/i15sEHCFjGIaZJ2RTfVWqi+/jDbJkW/p2wZKGsO3hw4dx//33w2QyAQBKSkpm7HP69Gls2bIF69atw6uvvorW1lYAwObNm7Fr1y7s27dvWnjdeuut+PGPf4yf/vSn6OjogE6nS3huycCCjGEYZp6QifqqcEIpleIwEXGVTenbBU0alsVKKSGEiLjPrl278Pzzz+PUqVN48skn4Xa7AVA07Ec/+hE6OzuxYcMG9PX14Rvf+Abeeust6HQ63HnnnTh8+HDCc0sGFmQMwzDzhNmur4oklBobgStXgHfeAQ4coJ9XriQmDhMRV9lsj7GgSEPYdvv27Xj99dfR19cHACFTlsPDw6ioqMD4+DheffXV6e3t7e1oamrC008/DZPJhM7OTly6dAnLly/HI488gq985Sv47LPPEp5bMnANGcMwzDxiNhs5R6oTa2wEpAzcP/j3cATXfl24AKxeHbhPtNo4RQcocwKyxx5jQdHYSCodoIfmdFLYduvWhIdcu3YtHn/8cWzduhVqtRo333wzXnzxxYB9fvjDH6KpqQnV1dVYt24dhoeHAQDf+9730NbWBikltm/fjvr6evzkJz/Bb37zG+Tm5qK8vBzf//73Z5zz7//+7/Hb3/4WIyMjsFgseOihh/DUU08lfA2hEDLW/4dkCQ0NDbKlpSXT02AYhlnw7N1LkTGVX65lcpKEktlMETN/QTQ0RFG7e+8NP6Z/Dbjy/n7vPaCuDli2LPaxlHG8XqCri8SdWg3s3p2aFO5CXjBw9uxZrFmzJvYDFtDNCnVvhBAfSykboh3LETKGYRgmISJFoRJd8Rkq6lZXB5w+DZSWxh5ksViATZuAffuAiQmaS0UFcPw4/UxGD3AT8TiZzbDtHIYFGcMwDBOR4ACHxULbLlwA2ttJMFVXBwolqzWxlGEoIVddTdE2pTbObKZzRHvH22y0X3CULlnrjXRaejALFxZkDMMwCbIQMjHB0aCODuC114DNm6muS6ej6NXICLBqVaBQSqR0KFzUbdWqyKnOUKTLly2b/N6Y+QOvsmQYhkmAheJzFbzCsbubUofd3fT7smUkshTBpIixRFd8ptK6I12+bNnk98bMHzhCxjAMkwALJW0VHA0aHKTrHhz0bQsXHUqkdEgRclZrfOnJUKRhgV9ax2UWNizIGIZhEmChpK2CU4hFRSQ+jEbfPqmODqWqBjwRcRdLGjqVopFhFFiQMQzDJMBC8bkKjgaVl1Mh/+rVlFLM9uhQsLhTOguEElzxrJ7khYPZx1NPPQWDwYDHHnsspeOOjIzga1/7Gtrb26FWq3HPPffgJz/5SUrPAXANGcMwTEJkok1RJgiuBauqAh57jH7ORjeAVBKt7i+b2y3F28uTSS2PPfYYzp07h08//RRHjhzBgQMHUn6OjEbIhBBaAO8DyJuayz9LKZ/M5JwYhmFiYSGlrUJFg1IlPGdzpWq0ur9sTUPPdd8z26AN1i4r7C47zPlmNFY2wlKU3MRffvllPPvssxBCYP369XjllVcCPt+3bx/27t2LsbEx1NTU4JVXXoFer8cbb7yBH/zgB1Cr1SgqKsL777+P1tZW/PVf/zXGxsYwOTmJN998E7W1tdNj6fV6bNu2DQCg0WiwceNG2NKgiDOdsvQA+AsppVMIkQvgQyHEASnl0QzPi2EYJiqctkqO2RYa0QRXtqah07GAZLaEsG3Qhv3n98OoNaLMUAbnmBP7z+/HzlU7ExZlra2teOaZZ3DkyBGYTKaQvSzvu+8+7N69GwDwxBNP4IUXXsDDDz+Mp59+GocOHcLixYvhcDgAUMPxRx99FN/85jcxNjYGr9cb9twOhwN/+MMf8OijjyY090hkVJBJ6tukLB7Onfrf3OrlxDAMM89J18s7XStVw803muDKltWTwfM/fx4I7lSUTORuNoWwtcsKo9aIwjy66cpPa5c1YUF2+PBh3H///TCZTACAkpKSGfucPn0aTzzxBBwOB5xOJ+68804AwObNm7Fr1y58/etfx3333QcAuPXWW/HMM8/AZrPhvvvuC4iO+TMxMYG/+qu/wiOPPILly5cnNPdIZLyGTAihFkKcAHADwL9LKY9lek4MwzAMEY/fWrx1TnY7CQuF3l7go4+An/8c+M53qO2R1RrfmJHmG63uL1HvtFQSav6XLpEhrz/JRO5ms1bO7rLDoDEEbDNoDLC77AmPKaWEECLiPrt27cLzzz+PU6dO4cknn4Tb7QZA0bAf/ehH6OzsxIYNG9DX14dvfOMbeOutt6DT6XDnnXfi8OHDIcfcs2cPamtr8bd/+7cJzz0SGRdkUkqvlHIDAAuATUKIuuB9hBB7hBAtQogWuz3xh8gwDMPER6wv72jCLZRY8zdY7e0FDh8GTpyg8bVa4I9/BH7wA6CzM3bz3UjzjUVwWSxkcLtnT6DRbSqJJFxDzV/p5ZmqBSTBQhig39PxejXnm+EcC3TRdY45Yc5PPA+8fft2vP766+jr6wOAkCnL4eFhVFRUYHx8HK+++ur09vb2djQ1NeHpp5+GyWRCZ2cnLl26hOXLl+ORRx7BV77yFXz22WczxnviiScwODiIX/ziFwnPOxqZriGbRkrpEEK8C+AuAKeDPtsLYC8ANDQ0cEqTYRhmloi10D1S+hEInSLbtImafQPUF/PGDSAvD1i6lM7h8QDj49QVYNmy2FKa0eYbqe7PZgMOHAA++QSQEmhoAO66K7WiLFq6MFwvz9HR+Ht5hmM2a+UaKxux/zzlgQ0aA5xjTjjcDmytTjwPvHbtWjz++OPYunUr1Go1br75Zrz44osB+/zwhz9EU1MTqqursW7dOgwPDwMAvve976GtrQ1SSmzfvh319fX4yU9+gt/85jfIzc1FeXk5vv/97weMZbPZ8Mwzz2D16tXYuHEjAOBv/uZv8NBDDyV8DaEQVMaVGYQQZgDjU2JMB+CPAH4qpfzXcMc0NDTIlpaWWZsjwzDMQqa5mSJTwQ269frA3pJ79wJqNXmUDQ6SgeyKFYDXSy/6cGM0NgIHDwIvv0xRsqVLgZoaOv7jj0kYLV9OwgigCFFPD0WwkplvMDYb8OKLwMWLQHExIATQ1wesXAk8+GDqRFm0+SU6/3jwF4X+tXKxpmfPnj2LNcFFbZHOl4ZVltlKqHsjhPhYStkQ7dhMR8gqALwkhFCD0qevRxJjDMMwzOwSqdDdv/j8009JUC1ZQqm206eBP/0JuPlm2hapKN3jATZuJDE3MQG0tQG1tUBODn1WVOQ7LlokJ97CfOUaDh2if1dW+tJ5QtC1hYvIJbLYIVoEbzYWFsy2ZYulyDJvBVgqyfQqy88A3JzJOTAMw2QDs+nHFQ/hXt5AYOptbAy4ehXIzaXIkkoF6HQkqC5dogjPsmW+cRVhpaQ66+vpuGvXAI0GuHyZ6sgmJ6k7QKxdAeIRG/6RIpUKcLvpGrRaEoFaLTAwELq2KtGVitHShbMlltiyJfvIdISMYRhmwZPtxp+hXt7NzYE1Y1otsH49cOoUUFBA22tqSEitWkURs9LSmVGft9+ma+7vp5TnjRuU8tTpgIceArZto/sTjzhR5quI3LffDi1y/evejEYSjePjwPXrJMjcbhKHoSJyiVp2xBIBY7G0MGFBxjAMk2HS5ccViWQjcsGpt6IiKjzXaoGmJkr3jYxQkX6konSzmSwdrFaKjq1YQVE1j4eibhUVia0mjEXk+l9DbS1Fx7q66Lwul6+GLPj8NhulOFUqGr+2FjCZYvMGmy8dHmKxnlhoJFuTz4KMYRgmw8x2yx6bDXjpJTrv2BhFgc6cia94PTj1VlsLvPcezdvlIrHicpFlg9NJwubee2dGrSwWWtl44wZF1oSg/9XWUk1aoqL0wAGqRRsfJ7FYWxtofxF8DSYTsH078OGHJAxHRoAtW2auslSEnlZL8/R4gGPHSISGi6YFM9cjYFqtFn19fSgtLWVRNoWUEn19fdBqtQmPwYKMYRgmw8x2y56DB8lmwmSiFYVuN/1+8CClCWMhOPWm0VCK8qabyEts0SLaR6MJXAQQHLU6fpxSmVevknjKz6dFAIWFlMZMxBvLZqMFBWVldH2joySaGhtJJEa6ho0byfssnGDyr3k7dozmq9eTkFOraUVoc3P21ACmA4vFApvNBvYFDUSr1cKSxENnQcYwDJNhZrtlT0sLiSC9nn7X6+n3lpbYBVmo1NuuXYG1W3Y7ja2k5ILrzpSfV68Cq1eToNHrqYbss89IPBUU0HjxvOesVhKEKhVFsZTrPHVqZq1WvOlDJZqpUlFUrK2N5nf5MvC1r1F6drZqADO1ECQ3NxfL/FdoMCmBBRnDMEyGmY26Iv+X95UrNHZ+vu9zKUm8xDvvUHMMtz1cara4mPzKLlygKNXFi2R/sWQJsHhxbOIm2IJj+XKy0QAovSgl3dvgejBlTOVYxcg23LmC05wmE/DOO0BJiW8V6WzVAGbzQhAmfliQMQzDZAHprCsKfnkvXkyrHlUqiiSNjpK9w+bN6Tm/QrjU7KpVPoPYN96gedXXA7fcQoJnaCiyuAm+vrw8oLUVWLeOCvMdDrLjuPnmmasugfiETahoZk8P8IUvBO6XzhpAIDMLQZj0woKMYRhmnhP88r7tNkoLdnWR+apS/7VjR3rnEUrMXL5MPmOKSNq2jUxkVVOdlnt7KXLW2ekbI1hwBF9ffT3w7rt0zLZtvvOMj/t6bSrCS6OJT9iEimZu305ROH+UGsB0pRVneyEIk35YkDEMw8wREn25B7+8TSYSX1YrsGFD4FjprEsKFjPKikqdzifQ/E1ke3upcF6lomOV5uLB0atQ13f77YGiqbyczhMsvD780NeWSSGasAmOZoZatWo2A1/8YvrSirO9EIRJPyzIGIZhQpBtzvnJ1AyFenlrtcCddwb2R5yNuiR/MdPcTOLLXyTV1flMZC9cIDGmmMuGi17Fcn179/paIikYDFRblgphE2xBJSWtNk1XWnG2F4Iw6YcFGcMwTBDZWDCdTM1QrC/vZM6Rqr6O/iaynZ00xqpVFPVS5h8cvYrl+sJFlBoaaN9o9yYSVitF9OrrfduGhuKPvsVzD+eLwSzjgwUZwzBMENlYMB1vzVDwy33TpugtiBKtS0p1X0fFRBagNGW06FUs4iScaNu5k7YlI2zC3bd4om+J3MO5bjDLBMKCjGEYJohkC6aTTXeGOj6UeOnoIFf5vXtn1oGFMmBNtvF1OCIJWIBc8z/5hARKQ4PP/T5aZCvU51eu0MrQ4GuOJk6iibZkhE0qom/Z+EcAM7uoMj0BhmGYbEN5wfoTa12RIoaU1XxKIbrNFtu5wx1vsdDLfGiIaqouXwaOHCELi+Dz+L/cVSpf82xFIIWjsTHwHEND9Hu0XpJ2e+j6rPPngRdfpHlqtZSG/OADKoBXzF537vT1uNTrA0Vj8OejoyTq9PrE7q3FQpG3PXvoZ6qETrj7dtddka/Pn3D3kM3wFw4cIWMYhgkimYLpZCMdBw+G7sFoswVGeK5dI9+wUGakiUb44q1LUsTfJ5+Q4Kqv99V6OZ3kbebxBHYFEILmd/AgbVeigHffHd1ktrk59ErJTEeRUhF9iyc6mW0LTpjUwIKMYRgmiGQKppNJd9ps5PpeUUGRrdOnKbpUV0eu9f5Rnb17w58nGUuEWOuS/NOijY3A++9Tc/EtW0icORzkXt/RQT8VtFoq1n/nHeDLX46tXkoRIG++GVuRfyZItp4r1j8CsnHBCZMaWJAxDMOEINEXbDJiyGr1vWSvXiXxYjRSK6Hx8cCejpHOMxuWCP6RwMJC4I47gJMnqR/mF79I57JagevXfasmAWpk3t9PRrSxRLqsVmDfPmqlNDJCZrYOB/WRNJnmj/dWrH8EcK3Z/IUFGcMwTApJRgzZ7dTu5/XXKUKm0VDKb3SUomT+L12LhYSK10sv78pKas6tvMTTbYkQyox12zY6n7+3WWsrCcrJSUpX9vXRPNetI+PXtjbqGlBQQELDH5uNrjEnh64hJwc4e5bStOfP0/2ZT95bsfwRwA798xcWZAzDMCkkGTFkNgcW87tcJF7Wryd/LuWla7PRqsm6OopA9fRQ1Gn37kDBls6ISSyRQIsF2LUrcJXlli300+UCzpyhBufFxTT//v7AKKDVSoJz0SISc4oQ6e2l/ZqaAu/tQqitYof++QsLMoZhmBSTqBhSomslJRRxEoKEyy23BL50/dNWSlH/0BAJkmgrIlNFrJFAi4WEoj82G/D00xTx0mopAjg5OTMKqAgr/5Sn2Uzpy3vuoUiczUbF/ufPU9ulujoSr7NRW5UJAcgO/fMXtr1gGIbJEpTomhL58nrpBayk5hSxlQ0WCcpcR0cpAvbhhzTPWI9dsYJWkTocQF4eRbvy84E//pEWLDQ3kyCtrCRROjJCkbWBARJyjY2BFiEOB20/c4YibbFafSSKcu7OTrIg+cNTlHtwAAAgAElEQVQfSGSm63wK0axCmLkLR8gYhmGyCIsFeOgh8rBSoi96fWBqLlLaKtGoTaLHeTyUhlSiNbFGpVauDHTh7+0ljzL/1YM3bpAIu+kmKua/fp1SuEpqtrnZFykcHqbI4ugo1aWZTOmtrVLSqWfO+LzH7HbgH/4B+PGPo0cqk4musUP//IQFGcMwTBYS6aUbLm21cmVilgiRrBSA8MIhlf01T54k8VVf7zOzXbqUBFZpKaU2m5oCz+9f4F5URPsqlhtAaJGqUtF5pEwuzWi3k0CcnKQoWV4e1brduEELESoqIvu3sXUFE0xGBZkQogrAywDKAUwC2Cul/GUm58QwDJPthFs4kKhAUo4bGwOOHaNVj7m5wG9/S2nEcMLBbqeIVWsrHVNURKlIlyv+a3C7gdtv9/mLASTUXK7AVZsKNhvQ3g4cPQqUl5Noa2sjUVZU5HPL9xepajX5pQlBUT3F6T8RIWQ207mHhkiM5eVRtFCpcYt0z9m6gglFpiNkEwD+Tkr5iRCiAMDHQoh/l1KeyfC8GCZpbIM2WLussLvsMOeb0VjZCEsR/9eW8ZHqtNXbb4e2RDh3jtJ74c6jCCur1bfq0eUC3noL+PrXwwsHlYoEjslEAsPtpt+3bIn/GpqbSSD5E60R9+LFJLpsNvI/y8ujOTQ0kDDTaIB/+ifaXl9PAk4RfO3twK23Bl5PPDQ2Uu2c3U6RMY+Hzr1kia8DQTjYuoIJRUaL+qWU16WUn0z9exjAWQCLMzknhkkFtkEb9p/fj5HxEZQZyjAyPoL95/fDNhhj0z1mzqOs/lMK1IP7LSbb8zIUoXpwdnSQ+Ih0HrMZOHWKxJheTxEklYqETFdX4Hj+iwekpH2BwJ9Sxj/3ePpoKhGmZcsoAqY0We/sJEE0MeHrfXn5Ml3ba68BFy5QSlOno4he8PXEg7J6VKOhNGVODp17dJR+//TT0M8doHv0pz9R+6iPPqL6ObauYLJmlaUQYimAmwEcy+xMGCZ5rF1WGLVGFOYVQiVUKMwrhFFrhLUrzUuwmKwgFrGVaAPwSIQSNadP06rN4PMcOOATjH19ZBkhJR2neKCtXj1TrPgLB8VXLC+PVj/m5fl8xuIlntWD/qtML18mMVRTQysyjUaKlp06RQX3Gg3tq1aTQa3d7ktrBl9PvDQ2UgH/qlV0XzUaGtvrpShdqOdus5FgU+7X6Ci1nLp8efYsS5jsJNMpSwCAEMIA4E0AfyulHArx+R4AewBgyZIlszw7hokfu8uOMkNgTsKgMaDHyTmJhUAsNULpSFuFqi1bvpx8ufxxuylC86Uv+WrDDAaKGnk8JFbq6mjl4unTJOxCeV4pRrZK6g+gfRXPsETmH0vqUIkwjY9Tr0+zmbYpET61mtK027fTwoC2NhKabjfw7ruU6rz7bl8ULpyHVywp5cZGKuC3WoFDh+hz/ybrQOBzt1ppTpWVvi4FRiPVwXH92MIm44JMCJELEmOvSin/JdQ+Usq9APYCQENDQwJ/ezHM7GLON8M55kRhns+XwDnmhDmfcxILAX+xpbQHcjgocqS81NPluB4sapqbZ57n1Cmqe/IXjJ/7HImvz3/eJ74UiwmbLXTXgUyYlPpHmEpLKRrV1UUCaMMG2kenI/Gl1ZJAUwRTbi5ZYyxfTp0DHA7yLPvoIxJp99/vi1LFsxJSuefKc1f55Z6CRbb/Popom5xMTIgvhM4EC4mMpiyFEALACwDOSin/ZybnwjCppLGyEQ63A0OeIUzKSQx5huBwO9BYyTmJhYAitnp7adWix0PiIC/Pl8KKp2YqGUKdp6eHekn6U11NKySDU4aNjbTKcc8e32pHJdVptQKbNiVnUhqt1i4YJcJ0xx10T00mEl8OBwnfkyd9/T0HBkgE9/aSAL31VmDzZuA//SdKx773HkXWliyhaOCzz/pSxomklEPV8AWL7Fj2iYV01CAymSXTEbLNAB4AcEoIcWJq2z9IKd/O4JwYJmksRRbsXLUT1i4repw9MOebsbV6K6+yXCAokaO2NorWAPTCbGqiOiOrlcRNuhuAKxEUpxO4epVWT65aRak8rTZwX6eTCuRDWUz4jxccNTp+PLIIs9moeL2lhcTPxo3Ajh20fyJ+XMERptJS4He/o5o3KSkF6HKRmWxbG0XExsYoKqYc89FHtCJ1fJyiZmo1jTM8TDVhO3ZQBK2xMTCyGC2lHEvEMJ6oYqQIWLS0OEfP5h4ZFWRSyg8BiEzOgWHShaXIwgJsnhLtZWexAJu22/DWBSvcKjtMWjM+v6oRJpMFk5PA2Ws2NJ+dskRZbcbdf5F6SxR/sbN6te/Fr0TgEkk1xuufZbMBL71EqxtLS0kwHTlCombXrsT8uIJTvX19dH0uF11LdzdF+yorqbD+9GkSwfn5FAn75BOKEnZ30/4nTlCqU0pKhTqdJPi0WrLwuOMOX2oxWiRLqeFTWklJSXMItU80IR5NrEaqQWTj2blJpiNkDMMwc4pYXna2QRuOD+3HmnojVONlEHlOtHn3o8SzE8NO4FLuflSNG1FmKINzzIn95/dj56qdKRVlkcROotG5eBciKKLVZPIV+qtUlEK0WqkhuMNBkamiIqC2liJasUSh+vqoduw//oMiXbW19Cyqqyk9OTBAthilpbSS0eMhMdbVRaljrZaiYwMDtPpSr6dUZ2EhpZk7O2l+Fy/SytHKShJy5eWUXo0UdRobA267LXw7qVgWL0QTq5FqENl4dm7CgoxhmDlBsNGupcAC27Bt1o13Y3nZKbYn9asLcewokC8KocsFTvZaMTIC1G00Ti/4UH5au6wpnX808ZRIP8R4FyLY7SROiot923Q6KqQ/f56sNnJyfD0ojx2jVGNVVfg5WCxUt7ZvH4m5iQmf8HG5fF0ClKiW4va/cyc1AFepaFtTEy1uGBujTgO5uVRjV1vr8wUzmeh+Xb5MKV+LhURepL6dqRJD0Z5fpNRnOINgNp7NbrLGh4xhGCYcwUa7nYOdePajZ9E52Dnrxrv+HlgKweaidpcdBo0BplKg6XNTbXWGDHDn2LFinR3V5YEDGDQG2F0JuJNGIFXF4/7EshDBv0i/vd3nYK+gOOgPDJC1xuSkrwelSkUpxlgac2/dSt5jmzaR6BGCxNnEBBnF1tYGXrPFQosB1q+nFOfKlbSwweWi+ZWU0H5jY2Qyq9ORsKqtpcUOixbRZ4WFJChbW4GPPwaeey6wkD7c9+PChfgWL0R7fpF829Lx7Jn0wxEyhmGyHn+jXQDodnajVFeKblc3lhUvS1uUKRSxRIn8bU9MpYCpFBjyOKHPpZ1mwxIlHZYUkeqfbDaqnfrTn0i8rFtHdVtvv+2r71q0iKJl9fUUkaquBgoKfLYgRUUkgqZTv2Fq9ZTo0eAgjanVUirS4SBRZzSSwPLvZ9ncTPM4f55EltlMQnDpUprPLbcAv/41icXr1ylK5/HQvoODPrNbZeVsfj6lL3t6AiNlob4fSrcEiyX2mq5Ynl+4KGcm7EiY5OEIGcMwWY8ScVIY9AzCqDVi0D04vS0dUaZQxBIlimR7MluWKPE438c7rr8Nhv9qydZWEhxqNQmzEyco0lRQQILm6lWKMt15J4kkJS14663AXXdRxGzlSjpPJFsHRfQIAXz2GYmdwUESe8XFdI6zZ+maN22ilaAjI74C/bY2qhFzuajQ/5ZbaPv69SQUXS4SeB4PiSmVioSaRkPHKga0Hg/Nzd8OI55uCZEsNJJ5ful69kx64QgZwzBZT7DRblFeERxuB4w64/Q+s2W8G8squWi2J9EsUVJlWRBLnVgqzqXUTY2PkyASgoTI9etUDD8xQXYXIyNUOK/4sEWK4kSqxWpspNWb3d103OQkCaiiIjr/5s0kChsbA8cpLCSH/pMnfU3IFy/21Zvdcgs905ISEpIaDY1//TqlLQsKqO6tvNzXXqqubmZtXizdEmKp6Uqkzi8VxzKZgQUZwzAZI7hQP1xhfmNlI/afp7e3QWNAuaEc7QPtWG1ajUk5CeeYEw63A1urZycnE8vLLpLtSaTPZtOyQDmX4nZ/7BilHXfv9rnbxyLUlBRiURGlAfV6EmGjo/S5ssJSq6XaMbs9urCNVNRusVCq0mKhsS9coH2VCNmyZSQIlfn7j2MyAdu20Th3303Xr7SG0mgoQnbTTSQuXS7fuDU15E/23HN0bFkZiTGTiY73T1nH0i2Ba7qYYFiQMQyTEZRCfaM2uv1DcMSpqqgKj1keg23YNi+Md/2jVO3tFLWZDcsCq5XE2JkzlIarqKCC9Z//HFi7luqrYhGFSgqxtpZEHUARqpwcnxXFuXMkxrRaipYBkYVttFo9KUlYqVRkPFtcTNscDqrzunCB0pKLF1M0bNmymeOEEoX19VT079/+SGltZLEADz/sE8wGQ/R+mADXdDGxwYKMYZiMEFyoH60wP1RUqRFzvxVVcETs2DF6WRcUBFo3pNKyQBGAb75JUSCz2RfFKi4m8bRoEdVUAdFFocVCNhReL60oVYrrly6lSNOVK7R9cpJSgd3dNIdIAlNJSyrWGRoNzfPBB+lzf8GmROYAOu+xY/TTYqGU6ZEj9Fl19UwxFG80K1Zj1+D7k+6uDMzchwUZwzAZwe6yo8wQmJMyaAzocSavPGJNhWYDwbVSZWW+voyRHOITvUZ/AVhVBfz5zyRmxvU2OAutcHjt6C8zo2+iEYBvvHCi0Gajovm6Oqq16umhyNgTT1DE7ZlnKFoFUCrwllt87aOitfhRVjYqSEnnUExlL12i865YAXzwAX1uMJAYm5ykNlHKPbx2jaJz0cRQMqsbw91v/+u7+24WYpkmW9tKsSBjGCYjKIX6YxNjaOtvw6BnELnqXKw1r01q3HhSoakg2f+4B9c41dYCR49SFGlyMrQgSOYa/QXgypXkXu9U2fDpyH5U5BmhcpehyOSETbcfvZ6dMOXReOFqnvzHU9KCQ0O+wv2bb6YVlKFSgJHq5axWGq++3nfc5csUidu6FVizhqJ6p0+TINu8mRYTvPsu3X9/MVZdTWJsz57ozyNcNAug6Fk8z3k+tTDKVhETL9n8TFiQMQyTERorG/HiiRdxceAiirXFyFPnoW+0DzecN2AbtCUsnuJNhSZDKv7jHlwrZTJR/da1a+HTW8lco78ANJnIguLl41Y4e43INxeipAoYGS2ER1JngW0Vlog1T9Ec5RNt8RNq3OvXfe2NAF9rJL3e1xS9tJRWQEYroI8kMIIjYIk+5/nSwiibRUy8ZPMzYR8yhmEygqXIgnJDOYxaI8a8Y9DmanHH0juwtHgprF0RDJqiEOxZBqTPo8z/P+6x+ksFE8q3Sq2m4nF/ry9/krnGYBf32lpg1UY71q82oKwMMJmB7duBu7ZTZ4FoPlbRXOEj+bZF6nrgP25vL/DRR8B779Gig97emftHup+hugmE8zgLRaLPOZauDnOBVHzPs4VsfiYcIWMYJiUkUtM0KSexbek2qIQqYFsydWTBnmVA+jzK4m22HYpECr6TucZQNVJFOWbUfdGJZRW+8YY8Tty52Yx718Q/XnDRfLjrixQ9828i3tpKItVgoMUOx45RL0qTaWb0K5b7GW+UJNHnHG/vz2wlFd/zbCGbnwkLMoZhkibRmqZ0iKdgz7J0epSl6j/u8Zp4xnqNIUWyxTJDsOy+uxHHh/ZjyBP/PYvWTilSQbu/mHO7qdn3jRtkZwHQuM89Rys1S0upFu3TT6mW7MoVsqfwX3kZ6/2MV2Ak+pzni92FENR5YXycVrTW1vpWvc41svmZcMqSYZik8a9pUgkVCvMKYdQao6Ye09FGSPEs0+fq0ePsgT5Xn7aC/ljSY+kglmsMbsju34A9uP1R4+rk7lmkdkqR0oKKmBsdBf7jP2jb9u2UIlVemitW0D633urzGtNofDYXwSsxYyHe5tuJPuf50MLIZiORPDBA1iWjo5Q6vnw5/d/zdJDNz0TIRL7NGaShoUG2tLRkehoMw/ixt2UvygxlIVOPexoiL22bSxYVocjW1WfNZ5sxMj6CwrxC9PaRjUb3wBDMRj0e/sK9Sc8x+LoVEab83tdHnmP+UaWhocACfGWc556j48rLKfqiuN8r3mhKkf5HH1H/SIDEQW2trw3SnXdGvvf+8xWCRMbSpYFRkkgv5mx9zummuZnu/9gYfYcGB6mbQV0d8NBDmZ7d3EAI8bGUsiHafpyyZBgmaZJJPUZqIzQXyNaegYrPW28fcOwokG8AyosN6HH1JL1CLnjVXUcH8NprZD2hmK++8w7whS8ECjL/tKDNRg7777xD4mjNGhJbSn1YSUlgeyOARJMSpamspH11Oio0VyJwoa4r1CpBKWkcxRg3FnPXbHzO6UZJ76pUPhsRxbaESS0syBiGSZpU1m2lO2I21yNysaKI5La2QuQbAL0OGPE6UWYww6hObpl/cFF8dzfVeHV3kxVFYSG9xE+dohSkgpIWVARSWxuZx7pcwNmzZPeRn0/b1671pRDz8sj49fJlmvNtt9E++fn0uf9cQl1XqCL+ZctmRuuYmWRzEfx8g2vIGIZJmlTVbUWqe0oF6R4/m1Dq87oHhpCXN4kR7xBcXgdq9Y1JL/O/cIEMWQ8epDTitWskeAYHffusW0eRr1B1V4pAGh+nCNeyZZR2/Ogj6qt59CgV7VssJNx0Omrs/aUvkRgYHqaxpCQxV1tL5wx3XdGsDmw2Ss3t3Us/w9lfLEQyVSe5EOEIGcMwKSEVqcd0m7rOpmlsqkg0oqeI5KtnrOhx9aDMYEadYStMeRYMDSUe4bDZqAF6Tg4V2bvdFBmTMjAypdXSakmleNo/Lfj22xRBKyqi4wEab3iYapX0ehrv5MnAyJbSCeDaNfp8ctJnfwGEj9xEivKk0vQ003Vm6Tg/9+GcPViQMQyTNaSzv2Ws42dTSjPZNlCWIgse/oKFBIcaMOT6IhyJLvO3Wqmg+8wZElM6HQmZS5eAhobAdk/RzGRra6kOrKuLxikqotqwpiZaSfnBBxQZ80dpg6TUlmk04VtMKUSyOkiVc3sqhF0ygiqdbvoLtX5utuGUJcMwWYNS9+RPKk1do42fbSnNRO1E/En1Mn+7nURRUxPVdg0MkIi67TZqVh7LOZQ0mEZD/3a5qCh/yRJfxMtgoNWQkewplNqygwfp+HDnjHQPUuXcnqybfbzdA1J9fibzZDxCJoT4JwBfBnBDSlmX6fkwTDaSTVGbdJJuU1dLgQX7PtkHr/TCnG9GpaESapV6evxsS2mmKmKYygiHEt0ymXypwlB2FqHwjwApXmKTkxRZW7zYl5IE6BwbN5JwAwIjWytX+qJBO3b4tkci3D1QrifY1mFtnD3uk3WzTzZSN5/c9Bcq2RAhexHAXZmeBMNkK9kWtUkn6TR1tQ3acLzrOCyFFnT1D6D50w/wq8N/gO10NTBM46eqD6Zt0Ibms83Y27IXzWebE35WyUYMUzUPfxIt8g6OAOn1ZHNx993Ut1Otnjnmjh2hI1s2W+qiQRYL8G//RgX9p06RMBsYoAUJ8RT3x2s2G0yykbpkz89knoxHyKSU7wshlmZ6HgyTrWQiapPJiFy6fMmsXVZ4J71o6+6Cp2cZVuvWwKMdwFHHW8h/cwN2fdUyLYDGvGNo62/DoHsQuepc1JljD95Hq/uKp06osbIRL514CfZRO8YmxqDJ0cCsM+PBDQ+GPsBvDgcvHsQ7l99BmaEM68zrpoV8sgI30SLvSBGge++NPGbw2MqiAH+iRYP877tKRYsC+vtpgYLXS9G+0VHg6lUymS0ri6+OLNmWPMnaS2RzSyAmNjIuyGJBCLEHwB4AWLJkSYZnwzCzS7oL3YNJtpA8W7G77LjuvI7BvnwU6vXI0wB5sgQDuI7eXCusVgsa/4IE0IX+CyjVlUKj1mDAPYBuZze1HAq6/lDCNZKAxrAl7sJrCRnx92CU59fW34YKQwWEELB2WdG0uGm6/izZ55hICjRcSu3cObKaCNfvMhTxihf/gne1Gnj/fapPy8+n1Z3XrwMbNtCigpERoLeXWjalu0m8P8kKKl4NOfeZE4JMSrkXwF6AWidleDoMM6ukowF3JLKtjipVmPPNOGo7ionRiunU0JgcRVGOGWO5dtjtFJ1bZFgE+6gdHq8HRXlFWL9kPTQ5mhnXH064Oj1OrDavDji3IqCt5+KrE7J2WbGseBnqy+untw15hiI+C+X5jXvHYdQap9tZtfW3ocnSlDYhH41QIqqjgyJUFkt8KwPjFS/+0bnWVl/tW2srcMst9NmVK0B9Pa3gdDhmp0l88LHJCipeDTm3mROCjGEWMukudA9mtiNys0VjZSMOXDwAb94APJ4SiNxReCZdWJR3EzTjZpinLllKiW1Lt4Xsy+lPOOF6dfBqWAEdb+F1Is9COaZIWwT3hBv6XD10OToMuAfSKuSjEUpEnT5NFhrxFrLHK1787/vgIAkwIeh/bjf1tDxxgqJjUlJRfybSfSyoFjYsyBgmy1EK3a1dVvQ4e2DON2Nr9da0RatmOyI3W1iKLNh982783LkPl69ch1lnxmL9TRgbU2PJRON0UXqs1x9OLBVri+FwO6Z/9xfQ1jhTbYk8C+WY2pJaHLMdA0CCMledO6vtrJRelS0tJHw2bgQ2baLtiohavpwsNPyJdWVgPOLFPzrnb0a7YgVZbqhU1FnA66Vzb98O3HUXiyNmdsm4IBNC/G8AdwAwCSFsAJ6UUr6Q2VkxTHYxmw24Ux2Ry7R7uT+Nlkb87O4KHDxlRcs5O4TLjNoSC0qXWfF299swD5thKbDgeNdxAJGvP9ICgLtq7gotoGNMtSkC6ELvBbQPtKNuUR2qjdUxPQvl+Rm1RjQubsSpG6dww3kD25Ztw46aHQm3s4qnptBmA156iVoslZZS1OnIERI7u3b5nn9z8+z0SfSPzq1Y4ash27KFBNnp0yQOV63K7PeTWdgIKedWSVZDQ4NsaWnJ9DQYZl6TqlWW/sXU/gIkFe7hqcBfbPiLr02Vm3Ci5wQ+6foEUkg0VDTgrpq7ZtSQ+S8AkJAYcA+gprgGuzbsmt43+F5aRCNsZy1hBWrwnDocHThtP43lxuVYZVoVW3Qqhatkm882Y2R8JCBKN+QZgj5Xj3vXhDYea24G3nuPCuj1eto2MkIRqK1bfX5ls/n9CLXKUsrM/5HAzH+EEB9LKRui7ZfxCBnDMMmRDouKVEXkUtWWJl2EqwM70XMCY94x3FZ927RQCxUVsg3bYBu2ocfVgxpjDbYu2RqwACBUdOm4ez92/kX46FLwnJYVk1vqteFrsLvs0y79kZ5PKiOqCdWx2cnPq7jYt02nI5sJf1+t2VwZmO76rGyKBDNzExZkDDOHyXaLimhF7JnyO1PO++aZN1FVVIWVpSth0tPSO4PGgA87PsRt1beFXWmq3HfPhAdNlU3weD1wjbmmj1fESiIrVoMFUK+rF632Vox7x/H5qs/P+jOOpY4tWIyoVOTE73b7ImSjo7QtOB05HwrZ09lHklk4sCBjmDlMui0q/GuZ+t39KNYWx5w2AyL7RSkpP3/T0zM3zuDBDQ+mVWj4i1hLkQWD7kEcsx1Dk6UJJr0JzjEnpJAhHfv9hZZ30otBzyA6hzph1BpRrC1GW38b1uasnRYriUSXggVQW38b1EKN0oLS6X6WyhxmQ5BFqykMJUa6u6nPZHe3r4ZsYACoqYnu6D8XyfZIMDM3YEHGMHOYdFpUKMLFO+nFpYFLUKvUcLgd0Ofq0TXc5XOejxDliuQXdfDiQVzovwCT3oRiXTHcE25c6L+AgxcPThfFpyNy5i9iV5WswrFrx6ASKlzou4BhzzBO20/D7rTjuWPPwTvphTZHixWlK7CyZCWqiqoAAOd7z+Oy4zJKdaVwepxwjjkx5B7CoGcQiwsXT4uV6cL/ianCfw8V/q81h2+UGCyAelw9yBE5qC2pnd5nNm1Ioq3yDSVGli2jmrHaWt8qy82bqRXSfBQo3EeSSQUsyBhmDpNOiwolCvRex3sYdA+iWFeMYm0xup3dWLto7XQtU6SUaaQaoZYTLSjVlUKfSzktfa4epbpSvHflPXi8nvhW9cWR+vQXsaZ8E5oWN+F8/3mc6z2HvpE+LC5YjBvOG7jkuAStWovFBYtxsvskrgxcwZNbnwQADLgHKGqVXwpdrg5dw13Ue3MisPdmY2UjXjzxIi4OXESxthh56jz0jfbhhvNGSOd/IFAAnbOfQ/9IPzQ5GrT1t9Gcp6J4s2lDEqkmLZwYcbmA3buBhx6ahQlmmGTbHjEMwIKMYeY06TSNvdB7AZcGLmHIM4RiXTHGJ8fR4eiAx+uZdnyPJWUarkZISBGyLZDdZY8rDRtvHV2wiDXlm6DJ0UBKifVl69F6oxWTchI1xTVweBzoc/fBUmiBWW+GbdiGRjRCBRUu9l/Ehb4LMOqMKNGWoERbguXFywPOaSmyoNxQjt7RXox5x1CkLcIdZXdAo57p/O+Psr1ruAvblm1Dq70VjlEHjnYexdpFa6FWqdNmDBwvLEa4jySTGliQMcwcJp2msf3ufqhVamrDMzmOPHUePCoPnGNOn/N8EinTjZUbcaTzCFRChXHvOK44rsA+YkeuKhfuCXdA1C/SmBF7R0799I+chROxJdoSuMfd+KT7E9gGbSjMK8Qi3SJIIbF+0Xr0j/bD7rLDNmhD32gfyg3lGJkYwaB7EMOeYWyu2oyVppUz5jcpJ2Ny/o90XQWaArT1t6HH1YNrw9fw8KaHs2LRBsBiBOA+kkxqYEHGMHOYeFcpxrO/4jhfnFeMjsEOeFQeTE5OQi3UPuf5LmvCKdMdNTvQ4+zB5YHLaOtrg16jx3LjcmhztHi/433csfSO6ZWPkcYMJwrP2s+i9UYrRaemFg203mjFrg27QorYAxcP4IPOD6BRaaDL0cHj9eDq8FVUFVRhdGIUmhwNzPlmWLusqFtUhzP2MzDnm+53ozwAACAASURBVKEr1aF/tB+2YRv+683/dcY9drgdONN7BuPecRRpi1BbUguNWhP1HgWnVk35pmkhly1iDGAxopDMalG2zGAAFmQMM2eJN1UX7/6rTKugz9Wj29kNj5ciYznqHCw1Lg04JtGUqaXIgl0bduG5488BAijLL5suXH/v6ns42XMS25ZuizpmuDq6DkcHRr2jKNWVokRXgtGJUVwcuIgDFw9g9y27Z1yzgICUEuWGcgx6BmEfsQMS8Hg96BvtQ01xDSwFFrxw4gWooEKOKgcer4eiedpCGPOM0/dDuccdjg683/E+dLk6WAotcI+78e6Vd7GyZCUe3PBgxPuTqRZWiYiD+WBdkSnYMoNRYEHGMHOUeC0vou0/w1G+wIKu4S6sXbQWTZamaWHkL8aSTZlaiixYUbwCn6/6fEBKb0vVFrR0tcQ0ZrgUpHPMibycPFwdvIqR8RHoc/UoyivCJ12fALfMHGdSTuL26tvRPtAOj9eD/Nx8jIyNYMw7hs1Vm7GhbAOOdx2HNkcLp8eJGyM34Bh1YH35elQaKlFVVDXjHne7urGkaAlUQgVdjg7Xhq+hb7QP5+znohq8KtfVN9KHLmcX7C471EKN3Rt3B+yXSi83FgezD1tmMAosyBhmjhJv/Vak/UN5gpl1ZnxxxRfJiT6CMErEFd5fRLQPtMM94Z52pAcAba4WX6z5YtjWPMHnDxaFK0tW4nenf4ceZw+KtEUoM5RhfHIclwYuYXHB4pDjmPPNGBkfwa2WW6e3+bcIaj7bDKPWiCpDFZqvNaMgrwBGrRFt/W2wu+x4zPIYPu3+NOAeD7oHYdQaMegZRG1pLfpH+7GyZCXcE26MjI9EjFBaiizYVLkJ+z7dhwnvBMoMZagwVOB413FUFFSE7QSQjGksi4PZJ1bLDE5rzn9YkDHMHCXelFak/cN5gpUZyvDQLan1LQgWEe4JN450HgEA5Ofm45T9FHqcPdi+bHtYa4hgpj2xpkxsD7QdgNfrhVqlhld6cW3oGsz5ZoxNjqEgryDkGNFWrCqCts/dh5tMN2HAMwDXmAsqqcLmqs2wDdtm3OMibREco45p4ZavyQeAgChaqIimIlj/ePGP0OfqUW+pn66nG/IMTR/jH5HrdfVOF/5fHbyaUOE/+2nNPrGsUuXI5cJAFX0XhmGykcbKRjjcDgx5hjApJzHkGcKVgSvoHenF3pa9aD7bDNugLeL+DrcDjZWNaLnu8wRTCdW0J1jL9ZaUz9tfRKiECsuKl2Fz1Wac7T2Ldy6/AwD4wvIvQJerw/7z+wOuIRyKyBsZH4HD40COKgfjchyFmkKoBYmy/pF+VBdVY0nRkpDHW7usGPYM47Oez3DOfg763EBPMUVsDXoGsciwCKtNq7HGvAY3V96MamM17C47LAUWvNfxHprPNuPPnX+GVq2dXpHpGHVgUk7CNeaarpUzaAywu+xhr0UIARVUOGY7ht6R3hnH2F12GDQG9Lp6cezaMXi8HpTll8Husk/fO9ugDc1nm0N+J4JRxIE/c8nCwmajxuZ799JPW/SvTsZpbKRVqUNDwOQk/XQ4Ajsa+EcuVSr6aTTSdmb+wBEyhpmjBKfqVEIFCQl9rj5kQ+xI9V7hPMGEFCmfd6jUabWxGmd6z+BLK78UEMEDYmsR5C/yFN+0ckM5RsdHYdQZ4RpzYRKTaFrcNO22r+AfsVtjXjMdGQuuxVIiaLnqXLjGXVAJFVxjLtQtqoNzzAmVUOF413HUmevQ5ezCDdcNqIUaD6x7AONyHGd6z0BComlxE0z54VeP+l+LUWukejZNPtr622aYwioiUYm+6XP1GBkfQXlBOYxaIw5ePBjSZHdT5SbYhm0z6s5SbWExm2m2uRpFimWVKkcuFwYsyBhmDuNfv9V8thm6XF1kk9Yw9V7+nmC6HB1GJ0Yx4B7A5qrNKZ+zOd+MDkcHul3dGHQPokhbhPL8cggppvtHKuk3h9sBKWXUQnV/kVekLYJ7wo2lRUtxoucElhQtgZQSk5iEWqVGY2VgM8VYF0cogvbAxQP40+U/YZFhERoXN0Kj1sDhdkCj1kyPo9TDDXmGMC7Hce+ae6cFnSZHg0k5GXb1qP+11JbU4ti1Y9Dl6uAYdeDywGWcvnEaK4pXoPlsMywFFhzvOo4eVw/K8sswMj4yLRINGgM+uPoBtizZEnBtfSN92PfJPmxdunVm3ZnFkjILi9kWSHO5/i3aKlU2310YsCBjmHlCMiatiidY72gv+kepVU9NcQ121OxI+TwtBRa8dvo1lOpKYdQa4Rh1oL2/HRsrNuLE9RM42nkUFwcuwqg1oqakBmUFZVEL1f1rt0w6Ew61H4J7wg19rh4OtwMj4yPYvmw77qq5a8YY8dw3S5EFu2/ZjR01O6YXJehz9dhavRVvt70dsSF5rCtSA65lqrXTyRsnMeQZwmn7adQtqkO1sRrOMSeOdx3HpspNuDp4Fd3ObpQXlKNuUR1MehOGPEMBIlfhuvM6vNIbVoCmysJitgXSfI4isfnuwiCqIBNCFAIwSynbg7avl1J+lraZMQwTF8n4VimeYOlq6O2PbdiGzVWb0e3sxqCHViGuNq1Gt7Mbh9oPYdw7DqPWiLHJMRzvOo5v1n0TRq0xYurS3yLifO95lOWXocfZg8K8QqhVanz3c99Fo6Ux5LGJ3LdQkcZYxollRWrw4gJNjga1JbWoM9eFjIDahm14eNPD02lXg8YwXR+4sXLjjDn1OHuwyLAo4JzpaFY+2wJpPkeR2Hx3YRBRkAkhvg7gFwBuCCFyAeySUiplhC8C2Jje6TFMGpin68eT7WuZiH1FIthddlQbqwNsLiblJN6+8DbWmtfitP00JjEJg8aAEl0JWntbccviWyIKBiX69Nzx5zAhJ2AptGDb0m0w5VOkSOlBGYpU9QNN1TjhImmRInDhjgFmGvfmqHNQaagMGCcdhrOzLZDmexSJzXfnP9EiZP8A4BYp5XUhxCYArwgh/kFK+S8AUl/tyzDpZq5W/sZAOvtappJwkaQR7wgshRaMToxi3DuOvJw8TMpJ2F32mARDOJPZaNGfVN23VN7/RCJw4QR18Jx237wbx7uOY8gzlPKG9P7MtkDiKBIz14kmyNRSyusAIKU8LoTYBuBfhRAWIGhJFjPnSaXjd9aShZW/qbzvqY5y+c9NCAEBgUk5OWOe8VxDuEhSnbkODrcDBbkF+LT/0+lVn6W60pgFQ6Jp21Tdt3RGGRONwIWaU0VBRdqFeyYEEkeRmLmMkDK8rhJC/BnAA/71Y0KIAgC/B3CblDIv/VMMpKGhQba0pN4baaHjv/Tf/z/2iTp+Zy1791JkTOVnwTc5SW+MPXtmfTqpuO/pEtL+c3OPu/FB5weQUuL26tuhzdFOzxNA3NcQas7Xh6/jB+/9AIOeQeSp89A72otB9yDqy+rx+JbHw9aAhZtz8FwAJHyfsuWPldmeR7ZcN8PMZYQQH0spG6LtFy1C9h0EpSallMNCiLsAfD2J+TFZRrx9EecsWVb5m+x9T3XrnHBza73RilJdKQCgfaB9ur2Q0o8xFd+dioIKFGuL0eHowCQmUV1UjQfWPYDygvKINWD+BKcNhRDIU+fh1c9eRftAe8AKxeD75C8+FE83KSWEELjhvIGlxUvjusfpEDOzVecHpPe7xTDMTCIKMinlyTDbxwG8qvwuhPhISnlrqH2jMSXufglADeB/SSl/ksg4THIkY5kwp8iyyt9k73s6hbT/3AY9gyjWFkNCwuF2zJhnPNcQ6kX/0omXICGhydHgnlX3wOP1wDXmQom+JO7voSJa/M+juPefsZ9BgaZg2pjVv7G6sq9apcb7He9DCIEtVVtwyn4KA6MDqCyshEqoojZlV3zO5rqYWTB/pDFMlpAqHzJtIgcJIdQA/h8AfwnABsAqhHhLSnkmRfNiYiQZy4Q5RZZV/iZ731MtpMM1/S7KK8LoxCgAMl4Nnmc81xDqRW8fpVZAZfll8Hg90OfqAQBt/W1Ya16b0PcwlHu/e8JNjvf5Jhg0Bpy1n0Xz2WYcaj8EbY4W9Yvq0T7QPt03sn2gHePecZTqSqed8oHApuz7z++Hd9KLLmcXjl07hgNtB1BTUoPFhYvntJhZMH+kMUyWkCpBlmiB/yYAF6WUlwBACPEagJ0AWJDNMqlasj8nCFH5m6lamWTveyqFdKSm3yuKVwTUkCk+V+GsFSJdw4XeC3B4qKdmkbYItSW1GJsYAwDUL6rHsWvHAAB56jx0D3djccHihL6Hodz7dTk6DLgHAAAdjg5cclxCVVEVVFBBQODYtWMYGR9BVVEVBAQG3APTYnTQPTg9tnKPrV1WeCe9OGM/g3xNPvJz8nGh/wIOXz6MO2vuRENFw3Q0bq6JmQXzRxrDZAmZbi6+GECn3++2qW3MLKPU3uhz9ehx9sxorDyf8W/mXGag9jOxNrVOlmTve6SG4fESrun3teFr8EovNldtxpYlW+Cd9AbMM55rsA3a0D7QjkE3GcJ6Jjw4ZjuGMe8YNDmaaWf6PHUeely0AjDR76EiKABqQeQac6F/tB8A8M7ld/DGmTfgnfRizDsGo84IlVAhX5MP17gL7gk3RidGUZRHgnHAPYBcde6Me2x32XG+7zy6hrvw6fVP8UHnB9SiSahxpPMIfn3y1zh08RB6R3rnnJhJ5XeLYZjoxBQhE0LcFJxGFELcIaV8V/k1wfOHOm5GtE0IsQfAHgBYsmRJgqdiojGbBcPZRKZrZZK576n0vgrX9Fubo8WehsgrUGO9BmuXFXWL6nDGfmY6YjU6PoqRiREsNS7FkGcIJfoSrM1ZC/2AHuWGcrzd9jbM+WZYCiwhG2KHwz/6WKIrwU3mm3D02lHccN6ANleL8Ylx3HDdwDuX3sHGio240HcB+lw98nPz0eHoQN9oH6oKqtDj7MHAyAC8Xi8OXDyAhoqGaZGoEip8cv0TLMpfBPeEGyqhwlXHVUhIuMfdKDeU4+rgVQyPDWNlyUo8uOHBGJ5EdjBXfO0YZr4Qa8rydSHEKwB+BqoX+xmABgBKIf8DCZ7fBqDK73cLgK7gnaSUewHsBcj2IsFzMUxIsqFWJpmUaaqE9GykqBSX/gJNAdr62zDgHkChthBLipbgW+u/hQMXD+DDjg/hHHNO91usNlajw9GB106/hs1Vm8OukgwmWFBUFVVhdGIUZ9VnUaorhVathWvchevO67jkuIQmy//f3rsHt3Wm6Z3PR5AgCF4AkoAokqAoSqJkWbRka0SxLY1ao7Hblmyn3XarqyaT7NqbGbumauNcap3ZnXRlZyuZmcpMd2224mQqkVOp8SQz1Zmow3KnW7Ld1qjdaluWKNutliiJpG6UwCtAErzgwhu+/ePVAQ7BA+IAOMABifdX5aIJnst3zkH3efxenrcLV8euQkapuWBb7TYsLi/ibuAuXHYXfmPrb8BWZos1NQCAhISt1IaF5QXML8+jtKQU4aUwqq3VaHW2oqK0Av6QH9vqtmFT1aaMn5Pe74fRqfdi/Y80hjEDvSnLLpBw+gxAD0g0HVb+KKW8nuH5ewC0CyHahBBWAL8F4EcZHothMkKd2lLIZ3rJzJSpGnWKanxuHOfuncOP+3+MidCEYWtR7rWr0oWnW57G8R3H8cSmJ+Cyu3D29lmcv3ce5WXlcNgccNqcuOG7gcnQJEaDo6ivqMfo3Gis01GZb7kWHocHr+x+BW8eeBOv7H4F96fuo9ZWC3uZHU3VND6ozFKG2/7bsFpoZuTRtqN4sf1FfOuxb8Hj8GB/435scWzBnak7q84rpcQLO15ANBrFUnQJ0WgU9jI7JCR21O1Aq7MVh1oO4djWY1jL83Et9H4/CuV7xDBMZugVZIsAwgAqQBGye1LKaLYnl1IuAfiHAD4EcBPA30gpe7M9LsOkg9m1Mom1W3rFhtEoEaXQYgjn7p0DADy77VlUlFUY9mLXutf3p+5jdG4Uvb5eNFQ1wCIs+NX4r2ApsaDSWomByYFYzdn0fLywvspaBV/Ql9b5pZAQjyollIYCa4kVoeVQrPYtKqOxmZHTkWnYSm2oKK3A9Pw0/CE/ro9fxw9v/BDdN7shhEBTTRN+q+O3cKTlCCqsFSgvLUdjVSNKS0oRXAiiva49K4Gv9/tRKN8jhmEyQ2/KsgfA+wA6AdQD+I9CiJNSypPZLkBKeQbAmWyPwzCZYnatjFkp02TpLZfdhRd3vrgidQlkXlOXeJ6DTQfhnfXG7vWmqk2wl9kxMjeCWlsthBBw2pwYnB7E3k17qdPR5kAgHIDT5owdN9bp6O3B6ZunMTQzhOaaZpzcfTKpq/+BxgO48OAChBCwldpQZilDbUUtvrnrm3hl9ysAVqZule5MABBC4JL3EkpECTwOD0KLIYzPjUNCoq22Dd/Y8Q3sdO3E597PEVwIIhAJwGax4RcPfwGLsOCN/W+kfe8A/d+PQki9MwyTOXoF2e9IKZV5RaMAXhZCZFo3xjAFh5m1MmbYC6zlwm7ki13Lp0sRJ4oAOnXlFKqsVTF7CXuZHa2OVlweuoye5R4IKdBc04zxuXE85noMURmNWWs4rA58/+L3UV9Rjy2OLQhEAvj+xe/j7aff1hRlx3ccx9jcGHxhH6bCU7CWWrGzbieO7zge20bdDLC9dnvMJLaytBIlogRRGcWuul2oKa/B1tqtCC+GYx2mLY4WvLr7VYzMjuDdr95FeCmMhqoGNFY14vLwZTRWN6b9PdP7/Uj3e8RjkRimsNCVslSJMfVn/8X45TBM8ZGYxrs3dQ+f3P8E/f5+dN/szkkN0FrpLSNr6tQ+XYvLi7FU3rtfvRu7LnelG4OBQcxEZtAz3IOro1fhD/phERYsLC3AbXejurwaj7keW2WtceHhBdRX1KPeXg9LiQX19nrUV9Tj9M3TmuvxODx47cnXcLT1KJ7c/CSOth7Fa0++tkKIqG08lqPLOLLlCA63HMbw7DBG5kYQXgzji5Ev8OHAh/j0waf4YvgLdDZ1xurUAOD0zdNYWl7C5urN2Fm/E221bRmnD/Wm1NNJvXO9GcMUHkYZwzIMkyHqlOlN303cDdxdc+aiEawVBXuh/QW898v3cDdwF0PTQ1iQC9hctRn/tOufah5rrUiLL+jD8NwwKq2VMff92opajMyOxMTJwMQA/qb3b+Cyu9BW04ax0Bh6fb3obOrE89ufjxmrzszPwF5mj4keABiaGcIWx0orHKfNiQfTD5Jeu55oaOI23mkvzt8/j4nwBALhAPxhPxzlDux27UZleWXsGQFkkusP+bG5anPMZ63L04W6ijrNKGOqSJXelHo6qXezrV4YhlkNCzKGyTVeL41q8vloVFNn56pJAYoA6L7ZjRZHS85flKnSW4FIAHen7qKkpARVZVVYWFrAR3c+WpVySzWA2l3pxqWhS2isaozt4wv6EIgE8JdX/xJnb5/FcnQZT21+CmPBMdybuYe9m/bCYXOgrbYtJsYA7bRpc00zApEA6u31sc8CkQCaa4z1l/7g9gdYXFrE4vIigotBlFnKMBWZQv9EP15/6nVYLdYVg9bVI6Bm52fx4/4fw1HugLvSDe+0d8VAcz0zL/Wm1PVul+96M06PMkxqzHbqZ5h1j3fai+6b3Th15dTKFKPXC7z7LvD7vw988glgsQChEA0392qnhnxBX6zDTyGTbsJUaKZJBz9Bn78P71x+B5PhSexv3I9DnkPYt3kfWp2t8IV96BnuWXG971x+B8vR5aSdfZ1NnbAICybDk4jKKMbmxnDTfzN2jaWiFLcnb8NWZsO+zfvQ2dSJmvIatNW2rRIHWmnTk7tPYiI8gYnQBJajy5gITWAiPIGTu7PuN1rBlZEraHG04IlNT2BJLkFAwF5qhygRcNldsWekPD9lMsDY7BgGA4PwBX0os5Shubp5RWrQrM7IfFq9cHqUYfTBgoxhsiDpy+ZWDwmv3l6goYHEWE8PsLAAOJ307xrk60WprpO65buF6+PX0eHuwG73bvhDfgxMDGBxeTG2va3UhoWlBfT5+1Zcry/oQ6+vF/6gP7atWkB6HB68sf8NLMkljMyOwB/yo83ZBnuZHdXWatRV1MFhc2BwehAAYvYSTVVNKLWUrqqH8lR7VojfxupGvP3026gur8aD6QeoLq9OWtCfDUIKSEjUlNdge+12tDha0FTdBFupDUD8Gal91rqauzARnkBkOQJ3pRtfa/5arJbs7O2z6L7ZjR/e+CGujV9Lev9yRT6tXtiOg2H0wSlLM9CRwmLWB0lrcT4/DY9zL7C4CNTWAuLRlLCBAaCrCxjTTg3lc8i7Ok3qcXhia2+obMDQzBDuB+5j3+Z9AIDIUgTWUiumIlMrUqqbqzcjEA5gYHIgll5MFJCdnk40VjeiZ7gHf3n1LzG7MAsACC4EMR4cR6ujFVfHriK0GEJURlFmKYOlxII3nnpjhT3GzrqduDx8WTO996ff+FND701iim1r7Vbc9N9EiShBY1Ujro9fx1J0CR2bOpIOWq+z18FZ4YTL7sLXWr4Gl53uT2QxgvP3zuPFnS+ixdGC6cg0Lg1dQldzF1yVrryYEufT6oXtOBhGHyzI8o3XS5ETp5MiJ3Nz9PvLL7MoW4ckfdlMDQHbDgEOBxAOA3Y7YLMBgQA9c7f2C9cMT7TEa2iva8eN8Ru44b+B0GIIFWUVKLeU46nNT6G0pHRFSrW9rh2fP/wcY8GxFXYUiQJSWf/Z22dRKkpRV1GH8blx3PDdQJuzDXs37cWyXMb43DiOtR3DiR0n4HF40Il4xKb7ZndeCtG16rqWlpfgrnBjUS5iKbqENmcbwkthbHFsgb3MvuIZqZ+fy+5Cc3VzTIwBwDXfNWyq2oSa8hrsrN8Z8zbrm+yDtdSaUoAbVY+VL6sXM2xdGGY9woIs3/T0kBirefR/TsrPnh4WZOuQpC+b2mYSXu3twKVL9AcpgbIyEmVHk79w8+2JpnUNZaVlaKlpQWlJKUJLIVRbq/Hc9ufgnfWu2NZld2HPpj0Ymh3S1dnX4abB4uGlMNxVbmxb3oaR2RF4ajyIIop9DftWiBc1+Yq0fHD7AwxMUspWcfNX/Mbq7fUphZD6+SnibmZ+JhbxHJsbw7PbngVA96/L04X+iX48nH6IruauNQW43iaAQiqiz2fUl2HWMyzI8o3PR5ExNVVVSVNYTGGT9GXztZPAucskvjs7gWvX6Bk/8wxw/HhBie/Ea7g6fhX2Mjte2PdCTBzNzM/AO+vVvF5LiQVvHXwr5Qs/Nli8nAaLK92QzdXNVDcV9mFwehAjwRHcGL+xyh8s00hLOuLEO+3FuXvn0FjVCKfNichSBJe8l9DZ3ImojK6w3NCDVsTzmbZnYrVnAIkyq8WKg80HUx5fj12FXtGWL8yehMEw6wUWZPnG7abISY1qLM0aKSymsFnzZVPVSJHPYJAiYgVaK5h4DZGlCL7e+vUVkSolEpXNyzVW8G53rRB6nz74FMNzw3DZXaitqEVkKYL+yX58cPsD/O6v/W5sf7UYjCxFcG38WizFqbaSUJOuOOkZ7kFDVQOEECgRJTHvtGvj1zKO6Gh5miWLGKUSj3qihIXoMWbmJAyGWS+wIMs3nZ1UMwZQZGxuLmUKiylskr5sPB7dAkxvFCdXqSj1NXTf7EZoMbTi74OBQQzNDuHUlVMZnzdZNHF2fhbuSndM/NjL7KivqMeVkSv4XcQFmSIGP7j9Ac7dO4eGqgaKNpXZkoqsdMWJL+jDE+4nYh2AFaUViMooxufGDetATCZqASQVj8qavxr5CuVl5StSu4lRQi6iZ5j1CQuyfOPxUAF/Tw+lsNxuEmMFGDlZE+4UNYx06oLykYpKFE6DgUF8+vBTHG45nNV5kwmR62PXISFXbCshIaTQPEa9vR4v7XxJ1/DzdMWJu9KN0GIIXc1dGJgcwFRkCmWWMhxrO2boPdYS8VpNCxOhCfzJhT/BVGQKDVUN2Fa7Db3+Xvzs/s/w9davw1ZqW1WPZVQRfSHVoTFMMcCCzAzSiJwUJFqdou+9B2zaRIXruRJoG1QE6o3i5CsVlSichmaHcLjlMNpq27I+r5YQ2d+0H58+/BQlogQVpRUIL4UxFZnC4ZbDmsdQRJY/5MfA5ACmI9PkbVXuXLVtuuJEEaNOmxNdnq5YFO/EjhOrts1WsCTu3+/vx2Pux2J/94f86B3vxe3AbezbtA9CCNyZuoMnXE/g4dxD9Az34Pntz69KGRtRRF9odWgMUwywMSyTPupO0ZISMjvt74+boKZwo88IRQSGQrk7h0nodef3BX2ILEVw0XsRH9z+ABe9FxFZiuTERNTj8OCV3a/gzQNvYnvtdrQ6W1OuL1NO7DiBHbU7sCyXMRmexLJcxo7aHZoiCIgPI7/kvYT5pXk4bU5MR6ZxZ+rOKvf3dA1Q1Ya56iHmiSIkW/d5rf3vTN3BYGAwts3A5AAsJRaUlZShoqwC9jI7Kq2VmIhM4NjWY9i/eT9e2f1K0pmWqa5hLdjMlWHyD0fImPRJ7BQdGADq64H5eRJoubDyMNMuJMeROb1RnBJRgp8P/hwuuyvWAfjzGx/gSNgFfHkqZ1HDXPtIeRwevP7k67qjTZ1NnTE/MyWiFpVRdGzqwNnbZ+Gyu1YcR6k7u/DgAoQU2N+0P+V6UomXbKOVWvt3bOrAdd911NvrUWWtwujsKMosZdhRuwORpQjsZXZUlFZgKjKV8v5nW0TPdWgMk39YkDHpk9gpOj0NWK1kgqpgtJWHHruQXAinPBj56k0xSUiIR47/AgKYm4V48ACypgZoMX5tSkqtz9+Hu4G76HB3oNXZmnR96dpLJG6r11LC4/Bgm3MbAvMBPJh+gOBCEFXWKtzy38LA5AD2bNqDhaUFWEut6B3vxfPbn8f88jyObDkSu7/v972Pg00H4Z31aq7XiG7HtdDav9XZitBiKBbZcle60VzdjOryalzykpedMskg1z5eTExN/QAAIABJREFUhWbmyvVsTDHAKUsmfTo7qTN0ZgaIRsnsdGqKTFAVjLbyUESgGvU5cpXSTEzP1tSsOYsyE/SmmKSUONJyBOWWckxFplA+NoEjjr2Qdpvha1On1Ha7d6PD3YHr49dxy3dLc33ppPCMGDa9y7ULTVVNsJfZsbV2K1ocLegd78X9wH2EFkKoq6iDRVhwe+o2/vNX/3lV+m05uox3v3pXcw161pftzNFk++9y7Yqlit86+BYsJRZYLVZ0NndiWS5jbG4Me9x7cl7Llc9Zl6ng4eRMscARMiZ9EjtFOzqA0VGKkkWjubHySGUXkquUZqrInEFROT0pJqUD8OmWp+mDOx9gptoKu6VCe20Z4p324p3L78Af8qOhsgHtde1oq21Dvb0e9jK7ZiQrnRSeEc0JnU2dODtwFqUlpbCV2hBeCsMX8qG5ujnWkWgvsyMqo/hy+Escbz++Yv/huWEsLS9prgFAyvVlWzivZ391c0VwIYijrUfzFhkqJDPXQvRVY5hcwIKMyYzETlFFmOTKyiOVXYginPx+qmmbno5HjNTrS1c4rWXkm+e5pKte4lVlCISmcLRh7+q1ZYgSjfAFfdhctRnzy/Oxwdd19rqkKbl0UnhG1Cd5HB5sr92OwHwAgUgADpuD5kNaaxBaDGFmfgbDs8OYDE1ien4ag4HBWJeonjVYhAW9472Ynp+Go9yB7bXbEVwIrjh/NoJF7/5mGqoWipkr17MxxQILMsYY8mHlsdY53G5gcBC4cQOorCSRNDUFTEyQELt8OTPhtFZkLs+NBqte4js7cPSLUXjmrUCZ/sjkWvU4SjRic/VmzC/Nx8xaByYHsKd0T9KUXDo1R0bVJ+107URoMRQ7zkxkBlfHrsJWakOfvw8logQSErvqd+HTh58CoDqtwcAgHgQeYG5hDkIItNe1w2V3xdbgD/lx4eEF1FfUo9ZWi/BSGBceXlhlw5GtYMlk/2KspSq0ejaGyRVcQ1YMeL1Adzdw6hT93ABWEavo7ASuX6daqooKIBKh9GlHB3D6dOZ1YEpkzm6nyJzdHhdyPh+JNDVVVfR5jlDbUbzy678Lz7df115bElLV4ygWHO117QguBBFaDKHcUo6x4NiaNUTp1BwZVZ+UeJyd9TvhKHdASoml6BJKS0rRXN2M4zuO43DLYQzNDuGm7yau+67j17f8Opw2JwLhAD5/+DnuTd2LrUFAIDgfxMDkAL4c+RIDkwMIzgchIOCd9qL7ZjdOXTmF7pvdea1jKtZaqkKqZ2OYXMIRso1OntNqq86dTX2Vsn9fH0W76uqAnTu1j+PxANu2UYRoaoo6Pjs6aJ/Ll4FDh1Zun06tVbLIXCHMJU0zMpmqHkc9b7LLQ271o7OjcFe61ywkTyeFZ1R9UuJxWhwt+MOjf4h/e+nfwhf2YSG6AIfNAQiKjNlKbXBXutHiaEFNeQ22BLdgYHIAY0Eyv1UGpE+EJmC1WDEfnY+dy2qx4s7kHU2z1LW6NY2kWGupCqmejWFyiWmCTAjxHQD/D4DdAA5KKa+YtZYNjVn+XdkKQWX/5WXg3j3AYiGxVVEBDA9rH2fXLuquVAukmRmguTk3wmkdziVdUY8zQfV2VYEAxiqjQHXnijq1uoo67HHvQXN1Mw42HUTPcA/ODJxJKjrSScEZVZ+kNbi7oqwC28q3xQaVX/JewuPux9HiaFlx/a5KF1yVLkRlNDY4HQAmI5Nw2BzYVrctdtyJ0ARu+W+ho6Fj1Wijd796F0dbj+bc0b6Ya6kKpZ6NYXKJmSnL6wBeBfBzE9ew8TEhrQYge7sIZf/RUVpvfT39HB1NfpxEO46ZGfr95EntzzuzTHmslc4sUGJ2CxN+4PNLwPw85mrK4V6yAe+/D88sVllwHGw6iMvDl9dMlZmZylPTM9yDjk0diMooIksRVJRWILQYwv/s/5/o8/etcsP3B/04f/88vhz9MrbuWlstluUyQoshSCkRWgxhWS4DwKqJCupuzVw72mdrtcEwTGFjWoRMSnkTQMzokskRZqXV9Bi56tl/ehqoraXPbDYSUspxtFKiyToxGxtTd4FmkmJdZ3NJYxGwWwOoqrRjzgoElsM46uoC5q1ATw88r6wcx6M19BqIp8oKae6hL+hDq7MV1dZqDEwO4OH0Q4zOjaLWVovd7t2xQekAUFlWiQsPL0BKia+3fj0mNBV7j9G5UUxFpuAod6DV3QqnzbmquDyfUSsjZlQyDFO4cA3ZRsestFq2QlDZ3+EAwmGKPkUi9PvcHCBE8pToKxqO76mEU75q7UwekB6rx7n4xxirEnCXOHG0qgOechd1amoI5lSiI93apkw7BfXsF6uBe5SOvPjwIiqtlXBWOFEiSmLWF0OzQ5iJzMBpc2Jfwz647K7YMcKLYVhKLNizac8K4XNy90lcHr4cu/65hTlYhAWNVY0r1pCrqBXXUjHMxiangkwI8TGAzRp/+q6U8v00jvMmgDcBYMuWLQatrkhI5d+VK7IVgsr+mzfT0PJwmOrJWlvpOOXl2dXGJQojvz/3tXZmNlio8Dg88Gx5bnW9XRLBnMp2IJ0oUabRNL37JUaRxoJjKBWlaK+LT5FQCvwBoKGqASUiXrlRZa1CcCGYVPg0Vjeu+PyN/W/g8vBlzMzP5CVqxbVUDLNxyakgk1I+a9BxTgE4BQAHDhyQRhyzqDAjrZatEFTvHwrFuyxbWkisnTmjXRunJyWqJYzOnweeeWalQDF6HqeZA9ITSUMwp0qVpeMTlWmnoN79EqNILrsLzdXNKyJg6rUlW3cy4aP1eaJI46gVwzCZwClLJndkKwRTGcHqTYmmioYtLFCh/1//NdDVRTM5XS7ja+2yratLvA6Phz7LJP2ZhmBOlSpLp7Yp05qrdPZTiyYlspYsgmVETRZHrYyjGI1vGUbBTNuLVwC8A8AN4CdCiF9KKZ83az3MOkNvhCdVNMzvBy5doqL/vj46xuefA3v2kNWGkbV22dTVJV7H4CDwgx8Ahw9TGjeT9KeG4E32QlxLdKRT25Sp63qm+6VaG9dkFQ6F1BzCMGYgpFxfGcADBw7IK1fYsiwpJheN5xU919rdvbpW6tw5+vnMM8DFi8D8IwPQ+XnabnSUjvfWW9r3LtN7rBZVahG5lohSzvXhh9Rlum8fRe8uXqR9nU7g6UfDxmdmqPlBq6lBB+oXojpiZOQLMdNz5GNtjLl03+xeMQoLAGbmZ5IOtGeY9YIQ4gsp5YFU23HKcr2jFgdCAOPjwNatphaN5w09KVGtNOETTwAffxz3Iysvp6aBri4SO9FH3YbJxFimhfnp1tWpz1VSQs/30iVa5/Q0fT49Hd8+y5q3fDjBZ9opqHc/TnmtX4rZ+JZhABZk65tEcXD+PBW/NzXFzVgBc4rGCyVSp5UmtNkoOma3A7OzwIMH1DAwMEB/t1qTpxGzLcxPp65OfS6nkyJ4lZW0TocjHiFTyLLmLScvRI3vgceTWc1VqlotTnmtb3iIOFPssCBbzySKg8VFcrQfGKBID2B8p6AekkWRDh6kv6WaTWmkmEtWa/byy/RZby9w+zaZz0YiwM9+Rmt67TXt42VbmJ8O6nO1t1N0zG6n9T/2GHDnDv2MRg3xlzP8hZhnm49infW4UWDjW6bYYUG2nkkUB4qJqjqNle9h14B2FGliAnj3XRr4fe8erfOrr4AvvwTOngXeeIPEU08Pbbe8TOuORJLPrtQiHff+7m6grY1mXQ4MxKcCbNqUurtzYYH2GRqia6utNT4SqI7uuVyUqrx6FZCS7D/efpuu1yB/OcNfiHm2+eCU1/qGjW+ZYocF2XomMR3X3g588gm9BA2KmmSEVhRpZIRE1ugoCYrxcaC0lD4rLSURBtDP0lISReEwcOMG8Pjj+l7iiRGZX/4S+PM/B6qr6d6cPLlyfqWyzpKSeEQxqu1WH6OzE3jvPaC/n1KbDx8CS0skhh8+TE88piIxume10nWoj584jzOL6KLhL8R8RhPBKa+NAFuIMMUMC7JCRO9LVeuFvWMHudvn05U/Ea26rbExElnT08DkJNVxWa1AMEipy5ER4PRp+vvyMtk62O0UeRoepu1T3Rd1RKa/H/jpT2k/IahW7Pvfp6iSImIysaHweOg6fD5KvVZVURNFWRmJzT17jIsAZdMEkGGK0NAXYp7nqHLKi2GY9QwLskIjnZeq1gv79dfN76jUqtsqLaVmg9FREku1tZT2s9spEuZ20+fKtlVV9Pe+PopAeb3AlSuU8kzmu6WOyHz2GUXGqqtJ9NXX0+enT8cFWabjnaQEjh2jmr3aWhJ80Wh88PnNm5QO1ROlSiUyM20CAMxt6gDyPkeVU14Mw6xnWJAVGum+VM0Yi5QKLaH4xhvA5csUvROComQWC0WbgkFKS/b10d8fPiTD1nCYftbUAE8+STYVP/kJbdPcTD/V90UdkZmYoN+npyk69uWXFC0bHV17nXoiimsNPh8cBO7epRqvVILa6KL3PKcIU2LCHFVOeTEMs15hQVZoFNpLNVMUoahEgL76ilKUQgD79wOffkpRpQcPSFzNzgK7dpEYW1igKNTsLEXLKiro+ufmqN4rGCQLiN5eMn1VUEdklFTn1BSJo8pKEoFC0JoUUZCJoF1r8Pn16xTF0yOojY5o5TlFqItC/A8GhmGYAoQFWaFRiC/VTNGKAAUCwLe/TSLT7yfxZbWSANuxgwRpfT0JnGiU6ssqKuhYtbXxFKSS6pyaWnnO8nLgwgUSXiMjNBKppobEXSQCfOMbccHj9VKH55df0vkPHACOH0/P4DVx8Hk4TMJMTTJBbbT4znOKkGEYhjEOFmSFhlEv1VwZs6Zz3GQRoNOngb17aQyQwswMiZtQiIRZRQVw7Rpdf2srdWUqnaN2O223vExCSFmXIv5OnKDtZmcpLaqIvGefpWOPjdH2f/EXcQ8yIUjIjY2RB5keUaa1TXe3fkGtV3zrvedaKcKdO+n3M2c2/igthmGYdQwLskLDiLqbXBlypnvcZBGgoSHg0KHVnweD5KB//TqJ0C1b4l2XTU3x6FFlJUXCWlspKgXExd/CAhmoTk/TNg0NwLe+FT/PzAzd054eitDV15PAA0iU+XxrpwwVcZTM3DYdQa1n23TvuVoo5tmYlWEYhskcFmSFSLZ1N7nqttNzXHU0584dShO2tcWPMTdHNWPJIkOdnVQfpgzgHhwkgbZrFxXqv/hivMsyEIh3TPp8FA3r6SHBpoizr76iSJx6n6NHKWK0sBCPsAFU9D81RcfSikoBJGj8fqqBm58n0ZdoXqtXUOvZNptnWWhdlwzDMExSWJBtRNSRKb+fHOUDAUr5ZZOySlXzlBiRiURIuAArBdHJk9RxqeyvFkqJIqWlBXj11ZUNAlrixe0mU9zKynjEq6aGxNjQEIkt9T5uN9WuKV2SAK3XaqXGAa3IktVK0brPPiPx19BAadHPPiOhqAiddAR1qm2zeZYbpUGEYRimCGBBthFRj/e5dCme4pMyu5RVqpqnxIiMEhnTEkSNjenXOq0lXjo7gf/+30mASElCKxik1OjyMvDmm6u3V+ZYRqOUrpyYoHVIqR1Z+sUvyNoiGqWfQlCTwdRU3LzWaLSe5cIC2Xf8s39GKd5kjQgbqUGEYRhmg8OCbCOi1CYNDMSjP+EwzUK0WjNPWaWqedKKyLS2klBJFERr1ToNDlL34/bt2sPHtfB4yKy1t5cEksNB9hNWa/weJG7/+usruyyPHCFxc+YMXZ+aqiraxuejYy8skMhdWKDf792jv586lVxQZtJokfgsZ2eBW7fIt62qitK58/PaIpu7LhmGYdYNLMg2Ikra74//mKI4TieJE5cr9axGPcddK22oNyKTWGvW3Ez7+f00v7K0lMTDw4ckmrZtozqytUTMiRMkkJT6M7UASSaG3nhj9XGSXceBA5Rqtdup63Nhge5nZSUd//Dh5MXzmQ5NT3yWExMkxhoa4tMBnE5tkW2CMSuTPt5pL3qGe+AL+uCudKOzqZPNbRmmCGFBtlHxeIDnniN7CCNTVqnShnoiMokRsUuXaLvqauCLL0ioLC1RVM/joc8DAbqWVB2GWgIESK/bUH0dkQjZb4yNUXrwm98EfvQjiootLtIMy8lJutdKijaxeN7rzW5ouvpZfvYZ2XQoa3M41q4Ly7ZBJFf2KQwAEmPv970Pp82JhqoGzC3M4f2+9/HyrpdZlDFMkcGCbCOT75SVWhDdukVCpbaWflf+DqyuNWtooHV98QXwq1/RPmVlJAKGhii6Nzurr0tQS4B0d+vvNlQEyNwcpQOHh0loPfsspV4HBymq5vXGRUpfH7B798rjqEVSTw8JTLebolxKCjWdujPlWZaVUW2cMrGgoyN3dWFsm5FzeoZ74LQ5UVNO30nlZ89wDwsyhikyWJBtZDwe4OBBMmIdGqK04MmTuXuZKmKmv5/SkMkGgSfWmtXX0+DwBw8oGmaxUH1WWRnt+8knZOjq95NNRTrDuwF93aGKt9jdu7Tuxx4jp//aWurUdLlWXucrr8R/T2UGq5w/EomLsYoKOn5Xl757q4jds2eB8+cp0tbZSTVyuRLZbJuRc3xBHxqqVn43q6xVGJvjTliGKTZYkG1kvF6qedq7l7oN5+bo98bG7F+oiaksj4eO7XSSQCgtpbRcdXVczCiRsjt3KE3Z0EBibGCA5kKOj5MQGx2Nz7Wcm6PUoNsNnDsHtLeTuEw1vFuPH5piEKvUdk1O0nqVdS8ukiAbGIhfg1Z6MFUkUqkZu3GDflf8ziyWuL+ZHpSatxMn4tdmt+euLoxtM3KOu9KNuYW5WGQMAOYW5uCu5E5Yhik2WJBtZHIV4dBKZb37bnyo9swMCZlIJC5mqqoosjU8TJG6QID+uXKFxJjdTl2OViulJ3t6aP9olPavrKR04eAg8J3vpDan1eOHtnPnytquBw+oTqu1ldbtcNC+09Pxa9dKD6Yqnu/spOt+/HGKio2M0DmVhoJ0on3K+bS2MbreS225MTBA96GsjJ4zYwidTZ14v4/EfJW1CnMLcwhEAjjayp2wDFNsmCbIhBDfA/B3ACwAuAPgf5NSBsxaz4bD6wU++ijeZdneHhdG2UY4tITe8jKlKkdHKSJltQJbt5KgAejFPjVFka2aGopADQzQ53NzZFkBUORMGaNUU0N/U1KXTidF0VIN79brh5ZY2+V00nkmJ+mcBw4AP/sZiUtljmay9OBaxfNqwWazURpZ7fxvRI1WLuq9OjuB996j51pfT890aoqesdfLaUsD8Dg8eHnXy+gZ7sHY3BjclW4cbT3K9WMMU4SYGSH7KYA/kFIuCSH+FMAfAPg/TVzPxkF5OZeXU/H3/DwJHcWHLNsCcK1Uls1GRfmHDpH46+2lsUV791LELBCg+i/F38vlittwjI/HU4JdXRTNmpmhqNiuXRRNikQokrawkNpaQ68f2pkzK2u7GhtJfPh8dA1WK0XRNm3SbxuRLEqVbbNBKnIRDfV46Np9PvoOORz0PLPxsmNW4XF4WIAxDIMSs04spfxISrn06NfPAfD/IxmF8nLet49ScAAVkV+9unL+Y6YoqSw1kUi8Y9DhoCL80lISVnY7RWp27ly9X1NTfLtoND666OhRikyVlsY/u32brCcCgfj2ithTX5PW+rRSjW43ibBgkO5TdXV8pJLTSet+7TVKLb7wAu1z5gwJKa939X1RhHAoREJPsenQ2hYgoaNlQOvzaW+/FkYeS42UFL08fhx4+ul4lDXb4zIMwzArKJQasn8A4L+ZvYiCR2+NkBIhKimhiJN6/mGqFJaec2gVsYfDJFqmpugfl4vOvby8siMxcT+LJW4joUShtm2jnz/5CRX2h8Mk9mprgd/+bdp/LbNTvXYfWrVdFRXAn/zJSoGnNx2YbpTKyNFGuRqTxOOXGIZh8oKQUubu4EJ8DGCzxp++K6V8/9E23wVwAMCrMslihBBvAngTALZs2fJrg4ODOVrxGphtkKkWBWqRoSWwurtXG8IqkSq1OMrmHIn3w++n46c6p5772N1NQqynhwrJl5ZI2NXXA3/2Z/ruu97npdUtqvYY6+ykv+u5n6dOxYUwQPekv5882TZvpvtZWUm1aceP0zZ/8Re03cICReZcLhrplG7RfjrPLh1ydVyGYZgiQQjxhZTyQMrtcinIUp5ciNcA/B6AZ6SUIT37HDhwQF65ciW3C0ukEF5K6YisTNebqZDL5pzKvomiSOl+VLo1g0GKZLW0pF5LpiS7hrk58iUrUWX4lRFU6po09f3z+6luLxgE7t+npoHSUprPubBA6dvnnqPGC58vLsjcbkqTagngVPc3V//RYPZ/jDAMw6xj9AoyM7ssj4OK+I/qFWOmUQgGmel4QmU6w1DrHJEI8ItfpH4Zq8958ybZUyhu9/v3k3dWsqhPYjrw8mWKhgEkOpRB4XV1ufXASvacHzzQl7ZTp0r7+0nAjY9TurWykj4fHqY07d/+LVl+HDtGhfIKMzPa3ys938FsxyQlI1fHZRiGYWKYWUP27wCUA/ipEAIAPpdS/p6J60lOIRhkplvLk8lLNPEcfj9w4YJ+KwXlsxs3KFLkdlNR+Kef0r3SSsWtJYL27l0drcukdind2ju/P+67VVNDwirwyJEl1Qiq8nK6ZzdvAnv2UKrS56PoVyhEQnX7dvp9fJy6UdXmucm+V4XwHWQYhmFyhmmCTEq5w6xzp00hFDbnYy5l4jmuXiVBtW8fiRI9kUFF+Lhc8TFBJSUkcrT2SyY06ur0i6C1SMefy+0mwXTjBkW0nE5qUFhaAl59dWXjQWLEUX2eEycoKqYMTJ+aopTk+DjdEyHI56ymhtKZg4MURVSsNrS+V0Z/BzkNyTAMU1AUSpdlYZPvId2A9gszkzRkOiSmOiMR4Otfj0dv/H6a96jYOGi9xJV6qNra+GcVFWS2qmWVkExo7NwZL6jP5nrTSTd7PMCf/zmt3+0mUVhSQunSxPmVqc6zb1+8S3R2lq4pEqHo2MwMbWux0PfIYqG//exndN2vvbb6+EZ+BxNF6uAgzcjcvj1+31mcMQzD5BUWZHrItCYrU9aK6uSqoF1BnepUitSBeJF6SQkV1iseW4mRJsXHSz1IOxxOHvlZS2gYUbuULA3pdK7cTpn7WVdHEbHRUfI9276d6r5CKcoctSJ95eUUYXzsMZoSMDhIx3nqqfjfZ2eBiQkyXq2tJSPWVDV62X4H1eLR76eIYGkp3fdkz5VhGIbJKSzI9JLPwuZ8NxEkS1+pxVJfH4mxaJSiKMnW1NlJL3hl3M7MDI1Sqq6OR5rU2+da7CZLQ05MrFyLcs+3byeREgzSmoWga5icXHtcUGKkT5mF2dpKhqp+PzVH9PeT+JmcpMhjSQnw0kvxqQVr1YSpv4PKMztzJv2Uo1o8DgzQfVFSrGY0rDAMwzDmOfUza5Ar13Ut1nKXV8SS3U6/Oxxk9qouQE9ck8dDKbcjR0gI/eIXlAJUR9USnes9Hor8vfkm/TRSCHR2UqdnSQmlTiMRikotLwN/9Edx133lnre307pLSuj36WkSZInba51HPUFgbIz2aW+PRxcdjvhczbt3aVv1/dRbE5buRIBE1JMMpqfj98XhoM/YiZ9hGCbvcIRMC7MLnrMp4E537amiceqoTKJHWbI1eTxkfHr5MvCbvxn3Ertxg7zEMom+ZPpMPB5y/g8EqJ5rfJyiYw0NtC5FzFitdD0uF3VGBoO0T2kpRclqaiitmCyllxjpc7mA5mb6efFi3PbC46GI2bZtJBSt1tSDyxPJNoKqjnxWV1O0LhqlCCbATvwMwzAmwBGyRLKNPhhBYrRFa16jFums3eulaM8Pfwhcu0ZRHAWtCEm6a+rpoQiRUhhvt5MoGRnRjr4o6zl1anUUKttnsmsXzcysqKDuxsZGWtvYGEXvnE4SXcr1NTVRLdf27fTPpk10DYoIcjrp+hJRR/reeouK9ZX7FI2SyGtvp21bW0mU2e20DmXepx5BlW0EVR35dDqpZu7xx+lZ6f2uMQzDMIbCEbJECsEENtO6Kr1rVzcNtLRQ2urSpXj6TCtCku6alEhWOBwv7rfZSJAdPLhy21TWFEZEhM6epWjX0hL9o4iaH/+YZnAqcz6Vc01MUMTo1i0qzA+FKOJ18WJcYGlF6dSRPKuVrj8apWMkpid37Uq/ScPrpZq8zz+nSJ7LRWJ6dJTu91p1bmq06tHy0bDCMAzDaMKCLJFCMeDMpIlA79rVAmfnznj3ZF8fiYhkqbN01uR2x9OUAEWnpqZIFCVGX1IJrmyficdDkS6li3BigqJgNTX02c9/TjVvWiLl5s14I0N/P0X5lO7JxNSl1wu8997qUUi/8zuUvs0kPalGEa7NzbS/10tr37aN7m9zc3odkolp4BdeYCHGMAxjEizIEikEE9hM0bt2tcBxuShy099PNVZdXXGh0N2deR1dZyfZRTz+OP0cGaEU3htv6DeHVQSXEc9k504SY7OzJLIqKkg0VVRQujJxpqsizpR6q4GBlTYeXV0ksNRRug8+oPvocsXr5vr76dqM6CRVC9fqaoruWSyUCj12jM47M0PrqK9f+9mlY5jLMAzD5ByuIUsk0/qtQkDv2tVddgC9yDs6gG9/O55Cy7aOTklxtrRQBOdrX6NU5VdfrawRU1JwP/oRpQOVWja14DLimSjHCIWA3btJxAwMxIenT0ysfR3z8ySwysvjqcfEuq0rV0gI2e3xurn6evrciE5Sde2Y0nxw+HA8dQnQGs+dS/3s1OJOmcKQrDaOYRiGyTkcIUsk3yawRqJ37alc342qo1OiTOpojHK+998ngXb5cjwFFwhQbdSePRT5UdZjxDPxeOh8H39MI6GWl4EnnySxODlJNhTJ6q88HuC55+Jdpn4/icfEui2tSJuU9LkRJEYKHQ66Z2qT22vXSIglPruzZ0m0KVGzvj4Spmp4NibDMIxmiUNxAAAQDklEQVRpsCDTIp8msOmgx/pBz9pTCRyj6+iSCbzTp+MDxKurKWI1Okqu9m+9tdpWIptnojjxHztGqb5olIRYVVV8PNJaglMRsRMTNBDcYqGOTXXd1v79NEhd8TwLh6lu7vDhzNettQaA1r15M0UXH3ssXps2Pg4888zK/SIR4Px5ilKOjJDoffiQon7798e3Wy+peYZhmA0IC7JcYqSfmdE1P2sJHCPr6Lxe4MMP47YR7e3xdN/QEHDoEG3ncq10qzdaEKtFYWMjpSynp0lgvfQSWT6kcsl/+WXgnXeoS7O+Pn4tMzN0/BMn6Bh+P4k9qxXYsYM+N4JEId3SArz99sqh58eOUTermmvXSCAq0woaG+kaPvqIat1aW/Mzn5VhGIZJCguyXGG0gMqnHYdRg6yVe2CzUdpufj5ur2G1UnQpXw0U6pmWc3MkohwOEiiKqEp1XqVb89AhEpgKSvTQ4wGef54if34/Xd/zzxs/AF4rBa2g3HNlXXNztLb6eqp/UxoTtmyh5zE0RM9nPaXmGYZhNiBc1J8rjC6azuc4JbVxaLqmpWqUe7BvH6XvADrW1ask8E6ezF8DhTLT8tIlEicWC51rZAS4d0//eRMbIoC4iFTSonv3At/5Dv28fDkzU+G1jHLXQuvZPfMM1b+pI2fhMI1x2r49NyOrGIZhmLTgCFmuMLoOK992HEbU0Sn3oKSEomIDAyR8pIwLvMZG/cX6Sgq4v5/E1cwM1Z7t309pwbXWqzaHra+nzwYHKVJ3/jytTxHLa5m9lpRQnVtb2+rooVFRzGyjq4nPThGKU1OUmg2HKWX7+ONcM8YwDFMgsCDLFUYLKKPSiPlEfQ+UGjHFZkIRDHqFnyJSlpepJur+fRJT27ZRIf3YGPD668mPpTaHDQRoLbt2kbhbXKSOQy3hoyWOhKCIUzC4UkSeOWOMCDc6Pe3xkP/bu+9SRNDtJjFmsawPOxeGYZgigAVZrjBaQK1HOw4j74EiUnp7SdQpvlvT01QP5fdrCxZ1dGtykuq6lEaCixdJlNTXx9PKExNUuL99O93jiYnV4mjrVhKViWOP0hHhazV8pBNd1ds40tkZj0Ya0WTCMAzDGAoLMqNRvyDLy7UjKZlSqHYcyTBSRCoiZXqaOgSVerpgkDoIJydX19MlRrciEYqmAdRZODZGKUxl4LffT4JvcZFE29wcmaw+++xKkZVMHHk8FIVaWqLzNTau9FNLtq7EyJxeYZduanO9fX8YhmGKCBZkRqL1ggwEinscjVEiQBEpDgeJqIUF+txup5ooZW6kmsTUX1sb/VQ6C10uipgp0baBgdURs4YGSpGqvb2SiaPLl8nPbHiY/MAmJrRHRaVKSeqNLOaz85ZhGIbJKdxlaSQ8jiZ3KKOPNm+Ou+Ur1hUTEySqEuuhtDpTW1vjnYVvvUUCTOnyHBujGjUlYgYATzxB4ipVJ6jy7NvayAj2W98iAaXVHZmqY1Zvl2s+O28ZhmGYnMIRMiMxurMyVxhpWJuvc6jTn+EwibKZGXLL7+rS7rJUrC5GRynV6XCQoGtpWX3MsbHVETOAImnHjsXFUbK0azrPXk9KUk9kMd+dtwzDMEzOYEFmJOvhBWm0YW0+z5Fu+tPjAX7wA0pBOp0U2bpzh9zttY6prHtmZmWqUM+603n2RjU7rMfOW4ZhGEYT01KWQoh/JYT4lRDil0KIj4QQTWatxTCUtFo+jE4zJR9p1XylblOZp3q9lD50OilC5nTS7+rt1Mfo6aEB5JkY4qbz7I0y3jXqOAzDMIzpmBkh+56U8l8AgBDiHwH4vwH8nonryZ71YE2Rj7RqPs6hJwrn81HNmFLMD8RrxZId4/Ll7MSR3mdvVLMDd04yDMNsCEwTZFLKGdWvlQCkWWsxFC2X9O7uwvF+ykdaNR/n0NNhmGoduTBgZXHEMAzDZICpXZZCiD8WQjwE8PdAEbKNhRKBCYUoAhMK0e+ZzDY0inykVfNxDj0dhqnWkW2XYqbzJhmGYRgmASFl7gJTQoiPAWzW+NN3pZTvq7b7AwA2KeUfJjnOmwDeBIAtW7b82uDgYC6Wazzd3STC1BEaZXRQost7Pslnl2V/P5m21tbSqCKjzpXs3obDVMSvXJvHQ2vRutZMno9yXX19wN275DvW2sqecwzDMIwmQogvpJQHUm2X05SllPJZnZv+NYCfANAUZFLKUwBOAcCBAwfWT2qzUG0w8pFaU44/PEz/rnQBGtXRqdVheP8+DS6vqNBXE5Zul6K65iwQIIPaGzdowLlilaE33WmEKM6HsGYYhmHygpldlir3TXwTwC2z1pIzlBomNYVmg5FLctltqdVhuGkTFfDrPV+6XYrq65mdBerqgMpKcvgH9Kc7jUhlF2I6nGEYhskYM7ss/7UQYheAKIBBrPcOSy2K3SdKiRD6/SRapqfjIskIEiN9p05p14StFZFMJ1qojng6HJQetdnomQL6xbYRzQQ8NolhGGZDYWaX5bfNOnfeWA82GLlEccq/cYMiSU4nMDVFo468XuPvQ667O9XHb28HLl0iUeZwxBsG9IhtI1LZ2R6D050MwzAFBTv155pitkLo7ATOnqVaq4oKEi/RKBXC5yKSk4uIpFq4lJTQGKa2NkpXPv44cP06CU27Xb/YNkI4ZnOMfExrYBiGYdKCBRmTOzweYNs2EkVTUxRJ6uggMZOLxgajI5JawkUIqtcKBmkm5quvpn98I4RjNsfgdCfDMEzBwYKMyS27dmlbS+SqscHIiKSWcNm6NT3bkmSpwWyFYzbHKNTuX4ZhmCKGBRmTW9ZzY4MRdVprpQazFY6ZHiMfkxQYhmGYtDDVqZ8pAtbzAOxsbUvyNWQ9XfIxSYFhGIZJC46QMblnvTY2ZBvd8/kAiwXo7SXLD4cD2L6d6s/MpNi7fxmGYQoQFmSMsWwkO4VshUtJCfDzn5OLv9MJRCL0+5EjuV23HtIVyRvpuTIMwxQgLMgY49iIdgrZRPekpK5MYOXPHM6PzQkb8bkyDMMUGCzIGOMoVjuFZNEjKSkadudO3PbjyBFgednsFadHsT5XhmGYPMKCjDGOYrRTWCt65HaT5cfTT8e3n5mhxob1RDE+V4ZhmDzDXZaMcRTjMPW1Oik3SjdjMT5XhmGYPMOCjDGOjSJA0sHn0x5o7vOtb8sPNcX4XBmGYfIMpywZ41ivdgrZdBCmMlldr5Yfatbrc2UYhllHsCBjjGW9CRA9HYRrCbb1PIkgHdbbc2UYhllnCLnOWvAPHDggr1y5YvYymI1Cd/fqWZv37gFDQ2TiKgQwPk4zLNWCS69gYxiGYYoaIcQXUsoDqbbjCBlT3CR2EPr95Ky/uAgcOgScP0+WFU1N8aJ9ID7+SC3EXniBhRjDMAyTEVzUzxQ3iR2EAwM07mjzZhJgi4tAfT19rlBVBfT3U6oyFCJBFwrR715v/q+BYRiGWfewIGOKm8QOwrExMm5tb6e/Oxxk8Do9Hd9nbg6YnCzMweEMwzDMuoQFGVPcJFpTuFzAnj30EyBhNjUFlJWttHyorU1ud8EwDMMwacI1ZAyj7iBUui5nZkhgWa3Ajh2UwlRbPvT0rG13wTAMwzBpwIKMYdRoeW69/rp2sX4x2F0wDMMweYEFGcMkosdzi81SGYZhGAMxXZAJId4G8D0Abiml3+z1MIxu2CyVYRiGMQhTi/qFEC0AvgHggZnrYBiGYRiGMROzuyz/DYDfB7C+xgUwDMMwDMMYiGmCTAjxTQBDUsqrZq2BYRiGYRimEMhpDZkQ4mMAmzX+9F0A/xzAczqP8yaANwFgy5Ythq2PYRiGYRimEDBluLgQ4gkA5wCEHn3kATAM4KCUcnStfXm4OMMwDMMw64WCHi4upbwGYJPyuxDiPoAD3GXJMAzDMEwxYnZRP8MwDMMwTNFjug8ZAEgpt5q9BoZhGIZhGLPgCBnDMAzDMIzJmFLUnw1CCB+AwRyfxgWA69k2JvxsNy78bDcu/Gw3LsXwbFullO5UG607QZYPhBBX9HREMOsPfrYbF362Gxd+thsXfrZxOGXJMAzDMAxjMizIGIZhGIZhTIYFmTanzF4AkzP42W5c+NluXPjZblz42T6Ca8gYhmEYhmFMhiNkDMMwDMMwJsOCLAVCiLeFEFII4TJ7LYwxCCG+J4S4JYT4lRCiWwjhNHtNTOYIIY4LIfqEELeFEP+X2ethjEEI0SKEOC+EuCmE6BVC/GOz18QYixDCIoT4SgjxY7PXUgiwIFsDIUQLgG8AeGD2WhhD+SmADinlXgD9AP7A5PUwGSKEsAD49wBOAHgcwN8VQjxu7qoYg1gC8H9IKXcD+BqA/52f7YbjHwO4afYiCgUWZGvzbwD8PgAutNtASCk/klIuPfr1cwAeM9fDZMVBALellHellAsAfgDgZZPXxBiAlHJESvnlo3+fBb24m81dFWMUQggPgBcB/Cez11IosCBLghDimwCGpJRXzV4Lk1P+AYCzZi+CyZhmAA9Vv3vBL+0NhxBiK4CnAFwydyWMgfx/oIBH1OyFFAoFMVzcLIQQHwPYrPGn7wL45wCey++KGKNY69lKKd9/tM13QWmRv8rn2hhDERqfcUR7AyGEqALwQwD/REo5Y/Z6mOwRQrwEYFxK+YUQ4jfMXk+hUNSCTEr5rNbnQognALQBuCqEACil9aUQ4qCUcjSPS2QyJNmzVRBCvAbgJQDPSPZ+Wc94AbSofvcAGDZpLYzBCCHKQGLsr6SU/8Ps9TCGcRjAN4UQLwCwAagRQvxXKeXfN3ldpsI+ZDoQQtwHcEBKudEHoBYFQojjAP5fAEellD6z18NkjhCiFNSY8QyAIQA9AH5bStlr6sKYrBH0X8PvAZiUUv4Ts9fD5IZHEbK3pZQvmb0Ws+EaMqYY+XcAqgH8VAjxSyHEfzB7QUxmPGrO+IcAPgQVff8Ni7ENw2EA/wuA33z0v9NfPoqoMMyGhCNkDMMwDMMwJsMRMoZhGIZhGJNhQcYwDMMwDGMyLMgYhmEYhmFMhgUZwzAMwzCMybAgYxiGYRiGMRkWZAzDMAzDMCbDgoxhGCYBIcQHQoiAEOLHZq+FYZjigAUZwzDMar4HMiVlGIbJCyzIGIYpCoQQnUKIXwkhbEKISiFErxCiQ2tbKeU5ALN5XiLDMEVMUQ8XZximeJBS9gghfgTgjwBUAPivUsrrJi+LYRgGAAsyhmGKi38JGkAeAfCPTF4LwzBMDE5ZMgxTTNQBqAINl7eZvBaGYZgYLMgYhikmTgH4FwD+CsCfmrwWhmGYGJyyZBimKBBC/K8AlqSUfy2EsAD4TAjxm1LKv9XY9gKAxwBUCSG8AH5HSvlhnpfMMEwRIaSUZq+BYRiGYRimqOGUJcMwDMMwjMlwypJhmKJECPEEgP+S8PG8lLLLjPUwDFPccMqSYRiGYRjGZDhlyTAMwzAMYzIsyBiGYRiGYUyGBRnDMAzDMIzJsCBjGIZhGIYxGRZkDMMwDMMwJvP/A+XcgapfhIB6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "params_1 = {'mean': [2, 2], 'covariance_matrix': 0.5*np.eye(2)}\n",
    "params_2 = {'mean': [-2, -2], 'covariance_matrix': 0.5 * np.eye(2)}\n",
    "params_3 = {'mean': [0, 0], 'covariance_matrix': 0.5 * np.eye(2)}\n",
    "params = [params_1, params_2,params_3]\n",
    "x, y = two_clusters_gaussian(params, 200)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "ax.scatter(x[y == 0, 0], x[y == 0, 1], alpha=0.3, color='blue', label='class 0')\n",
    "ax.scatter(x[y == 1, 0], x[y == 1, 1], alpha=0.3, color='red', label='class 1')\n",
    "ax.scatter(x[y == 2, 0], x[y == 2, 1], alpha=0.3, color='green', label='class 2')\n",
    "\n",
    "ax.set_xlabel('x_1')\n",
    "ax.set_ylabel('x_2')\n",
    "ax.set_title('toy classification data')\n",
    "ax.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test BNN\n",
    "* 3 classes\n",
    "* output dim =1\n",
    "* 2000 samples, step size 1e-2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###relu activation\n",
    "activation_fn_type = 'relu'\n",
    "activation_fn = lambda x: np.maximum(np.zeros(x.shape), x)\n",
    "\n",
    "\n",
    "###neural network model design choices\n",
    "width = 5\n",
    "hidden_layers = 1\n",
    "input_dim = 2\n",
    "output_dim = 1\n",
    "\n",
    "architecture = {'width': width,\n",
    "               'hidden_layers': hidden_layers,\n",
    "               'input_dim': input_dim,\n",
    "               'output_dim': output_dim,\n",
    "               'activation_fn_type': 'relu',\n",
    "               'activation_fn_params': 'rate=1',\n",
    "               'activation_fn': activation_fn}\n",
    "\n",
    "#set random state to make the experiments replicable\n",
    "rand_state = 0\n",
    "random = np.random.RandomState(rand_state)\n",
    "\n",
    "#instantiate a Feedforward neural network object\n",
    "nn = Feedforward(architecture, random=random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 lower bound [2878.58142705]; gradient mag: 1792.341722249051\n",
      "Iteration 100 lower bound [2345.53392195]; gradient mag: 1652.732104526413\n",
      "Iteration 200 lower bound [1837.72600291]; gradient mag: 1535.9597845965454\n",
      "Iteration 300 lower bound [1381.67497463]; gradient mag: 1268.5559520992047\n",
      "Iteration 400 lower bound [1063.0000556]; gradient mag: 854.6612670635143\n",
      "Iteration 500 lower bound [833.91835352]; gradient mag: 705.18438901048\n",
      "Iteration 600 lower bound [562.67301339]; gradient mag: 767.588951598304\n",
      "Iteration 700 lower bound [227.77019326]; gradient mag: 831.5919232076081\n",
      "Iteration 800 lower bound [-61.74577746]; gradient mag: 770.1890785272813\n",
      "Iteration 900 lower bound [-275.66181284]; gradient mag: 688.2818670636366\n",
      "Iteration 1000 lower bound [-446.58983265]; gradient mag: 648.1653759215062\n",
      "Iteration 1100 lower bound [-602.87025054]; gradient mag: 642.1251258295978\n",
      "Iteration 1200 lower bound [-759.02700536]; gradient mag: 655.579822186196\n",
      "Iteration 1300 lower bound [-922.96839479]; gradient mag: 683.7721185115665\n",
      "Iteration 1400 lower bound [-1101.19989085]; gradient mag: 720.8295093173699\n",
      "Iteration 1500 lower bound [-1296.47214063]; gradient mag: 763.0435347902245\n",
      "Iteration 1600 lower bound [-1511.0080628]; gradient mag: 809.8650874868023\n",
      "Iteration 1700 lower bound [-1745.98445449]; gradient mag: 859.0731939688154\n",
      "Iteration 1800 lower bound [-2002.02744587]; gradient mag: 910.5037693053224\n",
      "Iteration 1900 lower bound [-2278.37080147]; gradient mag: 964.0951933515565\n",
      "Iteration 2000 lower bound [-2575.31038982]; gradient mag: 1019.3869785028181\n",
      "Iteration 2100 lower bound [-2892.46449573]; gradient mag: 1074.882887203103\n",
      "Iteration 2200 lower bound [-3229.6494452]; gradient mag: 1131.0188257911695\n",
      "Iteration 2300 lower bound [-3585.52268747]; gradient mag: 1188.5322382755196\n",
      "Iteration 2400 lower bound [-3959.2688707]; gradient mag: 1246.4615169255635\n",
      "Iteration 2500 lower bound [-4350.28572543]; gradient mag: 1304.586041601217\n",
      "Iteration 2600 lower bound [-4753.66258495]; gradient mag: 1331.9208824846226\n",
      "Iteration 2700 lower bound [-5130.98039343]; gradient mag: 1294.5796518648988\n",
      "Iteration 2800 lower bound [-5445.97685634]; gradient mag: 1166.1269314422595\n",
      "Iteration 2900 lower bound [-5712.34995412]; gradient mag: 1040.5527912668244\n",
      "Iteration 3000 lower bound [-5925.86537186]; gradient mag: 896.463561383396\n",
      "Iteration 3100 lower bound [-6097.52712974]; gradient mag: 763.6842063113448\n",
      "Iteration 3200 lower bound [-6224.82218705]; gradient mag: 639.3445610629186\n",
      "Iteration 3300 lower bound [-6314.83644601]; gradient mag: 475.2436415203741\n",
      "Iteration 3400 lower bound [-6373.43183979]; gradient mag: 372.62847059432795\n",
      "Iteration 3500 lower bound [-6418.04679926]; gradient mag: 298.5320828023367\n",
      "Iteration 3600 lower bound [-6453.62918234]; gradient mag: 242.45966073616145\n",
      "Iteration 3700 lower bound [-6479.05951737]; gradient mag: 191.01932014170268\n",
      "Iteration 3800 lower bound [-6502.22202507]; gradient mag: 174.1810072720403\n",
      "Iteration 3900 lower bound [-6521.41380494]; gradient mag: 133.8628070225874\n",
      "Iteration 4000 lower bound [-6537.64757853]; gradient mag: 124.01702362662812\n",
      "Iteration 4100 lower bound [-6552.26172771]; gradient mag: 118.24192857459587\n",
      "Iteration 4200 lower bound [-6564.91747423]; gradient mag: 101.38359177047664\n",
      "Iteration 4300 lower bound [-6574.73694339]; gradient mag: 90.03595908893382\n",
      "Iteration 4400 lower bound [-6583.71243895]; gradient mag: 84.38516555072823\n",
      "Iteration 4500 lower bound [-6591.77029945]; gradient mag: 80.39623273541734\n",
      "Iteration 4600 lower bound [-6598.78075736]; gradient mag: 67.99710816001013\n",
      "Iteration 4700 lower bound [-6604.62823147]; gradient mag: 56.357706936007936\n",
      "Iteration 4800 lower bound [-6609.33900545]; gradient mag: 56.008139153379524\n",
      "Iteration 4900 lower bound [-6613.22244378]; gradient mag: 38.28230128844178\n",
      "Iteration 5000 lower bound [-6616.35495273]; gradient mag: 38.40122161467306\n",
      "Iteration 5100 lower bound [-6619.02620751]; gradient mag: 33.97043697037226\n",
      "Iteration 5200 lower bound [-6621.33290165]; gradient mag: 33.75389097682903\n",
      "Iteration 5300 lower bound [-6623.58651715]; gradient mag: 27.842384621558445\n",
      "Iteration 5400 lower bound [-6625.45470322]; gradient mag: 27.81010090740227\n",
      "Iteration 5500 lower bound [-6627.3503229]; gradient mag: 28.240163884738312\n",
      "Iteration 5600 lower bound [-6629.25620848]; gradient mag: 28.682321085175357\n",
      "Iteration 5700 lower bound [-6631.21026397]; gradient mag: 28.68371226233911\n",
      "Iteration 5800 lower bound [-6633.38314889]; gradient mag: 29.396436917061052\n",
      "Iteration 5900 lower bound [-6635.15913706]; gradient mag: 23.01978003404088\n",
      "Iteration 6000 lower bound [-6636.87118107]; gradient mag: 29.85416889457314\n",
      "Iteration 6100 lower bound [-6638.72569129]; gradient mag: 19.264774252267664\n",
      "Iteration 6200 lower bound [-6640.17994034]; gradient mag: 17.22799432067721\n",
      "Iteration 6300 lower bound [-6641.45005499]; gradient mag: 15.312234405175493\n",
      "Iteration 6400 lower bound [-6642.18409332]; gradient mag: 25.341024411876198\n",
      "Iteration 6500 lower bound [-6643.33759125]; gradient mag: 18.89187101424539\n",
      "Iteration 6600 lower bound [-6644.57242661]; gradient mag: 19.154594179386986\n",
      "Iteration 6700 lower bound [-6645.80342882]; gradient mag: 14.917521231747383\n",
      "Iteration 6800 lower bound [-6647.47586889]; gradient mag: 19.899599818322287\n",
      "Iteration 6900 lower bound [-6649.19719254]; gradient mag: 14.064831925737108\n",
      "Iteration 7000 lower bound [-6650.15941572]; gradient mag: 20.37709744092624\n",
      "Iteration 7100 lower bound [-6651.34386239]; gradient mag: 14.313961606349626\n",
      "Iteration 7200 lower bound [-6652.41228075]; gradient mag: 9.436686201766092\n",
      "Iteration 7300 lower bound [-6653.03625229]; gradient mag: 11.466908666040029\n",
      "Iteration 7400 lower bound [-6654.76195023]; gradient mag: 10.578837600359064\n",
      "Iteration 7500 lower bound [-6656.15576032]; gradient mag: 10.69375902275633\n",
      "Iteration 7600 lower bound [-6657.33537113]; gradient mag: 10.523438910035035\n",
      "Iteration 7700 lower bound [-6658.71006808]; gradient mag: 10.168112103967756\n",
      "Iteration 7800 lower bound [-6659.81048268]; gradient mag: 10.23496385631739\n",
      "Iteration 7900 lower bound [-6661.75868525]; gradient mag: 15.675145596920157\n",
      "Iteration 8000 lower bound [-6663.71077377]; gradient mag: 15.840123867892771\n",
      "Iteration 8100 lower bound [-6665.64204045]; gradient mag: 15.558213530753513\n",
      "Iteration 8200 lower bound [-6667.63587923]; gradient mag: 15.645080576843924\n",
      "Iteration 8300 lower bound [-6669.71768278]; gradient mag: 13.584276910673776\n",
      "Iteration 8400 lower bound [-6671.23666254]; gradient mag: 10.34867263941852\n",
      "Iteration 8500 lower bound [-6672.45956253]; gradient mag: 10.562558898363969\n",
      "Iteration 8600 lower bound [-6673.7246546]; gradient mag: 10.657600314809788\n",
      "Iteration 8700 lower bound [-6675.05115963]; gradient mag: 13.367893472863255\n",
      "Iteration 8800 lower bound [-6676.44588277]; gradient mag: 13.449942833353873\n",
      "Iteration 8900 lower bound [-6677.91470968]; gradient mag: 13.548961263284799\n",
      "Iteration 9000 lower bound [-6680.74246851]; gradient mag: 11.757252097545223\n",
      "Iteration 9100 lower bound [-6683.46627885]; gradient mag: 12.773923348980173\n",
      "Iteration 9200 lower bound [-6686.26380396]; gradient mag: 14.814209928204876\n",
      "Iteration 9300 lower bound [-6688.87908549]; gradient mag: 14.450318544355715\n",
      "Iteration 9400 lower bound [-6691.26049509]; gradient mag: 15.288426223450521\n",
      "Iteration 9500 lower bound [-6693.34415275]; gradient mag: 14.008560868915291\n",
      "Iteration 9600 lower bound [-6695.53128588]; gradient mag: 15.571585205924467\n",
      "Iteration 9700 lower bound [-6696.86896587]; gradient mag: 8.722717913441878\n",
      "Iteration 9800 lower bound [-6697.99697792]; gradient mag: 8.849670390215103\n",
      "Iteration 9900 lower bound [-6699.09954888]; gradient mag: 11.718707512881263\n",
      "Iteration 10000 lower bound [-6700.24853469]; gradient mag: 10.513462384330122\n",
      "Iteration 10100 lower bound [-6701.44538874]; gradient mag: 10.597432199892262\n",
      "Iteration 10200 lower bound [-6702.69942535]; gradient mag: 9.74036893979737\n",
      "Iteration 10300 lower bound [-6704.02689712]; gradient mag: 11.720534518877821\n",
      "Iteration 10400 lower bound [-6705.35870822]; gradient mag: 12.087139561637743\n",
      "Iteration 10500 lower bound [-6706.70583097]; gradient mag: 11.459005676908378\n",
      "Iteration 10600 lower bound [-6707.99640441]; gradient mag: 10.559361720035374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10700 lower bound [-6709.11139537]; gradient mag: 10.606838862161787\n",
      "Iteration 10800 lower bound [-6710.46125256]; gradient mag: 28.326370801734583\n",
      "Iteration 10900 lower bound [-6711.37106792]; gradient mag: 13.957284039450316\n",
      "Iteration 11000 lower bound [-6712.25684582]; gradient mag: 13.67816309301631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaelancel/anaconda3/lib/python3.5/site-packages/autograd/numpy/numpy_vjps.py:53: RuntimeWarning: overflow encountered in square\n",
      "  lambda ans, x, y : unbroadcast_f(y, lambda g: - g * x / y**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11100 lower bound [-6713.21912724]; gradient mag: 15.80625790952774\n",
      "Iteration 11200 lower bound [-6714.07401444]; gradient mag: 16.292140609832927\n",
      "Iteration 11300 lower bound [-6715.09396662]; gradient mag: 28.47643623964849\n",
      "Iteration 11400 lower bound [-6715.86613733]; gradient mag: 20.712023358012985\n",
      "Iteration 11500 lower bound [-6716.55540958]; gradient mag: 6.201623652005573\n",
      "Iteration 11600 lower bound [-6717.28796723]; gradient mag: 16.54093248252807\n",
      "Iteration 11700 lower bound [-6717.80374243]; gradient mag: 11.881393568452731\n",
      "Iteration 11800 lower bound [-6718.503306]; gradient mag: 13.3280618488312\n",
      "Iteration 11900 lower bound [-6719.05042741]; gradient mag: 13.779563671296282\n",
      "Iteration 12000 lower bound [-6719.52733969]; gradient mag: 10.142055342250552\n",
      "Iteration 12100 lower bound [-6720.11347525]; gradient mag: 10.4802123012541\n",
      "Iteration 12200 lower bound [-6720.74752152]; gradient mag: 12.44467179374495\n",
      "Iteration 12300 lower bound [-6721.27188932]; gradient mag: 11.31795260608155\n",
      "Iteration 12400 lower bound [-6721.65279152]; gradient mag: 12.452443171519475\n",
      "Iteration 12500 lower bound [-6722.21724372]; gradient mag: 13.672325655670862\n",
      "Iteration 12600 lower bound [-6722.66206275]; gradient mag: 9.79693114796591\n",
      "Iteration 12700 lower bound [-6723.09768326]; gradient mag: 9.604878454126988\n",
      "Iteration 12800 lower bound [-6723.43401945]; gradient mag: 16.517669410682323\n",
      "Iteration 12900 lower bound [-6724.05260195]; gradient mag: 25.708837444986525\n",
      "Iteration 13000 lower bound [-6724.37061061]; gradient mag: 16.35878753602045\n",
      "Iteration 13100 lower bound [-6724.68958575]; gradient mag: 17.372668614435526\n",
      "Iteration 13200 lower bound [-6725.13737041]; gradient mag: 18.71040725509645\n",
      "Iteration 13300 lower bound [-6725.5635323]; gradient mag: 19.224471905773616\n",
      "Iteration 13400 lower bound [-6726.04525853]; gradient mag: 11.986152570025624\n",
      "Iteration 13500 lower bound [-6726.40758392]; gradient mag: 19.87949542202715\n",
      "Iteration 13600 lower bound [-6726.81211863]; gradient mag: 19.660536367731915\n",
      "Iteration 13700 lower bound [-6727.21540944]; gradient mag: 19.513498839080295\n",
      "Iteration 13800 lower bound [-6727.60659094]; gradient mag: 19.472605868483843\n",
      "Iteration 13900 lower bound [-6728.00095768]; gradient mag: 20.393241063480925\n",
      "Iteration 14000 lower bound [-6728.34708949]; gradient mag: 19.9686772060465\n",
      "Iteration 14100 lower bound [-6728.7693316]; gradient mag: 7.223760704823891\n",
      "Iteration 14200 lower bound [-6729.19293542]; gradient mag: 24.2986227437423\n",
      "Iteration 14300 lower bound [-6729.41826488]; gradient mag: 12.12228409052287\n",
      "Iteration 14400 lower bound [-6729.83488115]; gradient mag: 24.46491769780763\n",
      "Iteration 14500 lower bound [-6729.97965655]; gradient mag: 22.21382049467659\n",
      "Iteration 14600 lower bound [-6730.42215134]; gradient mag: 7.002062699530459\n",
      "Iteration 14700 lower bound [-6730.68299769]; gradient mag: 23.40808854340065\n",
      "Iteration 14800 lower bound [-6731.107812]; gradient mag: 10.135229476165495\n",
      "Iteration 14900 lower bound [-6731.35858714]; gradient mag: 22.919658804130506\n"
     ]
    }
   ],
   "source": [
    "###define design choices in gradient descent\n",
    "params = {'step_size':1e-3, \n",
    "          'max_iteration':15000, \n",
    "          'random_restarts':1}\n",
    "\n",
    "#fit my neural network to minimize MSE on the given data\n",
    "nn.fit(x.T, y.reshape(1,-1), params)\n",
    "#nn.fit(x.T, y.reshape(3,-1), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.71933538e-010, 9.10227913e-082, 2.96278218e-091,\n",
       "        2.55964933e-174, 1.07414765e-076, 4.00206113e-097,\n",
       "        1.41976838e-021, 1.00000000e+000, 3.27052385e-049,\n",
       "        9.92799291e-080, 3.80269484e-040, 5.63807066e-060,\n",
       "        4.15416060e-114, 1.53970185e-127, 7.95798543e-136,\n",
       "        1.76074853e-037, 4.37944870e-173, 9.47127570e-055,\n",
       "        6.79222699e-071, 1.54465344e-128, 1.51030456e-167,\n",
       "        4.26829466e-126, 2.48907921e-029, 1.54276083e-102,\n",
       "        6.54203122e-135, 1.57240765e-066, 1.15481781e-114,\n",
       "        4.21356480e-050, 2.21165271e-096, 1.30945028e-092,\n",
       "        4.42520306e-044, 1.74832946e-049, 1.88681836e-061,\n",
       "        2.07934134e-089, 2.82115022e-113, 4.25855819e-129,\n",
       "        8.30128796e-096, 1.12652314e-070, 1.51969942e-087,\n",
       "        2.73595580e-081, 3.73316323e-140, 1.30606994e-111,\n",
       "        1.37105717e-118, 3.51463065e-153, 3.36381151e-073,\n",
       "        2.24115465e-047, 3.47111907e-123, 1.66949131e-106,\n",
       "        3.96580904e-022, 9.16374285e-052, 6.47060599e-060,\n",
       "        3.19669857e-096, 1.37690190e-102, 2.10290165e-125,\n",
       "        1.64281837e-063, 1.31484818e-058, 1.85360625e-075,\n",
       "        8.85036712e-235, 3.55160656e-130, 7.00229419e-073,\n",
       "        2.97427725e-053, 1.03774088e-138, 7.62126256e-071,\n",
       "        2.12498984e-019, 4.10880970e-112, 1.09816700e-090,\n",
       "        5.73964833e-085, 8.35304845e-141, 9.25693457e-087,\n",
       "        2.15778587e-094, 5.71609260e-140, 1.10065702e-020,\n",
       "        7.85655063e-122, 6.10668904e-114, 2.39909219e-119,\n",
       "        2.48880685e-086, 1.48967447e-113, 1.19866096e-109,\n",
       "        1.36956287e-109, 5.06520358e-131, 1.35164824e-009,\n",
       "        2.89713881e-073, 2.45939138e-029, 6.74353314e-072,\n",
       "        2.12674708e-063, 3.81140209e-029, 1.55480984e-083,\n",
       "        1.88300794e-165, 4.02984741e-022, 4.99666946e-139,\n",
       "        4.09103411e-047, 1.13145187e-074, 2.05846667e-027,\n",
       "        1.04159455e-047, 4.43966805e-050, 3.49806120e-091,\n",
       "        2.25833731e-131, 8.39367251e-081, 1.56254555e-145,\n",
       "        1.03434798e-004, 3.01835794e-086, 2.22791186e-099,\n",
       "        1.95035712e-157, 1.95479446e-039, 2.00179433e-109,\n",
       "        2.51340987e-166, 7.63371347e-018, 9.23143904e-052,\n",
       "        7.27243019e-058, 5.78250596e-162, 1.91895533e-090,\n",
       "        3.47246230e-108, 5.21931194e-022, 6.73251542e-082,\n",
       "        4.01828132e-065, 1.09206376e-068, 1.04477795e-009,\n",
       "        2.07038727e-064, 9.21438988e-131, 1.29285700e-075,\n",
       "        2.85106420e-075, 3.84951753e-097, 3.46118588e-018,\n",
       "        2.50339813e-124, 2.84410771e-094, 2.43296135e-135,\n",
       "        4.42029726e-083, 1.92253679e-135, 1.64823832e-143,\n",
       "        7.30840475e-073, 8.60035769e-001, 5.09183413e-093,\n",
       "        1.35789517e-079, 2.21646289e-127, 5.78773830e-049,\n",
       "        1.77036407e-132, 2.85251023e-122, 2.82383764e-048,\n",
       "        1.80313096e-063, 2.69283162e-164, 1.18272502e-106,\n",
       "        7.02937126e-128, 9.99999862e-001, 8.38797013e-077,\n",
       "        9.35145816e-095, 7.54479695e-146, 2.02243603e-100,\n",
       "        2.60605796e-120, 6.89888800e-150, 2.00294264e-070,\n",
       "        1.07621640e-146, 1.95388077e-084, 2.50501097e-062,\n",
       "        4.50061412e-020, 8.78275717e-136, 2.35361816e-033,\n",
       "        8.03593403e-108, 2.21225885e-108, 8.01752603e-088,\n",
       "        2.07260156e-031, 2.45616839e-139, 3.90320532e-118,\n",
       "        8.76321562e-108, 1.22301503e-148, 3.48550377e-067,\n",
       "        8.29950896e-019, 2.46489317e-105, 7.89941162e-122,\n",
       "        9.77514002e-100, 2.97591689e-127, 1.36610963e-112,\n",
       "        3.37160574e-050, 3.67258633e-041, 1.00000000e+000,\n",
       "        3.89172501e-041, 1.67430403e-038, 4.20502577e-139,\n",
       "        4.92165551e-120, 1.79641079e-047, 1.00000000e+000,\n",
       "        9.95326368e-001, 7.85615365e-104, 8.36926168e-127,\n",
       "        1.99328041e-128, 2.23311188e-157, 3.22662658e-151,\n",
       "        4.59632615e-183, 9.76466464e-101, 3.39720261e-086,\n",
       "        4.42031279e-075, 1.34670076e-096, 6.49183146e-066,\n",
       "        1.92959760e-092, 3.53983437e-048, 7.35061013e-117,\n",
       "        5.63647425e-138, 1.74921337e-115, 9.01185206e-057,\n",
       "        4.09641659e-085, 2.83722475e-055],\n",
       "       [1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 9.82349783e-001, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 9.99999860e-001, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000, 1.00000000e+000,\n",
       "        1.00000000e+000, 1.00000000e+000]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.forward(nn.weights,x.T).reshape(3,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_hmc={\n",
    "       'num_samples':2000,\n",
    "       'step_size':1e-2, \n",
    "       'L':20,\n",
    "       'init': nn.weights,\n",
    "       'burn':.1, \n",
    "       'thin':2,\n",
    "}\n",
    "\n",
    "\n",
    "def log_prior(W):\n",
    "    Sigma=25*np.eye(nn.D)\n",
    "    D_bayes=Sigma.shape[0]\n",
    "    Sigma_inv= np.linalg.inv(Sigma)\n",
    "    Sigma_det = np.linalg.det(Sigma)\n",
    "    constant_W = -0.5 * (D_bayes * np.log(2 * np.pi) + np.log(Sigma_det))\n",
    "    exponential_W = -0.5 * np.diag(np.dot(np.dot(W, Sigma_inv), W.T))\n",
    "    log_p_W = constant_W + exponential_W\n",
    "    return log_p_W\n",
    "\n",
    "def log_likelihood(W):\n",
    "    D_bayes=len(y.reshape((-1,1)))\n",
    "    sigma_y=0.5\n",
    "    constant = (-np.log(sigma_y) - 0.5 * np.log(2 * np.pi)) * D_bayes\n",
    "    exponential = -0.5 * sigma_y**-2 * np.sum((y.reshape((1, 1, D_bayes)) - nn.forward(W, x.T))**2, axis=2).flatten()\n",
    "    return constant + exponential\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q=hmc(log_prior, log_likelihood, **params_hmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'q' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a0bae05ab21e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mq_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BNN posterior'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'q' is not defined"
     ]
    }
   ],
   "source": [
    "q_=np.asarray(q).T\n",
    "plt.plot(range(len(q_[-1])),q_[-1] , color='r')\n",
    "plt.title('BNN posterior')\n",
    "plt.show()\n",
    "print(nn.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decision boundary for the learned model\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "model=Bayesian_logistic_regression(nn.weights[0][-1],nn.weights[0][:-1])\n",
    "ax = plot_decision_boundary(x, y, [model], ax, poly_degree=1,  shaded=True)\n",
    "ax.set_xlabel('x_1')\n",
    "ax.set_ylabel('x_2')\n",
    "ax.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test BNN\n",
    "* 3 classes\n",
    "* output dim =3\n",
    "* 2000 samples, step size 1e-2m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feedforward:\n",
    "\n",
    "    def __init__(self, architecture, random=None, weights=None):\n",
    "        self.params = {'H': architecture['width'],\n",
    "                       'L': architecture['hidden_layers'],\n",
    "                       'D_in': architecture['input_dim'],\n",
    "                       'D_out': architecture['output_dim'],\n",
    "                       'activation_type': architecture['activation_fn_type'],\n",
    "                       'activation_params': architecture['activation_fn_params']}\n",
    "\n",
    "        self.D = ((architecture['input_dim'] * architecture['width'] + architecture['width'])\n",
    "                  + (architecture['output_dim'] * architecture['width'] + architecture['output_dim'])\n",
    "                  + (architecture['hidden_layers'] - 1) * (architecture['width'] ** 2 + architecture['width'])\n",
    "                  )  # in order: input, output, hidden. Take into account the biases\n",
    "\n",
    "        if random is not None:\n",
    "            self.random = random\n",
    "        else:\n",
    "            self.random = np.random.RandomState(0)\n",
    "\n",
    "        self.h = architecture['activation_fn']\n",
    "\n",
    "        if weights is None:\n",
    "            self.weights = self.random.normal(0, 1, size=(1, self.D))\n",
    "        else:\n",
    "            self.weights = weights\n",
    "\n",
    "        self.objective_trace = np.empty((1, 1))\n",
    "        self.weight_trace = np.empty((1, self.D))\n",
    "\n",
    "    def forward(self, weights, x):\n",
    "        \"\"\" Forward pass given weights and input \"\"\"\n",
    "        H = self.params['H']\n",
    "        D_in = self.params['D_in']\n",
    "        D_out = self.params['D_out']\n",
    "        assert weights.shape[1] == self.D\n",
    "\n",
    "        if len(x.shape) == 2:\n",
    "            assert x.shape[0] == D_in\n",
    "            x = x.reshape((1, D_in, -1))\n",
    "        else:\n",
    "            assert x.shape[1] == D_in\n",
    "\n",
    "        weights = weights.T\n",
    "\n",
    "        # input to first hidden layer\n",
    "        W = weights[:H * D_in].T.reshape((-1, H, D_in))\n",
    "        b = weights[H * D_in:H * D_in + H].T.reshape((-1, H, 1))\n",
    "        input = self.h(np.matmul(W, x) + b)\n",
    "        index = H * D_in + H\n",
    "\n",
    "        assert input.shape[1] == H\n",
    "\n",
    "        # additional hidden layers\n",
    "        for _ in range(self.params['L'] - 1):\n",
    "            before = index\n",
    "            W = weights[index:index + H * H].T.reshape((-1, H, H))\n",
    "            index += H * H\n",
    "            b = weights[index:index + H].T.reshape((-1, H, 1))\n",
    "            index += H\n",
    "            output = np.matmul(W, input) + b\n",
    "            input = self.h(output)\n",
    "\n",
    "            assert input.shape[1] == H\n",
    "\n",
    "        def softmax(y):   \n",
    "            return np.exp(y - np.max(y))/(np.exp(y - np.max(y)).sum())\n",
    "\n",
    "        def sigmoid(y):   \n",
    "            return 1/(1 + np.exp(-y))\n",
    "\n",
    "       # output layer\n",
    "        W = weights[index:index + H * D_out].T.reshape((-1, D_out, H))\n",
    "        b = weights[index + H * D_out:].T.reshape((-1, D_out, 1))\n",
    "        output = softmax(np.matmul(W, input) + b)  # review that for training\n",
    "        assert output.shape[1] == self.params['D_out']\n",
    "\n",
    "        return output\n",
    "\n",
    "    def make_objective(self, x_train, y_train, reg_param):\n",
    "\n",
    "        def objective(W, t):\n",
    "            sigmoid_probability = self.forward(W, x_train)\n",
    "            sigmoid_probability = np.clip(sigmoid_probability, 1e-15, 1 - 1e-15)\n",
    "            #bce = np.dot(np.log(sigmoid_probability),y_train.flatten()) + np.dot(np.log(1 - sigmoid_probability),(1 - y_train.flatten())) ##true only for k=2\n",
    "            bce = np.dot(np.log(sigmoid_probability),y_train.flatten()).sum()\n",
    "            if reg_param is None:\n",
    "                sum_error = bce\n",
    "                return -sum_error\n",
    "            else:\n",
    "                mean_error = bce + reg_param * np.linalg.norm(W)\n",
    "                return -mean_error\n",
    "\n",
    "        return objective, grad(objective)\n",
    "\n",
    "    def fit(self, x_train, y_train, params, reg_param=None):\n",
    "\n",
    "        assert x_train.shape[0] == self.params['D_in']\n",
    "        assert y_train.shape[0] == self.params['D_out']\n",
    "\n",
    "        ### make objective function for training\n",
    "        self.objective, self.gradient = self.make_objective(x_train, y_train, reg_param)\n",
    "\n",
    "        ### set up optimization\n",
    "        step_size = 0.01\n",
    "        max_iteration = 5000\n",
    "        check_point = 100\n",
    "        weights_init = self.weights.reshape((1, -1))\n",
    "        mass = None\n",
    "        optimizer = 'adam'\n",
    "        random_restarts = 5\n",
    "\n",
    "        if 'step_size' in params.keys():\n",
    "            step_size = params['step_size']\n",
    "        if 'max_iteration' in params.keys():\n",
    "            max_iteration = params['max_iteration']\n",
    "        if 'check_point' in params.keys():\n",
    "            self.check_point = params['check_point']\n",
    "        if 'init' in params.keys():\n",
    "            weights_init = params['init']\n",
    "        if 'call_back' in params.keys():\n",
    "            call_back = params['call_back']\n",
    "        if 'mass' in params.keys():\n",
    "            mass = params['mass']\n",
    "        if 'optimizer' in params.keys():\n",
    "            optimizer = params['optimizer']\n",
    "        if 'random_restarts' in params.keys():\n",
    "            random_restarts = params['random_restarts']\n",
    "\n",
    "        def call_back(weights, iteration, g):\n",
    "            ''' Actions per optimization step '''\n",
    "            objective = self.objective(weights, iteration)\n",
    "            self.objective_trace = np.vstack((self.objective_trace, objective))\n",
    "            self.weight_trace = np.vstack((self.weight_trace, weights))\n",
    "            if iteration % check_point == 0:\n",
    "                print(\"Iteration {} lower bound {}; gradient mag: {}\".format(iteration, objective, np.linalg.norm(\n",
    "                    self.gradient(weights, iteration))))\n",
    "\n",
    "        ### train with random restarts\n",
    "        optimal_obj = 1e16\n",
    "        optimal_weights = self.weights\n",
    "\n",
    "        for i in range(random_restarts):\n",
    "            if optimizer == 'adam':\n",
    "                adam(self.gradient, weights_init, step_size=step_size, num_iters=max_iteration, callback=call_back)\n",
    "            local_opt = np.min(self.objective_trace[-100:])\n",
    "            if local_opt < optimal_obj:\n",
    "                opt_index = np.argmin(self.objective_trace[-100:])\n",
    "                self.weights = self.weight_trace[-100:][opt_index].reshape((1, -1))\n",
    "            weights_init = self.random.normal(0, 1, size=(1, self.D))\n",
    "\n",
    "        self.objective_trace = self.objective_trace[1:]\n",
    "        self.weight_trace = self.weight_trace[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "###relu activation\n",
    "activation_fn_type = 'relu'\n",
    "activation_fn = lambda x: np.maximum(np.zeros(x.shape), x)\n",
    "\n",
    "\n",
    "###neural network model design choices\n",
    "width = 5\n",
    "hidden_layers = 3\n",
    "input_dim = 2\n",
    "output_dim = 3\n",
    "\n",
    "architecture = {'width': width,\n",
    "               'hidden_layers': hidden_layers,\n",
    "               'input_dim': input_dim,\n",
    "               'output_dim': output_dim,\n",
    "               'activation_fn_type': 'relu',\n",
    "               'activation_fn_params': 'rate=1',\n",
    "               'activation_fn': activation_fn}\n",
    "\n",
    "#set random state to make the experiments replicable\n",
    "rand_state = 0\n",
    "random = np.random.RandomState(rand_state)\n",
    "\n",
    "#instantiate a Feedforward neural network object\n",
    "nn2 = Feedforward(architecture, random=random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 lower bound 14165.294475406648; gradient mag: 5071.668682035805\n",
      "Iteration 100 lower bound 13788.87047953952; gradient mag: 612.3718546373932\n",
      "Iteration 200 lower bound 13695.172990709412; gradient mag: 531.2357939769743\n",
      "Iteration 300 lower bound 13616.53074286403; gradient mag: 463.05309810446926\n",
      "Iteration 400 lower bound 13459.10314177232; gradient mag: 513.6961987177307\n",
      "Iteration 500 lower bound 13222.993835211098; gradient mag: 541.735473886132\n",
      "Iteration 600 lower bound 13004.788113682669; gradient mag: 346.08057887260475\n",
      "Iteration 700 lower bound 12906.01765214257; gradient mag: 161.76726890909373\n",
      "Iteration 800 lower bound 12834.542486895863; gradient mag: 99.19997810589678\n",
      "Iteration 900 lower bound 12808.595820218983; gradient mag: 75.2084675907192\n",
      "Iteration 1000 lower bound 12794.16745257695; gradient mag: 52.59501054539058\n",
      "Iteration 1100 lower bound 12787.311152857264; gradient mag: 36.52231945902835\n",
      "Iteration 1200 lower bound 12782.9097393224; gradient mag: 32.51116336182147\n",
      "Iteration 1300 lower bound 12778.218932315143; gradient mag: 32.578523732162736\n",
      "Iteration 1400 lower bound 12772.205903467038; gradient mag: 27.103800065649935\n",
      "Iteration 1500 lower bound 12770.153959594792; gradient mag: 18.74399479203\n",
      "Iteration 1600 lower bound 12767.711582491247; gradient mag: 25.448608585965907\n",
      "Iteration 1700 lower bound 12765.504048770708; gradient mag: 22.232964538804662\n",
      "Iteration 1800 lower bound 12762.959847332932; gradient mag: 23.251898140897907\n",
      "Iteration 1900 lower bound 12760.347634879574; gradient mag: 15.624142186356508\n",
      "Iteration 2000 lower bound 12759.332304543954; gradient mag: 7.9539471689795365\n",
      "Iteration 2100 lower bound 12758.743873800071; gradient mag: 8.419051457024814\n",
      "Iteration 2200 lower bound 12758.337407371311; gradient mag: 7.507760978426126\n",
      "Iteration 2300 lower bound 12757.802863250039; gradient mag: 6.148891774567628\n",
      "Iteration 2400 lower bound 12757.43545271576; gradient mag: 4.813123334446289\n",
      "Iteration 2500 lower bound 12757.049690832075; gradient mag: 11.807281814971796\n",
      "Iteration 2600 lower bound 12754.170698520957; gradient mag: 22.395724242770303\n",
      "Iteration 2700 lower bound 12752.797801693669; gradient mag: 12.509514508742082\n",
      "Iteration 2800 lower bound 12752.175391390516; gradient mag: 12.023641438140793\n",
      "Iteration 2900 lower bound 12751.851649761826; gradient mag: 10.054572254480094\n",
      "Iteration 3000 lower bound 12751.666813534444; gradient mag: 14.169178706746113\n",
      "Iteration 3100 lower bound 12751.572605508856; gradient mag: 12.039715696459194\n",
      "Iteration 3200 lower bound 12751.515439219163; gradient mag: 9.152253576119936\n",
      "Iteration 3300 lower bound 12751.472313032467; gradient mag: 9.865917025630997\n",
      "Iteration 3400 lower bound 12751.408960971768; gradient mag: 12.189649550309161\n",
      "Iteration 3500 lower bound 12751.347195936487; gradient mag: 12.755128581795402\n",
      "Iteration 3600 lower bound 12751.313475184663; gradient mag: 13.675290032336083\n",
      "Iteration 3700 lower bound 12751.284179340684; gradient mag: 10.401927379806944\n",
      "Iteration 3800 lower bound 12751.25755456112; gradient mag: 13.885661023697235\n",
      "Iteration 3900 lower bound 12751.232201435432; gradient mag: 17.356495850568102\n",
      "Iteration 4000 lower bound 12751.204778572284; gradient mag: 12.688039068410152\n",
      "Iteration 4100 lower bound 12751.182420910773; gradient mag: 16.416754497666915\n",
      "Iteration 4200 lower bound 12751.162109090172; gradient mag: 8.617569419144331\n",
      "Iteration 4300 lower bound 12751.14469432602; gradient mag: 3.883853737678377\n",
      "Iteration 4400 lower bound 12751.129184039952; gradient mag: 15.4002420093628\n",
      "Iteration 4500 lower bound 12751.114534056578; gradient mag: 12.64662901513021\n",
      "Iteration 4600 lower bound 12751.101007577623; gradient mag: 7.536374134072684\n",
      "Iteration 4700 lower bound 12751.08927696628; gradient mag: 4.1684944797312085\n",
      "Iteration 4800 lower bound 12751.079321779409; gradient mag: 4.628889150793851\n",
      "Iteration 4900 lower bound 12751.07043283063; gradient mag: 5.266251230391095\n",
      "Iteration 5000 lower bound 12751.062445860416; gradient mag: 4.525052185804545\n",
      "Iteration 5100 lower bound 12751.056853279959; gradient mag: 9.42180160514374\n",
      "Iteration 5200 lower bound 12751.050705891672; gradient mag: 6.493134055652112\n",
      "Iteration 5300 lower bound 12751.045715845023; gradient mag: 6.542795457806571\n",
      "Iteration 5400 lower bound 12751.041007493857; gradient mag: 11.704887764057657\n",
      "Iteration 5500 lower bound 12751.036546854539; gradient mag: 2.700573468857315\n",
      "Iteration 5600 lower bound 12751.033066348855; gradient mag: 4.445235966376818\n",
      "Iteration 5700 lower bound 12751.029852470052; gradient mag: 9.397538424606935\n",
      "Iteration 5800 lower bound 12751.026377030603; gradient mag: 6.077579030451396\n",
      "Iteration 5900 lower bound 12751.022730066965; gradient mag: 8.99675566914463\n",
      "Iteration 6000 lower bound 12751.019611351016; gradient mag: 10.910357984263102\n",
      "Iteration 6100 lower bound 12751.015980766644; gradient mag: 5.352916986358749\n",
      "Iteration 6200 lower bound 12751.012986968846; gradient mag: 4.647382500686779\n",
      "Iteration 6300 lower bound 12751.008448209395; gradient mag: 8.966610325576744\n",
      "Iteration 6400 lower bound 12751.00582079376; gradient mag: 15.085311917030573\n",
      "Iteration 6500 lower bound 12751.00106856565; gradient mag: 0.8549770415869459\n",
      "Iteration 6600 lower bound 12750.998188857797; gradient mag: 1.2057875905320976\n",
      "Iteration 6700 lower bound 12750.99538396043; gradient mag: 1.9157107985634716\n",
      "Iteration 6800 lower bound 12750.992005960374; gradient mag: 4.339418879501384\n",
      "Iteration 6900 lower bound 12750.986474206493; gradient mag: 0.8638344756282073\n",
      "Iteration 7000 lower bound 12750.976679163006; gradient mag: 22.642601128304637\n",
      "Iteration 7100 lower bound 12750.966152066854; gradient mag: 9.10351215415041\n",
      "Iteration 7200 lower bound 12750.95584939214; gradient mag: 3.970861391356738\n",
      "Iteration 7300 lower bound 12750.94635739401; gradient mag: 21.759111114337493\n",
      "Iteration 7400 lower bound 12750.932155003353; gradient mag: 18.787743849243967\n",
      "Iteration 7500 lower bound 12750.912102506984; gradient mag: 10.682438341944541\n",
      "Iteration 7600 lower bound 12750.87427181631; gradient mag: 5.254802543638302\n",
      "Iteration 7700 lower bound 12750.855894922752; gradient mag: 5.224292692856782\n",
      "Iteration 7800 lower bound 12750.840728080342; gradient mag: 3.0086770172657022\n",
      "Iteration 7900 lower bound 12750.824837265925; gradient mag: 6.030118263190534\n",
      "Iteration 8000 lower bound 12750.810197571966; gradient mag: 19.086133098316193\n",
      "Iteration 8100 lower bound 12750.775526663261; gradient mag: 6.639101581912223\n",
      "Iteration 8200 lower bound 12750.746873170861; gradient mag: 6.114269202321015\n",
      "Iteration 8300 lower bound 12750.737496123464; gradient mag: 12.479081361888518\n",
      "Iteration 8400 lower bound 12750.733367067422; gradient mag: 18.898655451498723\n",
      "Iteration 8500 lower bound 12750.723913166725; gradient mag: 11.676778079036241\n",
      "Iteration 8600 lower bound 12750.720150867397; gradient mag: 8.10893260622445\n",
      "Iteration 8700 lower bound 12750.711446161764; gradient mag: 11.185120975875614\n",
      "Iteration 8800 lower bound 12750.710026638848; gradient mag: 4.832865019516897\n",
      "Iteration 8900 lower bound 12750.710171356239; gradient mag: 13.414639164465155\n",
      "Iteration 9000 lower bound 12750.707747155637; gradient mag: 10.578572506477451\n",
      "Iteration 9100 lower bound 12750.708090346248; gradient mag: 21.227111042561727\n",
      "Iteration 9200 lower bound 12750.705161222304; gradient mag: 6.238433726697981\n",
      "Iteration 9300 lower bound 12750.703900505367; gradient mag: 13.511460915482091\n",
      "Iteration 9400 lower bound 12750.701367959151; gradient mag: 13.868560532651777\n",
      "Iteration 9500 lower bound 12750.701130521984; gradient mag: 14.739822216554021\n",
      "Iteration 9600 lower bound 12750.699543971765; gradient mag: 18.91311339205381\n",
      "Iteration 9700 lower bound 12750.70197697428; gradient mag: 24.99797339862508\n",
      "Iteration 9800 lower bound 12750.702124602227; gradient mag: 28.892999390619146\n",
      "Iteration 9900 lower bound 12750.69446770872; gradient mag: 7.419916605073899\n",
      "Iteration 10000 lower bound 12750.694704741385; gradient mag: 15.573261868647158\n",
      "Iteration 10100 lower bound 12750.692564946781; gradient mag: 10.13100003177896\n",
      "Iteration 10200 lower bound 12750.696604545625; gradient mag: 35.49535993125206\n",
      "Iteration 10300 lower bound 12750.693297386839; gradient mag: 26.103787093016052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10400 lower bound 12750.690522562567; gradient mag: 10.89560398330707\n",
      "Iteration 10500 lower bound 12750.692907965058; gradient mag: 25.633982024956282\n",
      "Iteration 10600 lower bound 12750.690815844337; gradient mag: 11.93269909345627\n",
      "Iteration 10700 lower bound 12750.69172990986; gradient mag: 23.133831356561984\n",
      "Iteration 10800 lower bound 12750.687392584232; gradient mag: 10.058841531870167\n",
      "Iteration 10900 lower bound 12750.686843108906; gradient mag: 20.027200010924894\n",
      "Iteration 11000 lower bound 12750.684288698532; gradient mag: 10.149519516069315\n",
      "Iteration 11100 lower bound 12750.68440620679; gradient mag: 12.53590803869931\n",
      "Iteration 11200 lower bound 12750.683633429922; gradient mag: 14.879590267146098\n",
      "Iteration 11300 lower bound 12750.683345758467; gradient mag: 32.903008202272\n",
      "Iteration 11400 lower bound 12750.683868953827; gradient mag: 18.075277921934028\n",
      "Iteration 11500 lower bound 12750.68618305781; gradient mag: 21.058550538831273\n",
      "Iteration 11600 lower bound 12750.680877973742; gradient mag: 15.417167000653462\n",
      "Iteration 11700 lower bound 12750.680091641538; gradient mag: 9.558294092992735\n",
      "Iteration 11800 lower bound 12750.682672170744; gradient mag: 17.79768902451726\n",
      "Iteration 11900 lower bound 12750.677785768134; gradient mag: 12.526125113943829\n",
      "Iteration 12000 lower bound 12750.677602767499; gradient mag: 7.534429711336251\n",
      "Iteration 12100 lower bound 12750.681484289984; gradient mag: 15.677196169369779\n",
      "Iteration 12200 lower bound 12750.678732983983; gradient mag: 17.82960646721283\n",
      "Iteration 12300 lower bound 12750.675851583588; gradient mag: 5.8828429511912415\n",
      "Iteration 12400 lower bound 12750.677927945597; gradient mag: 10.949543113954928\n",
      "Iteration 12500 lower bound 12750.677576095739; gradient mag: 9.994290011777869\n",
      "Iteration 12600 lower bound 12750.6757564959; gradient mag: 9.375053305729804\n",
      "Iteration 12700 lower bound 12750.677213944424; gradient mag: 10.412117698296367\n",
      "Iteration 12800 lower bound 12750.679891759886; gradient mag: 18.266990079757406\n",
      "Iteration 12900 lower bound 12750.679242433012; gradient mag: 32.1953826934408\n",
      "Iteration 13000 lower bound 12750.676419165116; gradient mag: 13.005543395907779\n",
      "Iteration 13100 lower bound 12750.679978074248; gradient mag: 17.23170207252036\n",
      "Iteration 13200 lower bound 12750.677256489947; gradient mag: 17.30321904285216\n",
      "Iteration 13300 lower bound 12750.675538606516; gradient mag: 11.619297949632807\n",
      "Iteration 13400 lower bound 12750.67679019964; gradient mag: 10.077145484411908\n",
      "Iteration 13500 lower bound 12750.676833664003; gradient mag: 7.9178226134661305\n",
      "Iteration 13600 lower bound 12750.677538170718; gradient mag: 31.62192183563755\n",
      "Iteration 13700 lower bound 12750.6768430206; gradient mag: 13.770418794371357\n",
      "Iteration 13800 lower bound 12750.681290406017; gradient mag: 23.79163979816498\n",
      "Iteration 13900 lower bound 12750.675057718312; gradient mag: 13.90486500664227\n",
      "Iteration 14000 lower bound 12750.673812857036; gradient mag: 6.8511150841407416\n",
      "Iteration 14100 lower bound 12750.678791267415; gradient mag: 15.211568760085564\n",
      "Iteration 14200 lower bound 12750.678023778384; gradient mag: 17.666930721129614\n",
      "Iteration 14300 lower bound 12750.674430336461; gradient mag: 12.310563065112861\n",
      "Iteration 14400 lower bound 12750.675770736905; gradient mag: 7.071661906345339\n",
      "Iteration 14500 lower bound 12750.676662785736; gradient mag: 8.96533417177648\n",
      "Iteration 14600 lower bound 12750.675911922095; gradient mag: 9.078560397267355\n",
      "Iteration 14700 lower bound 12750.676735102106; gradient mag: 14.15921046868772\n",
      "Iteration 14800 lower bound 12750.678092444594; gradient mag: 13.332081655945242\n",
      "Iteration 14900 lower bound 12750.676305676498; gradient mag: 30.00760656643126\n"
     ]
    }
   ],
   "source": [
    "###define design choices in gradient descent\n",
    "params = {'step_size':1e-3, \n",
    "          'max_iteration':15000, \n",
    "          'random_restarts':1}\n",
    "\n",
    "#fit my neural network to minimize MSE on the given data\n",
    "nn2.fit(x.T, y.reshape(3,-1), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.86689670e-09 2.87449837e-05 2.87245684e-06 3.06354139e-05\n",
      " 2.62519079e-09 2.21997666e-09 2.21997666e-09 2.21997666e-09\n",
      " 8.64401789e-07 2.69113395e-04 4.16824332e-08 1.53026054e-05\n",
      " 9.26882033e-08 4.45820676e-09 1.08025657e-07 5.84241334e-07\n",
      " 1.44205773e-04 1.95657872e-04 7.50863268e-04 3.85065041e-05\n",
      " 1.52084235e-06 8.66157897e-06 9.08486439e-04 7.69333399e-05\n",
      " 1.01359768e-06 5.03395973e-08 5.85195231e-09 1.51810594e-07\n",
      " 7.40353616e-07 1.09745164e-07 9.65714414e-09 2.21997666e-09\n",
      " 1.18103529e-06 6.48008386e-04 6.72485174e-08 2.68654764e-06\n",
      " 2.16443119e-06 8.93280550e-08 6.39125689e-08 2.21989161e-06\n",
      " 3.32594280e-04 2.00472546e-06 3.83377515e-07 3.55582045e-06\n",
      " 1.43050453e-06 2.61488329e-08 1.24120803e-07 9.11013126e-07\n",
      " 2.21997666e-09 4.17862657e-06 1.19879811e-06 2.21997666e-09\n",
      " 1.72046751e-06 2.42072423e-06 1.05411086e-03 1.44585935e-08\n",
      " 2.21997666e-09 8.84879482e-08 3.99539757e-08 2.34561992e-08\n",
      " 4.53008190e-05 1.10799956e-07 6.85374222e-05 1.65700033e-06\n",
      " 6.05496607e-06 2.21997666e-09 2.21997666e-09 2.02319371e-07\n",
      " 1.49666050e-06 7.46427456e-06 1.72639847e-05 8.16549695e-04\n",
      " 2.69070280e-04 1.57854964e-07 6.90574989e-06 2.89546563e-06\n",
      " 1.22773835e-05 3.22937783e-05 5.97023702e-08 6.49306611e-07\n",
      " 2.21997666e-09 6.17997831e-06 6.31805586e-06 1.15452639e-08\n",
      " 2.21997666e-09 3.11049091e-08 6.32020779e-07 2.90848785e-08\n",
      " 5.86798467e-09 5.67954628e-05 1.02975680e-07 5.41586201e-06\n",
      " 1.09063781e-07 2.24317611e-09 1.21594604e-06 8.14243703e-09\n",
      " 8.88413099e-09 5.49114840e-09 5.22417703e-07 5.67954687e-06] \n",
      "\n",
      "[2.21972949e-07 2.26431059e-07 2.21997666e-09 2.21997666e-09\n",
      " 2.40216608e-08 1.19663536e-08 3.22935516e-08 2.71335996e-07\n",
      " 1.61980293e-05 2.21997666e-09 6.05335047e-09 2.83233214e-09\n",
      " 5.39197691e-06 2.07636323e-08 2.07566744e-08 7.76878309e-05\n",
      " 1.47403456e-05 4.48011455e-07 2.21997666e-09 2.21997666e-09\n",
      " 1.59051093e-08 6.01674173e-06 2.21997666e-09 4.05042364e-05\n",
      " 8.13392044e-08 7.07406631e-07 9.74049510e-06 6.41436412e-09\n",
      " 7.16583445e-08 2.83261794e-07 3.75271808e-09 6.81441176e-06\n",
      " 5.88025543e-08 2.21997666e-09 4.61670410e-07 4.02393143e-07\n",
      " 3.52673237e-05 3.75271990e-07 2.38420452e-06 5.15635776e-05\n",
      " 4.37878579e-08 4.29854854e-06 8.12254054e-09 6.89568240e-06\n",
      " 1.19585194e-07 3.41819610e-05 5.49261714e-08 6.44238382e-09\n",
      " 5.94905398e-09 7.30189462e-04 2.76655109e-05 3.10348987e-06\n",
      " 4.60475389e-06 6.06623048e-08 7.41750381e-08 6.49309245e-08\n",
      " 2.69493449e-07 1.05814882e-08 4.09259210e-04 9.80492172e-04\n",
      " 6.81403647e-07 1.50739003e-07 1.30268987e-08 1.00494741e-04\n",
      " 2.21997666e-09 2.21997666e-09 1.28330440e-07 2.81208192e-07\n",
      " 2.21997666e-09 9.21792577e-04 4.26208303e-06 2.29354975e-07\n",
      " 9.32618328e-08 2.38938507e-07 1.12677146e-04 1.00150246e-06\n",
      " 2.21997666e-09 2.21997666e-09 3.61195215e-09 6.36778822e-08\n",
      " 3.35982098e-08 2.00004267e-05 4.08643586e-04 2.89607270e-08\n",
      " 2.41735903e-09 3.68910025e-08 3.62976090e-08 1.36624944e-05\n",
      " 5.95335855e-08 2.21997666e-09 5.01310407e-06 2.79307292e-07\n",
      " 2.21997666e-09 1.25647696e-05 5.56088381e-08 4.74489432e-08\n",
      " 7.56625930e-08 2.21997666e-09 2.21997666e-09 1.69248837e-05] \n",
      "\n",
      "[4.98579104e-04 5.65725756e-04 5.63838035e-04 5.64668637e-04\n",
      " 5.65238834e-04 5.65050898e-04 5.63037463e-04 5.41592857e-04\n",
      " 5.63970787e-04 5.65477003e-04 5.65444247e-04 5.65759968e-04\n",
      " 5.64413300e-04 5.64680944e-04 5.64390861e-04 5.64482226e-04\n",
      " 5.63705316e-04 5.64342755e-04 5.50886000e-04 5.65186547e-04\n",
      " 7.22679773e-04 5.64369427e-04 5.64336851e-04 4.46159599e-04\n",
      " 5.65119035e-04 5.65853748e-04 5.65376182e-04 5.65540304e-04\n",
      " 5.64363831e-04 5.65057292e-04 5.58483578e-04 5.65634593e-04\n",
      " 5.65474873e-04 5.65129475e-04 5.64277402e-04 5.64120121e-04\n",
      " 5.65582541e-04 5.64999719e-04 5.63702375e-04 5.65773831e-04\n",
      " 5.63117183e-04 5.95579345e-04 6.90271405e-04 6.42872499e-04\n",
      " 5.63911036e-04 5.65619498e-04 5.64492064e-04 5.64037572e-04\n",
      " 5.64620528e-04 5.64677391e-04 5.64844976e-04 5.65302364e-04\n",
      " 5.33389503e-04 5.63529156e-04 5.64616555e-04 7.11408481e-04\n",
      " 5.65493138e-04 5.62665245e-04 5.65653539e-04 9.22257650e-04\n",
      " 8.05322915e-04 5.64943693e-04 5.62768349e-04 5.65673562e-04\n",
      " 5.65396539e-04 5.63613838e-04 5.65625375e-04 6.59375918e-04\n",
      " 5.65582103e-04 5.64639655e-04 5.50271780e-04 5.65488247e-04\n",
      " 5.65604107e-04 5.65524357e-04 5.52690863e-04 5.65209112e-04\n",
      " 5.65515400e-04 5.65699372e-04 5.65226576e-04 5.64667449e-04\n",
      " 5.64834256e-04 5.65325287e-04 7.58644001e-04 5.64420712e-04\n",
      " 5.65225112e-04 5.64701618e-04 5.63301054e-04 5.64760807e-04\n",
      " 5.64628118e-04 6.84357305e-04 5.65255245e-04 5.65357217e-04\n",
      " 5.65328220e-04 5.64496955e-04 5.64581580e-04 5.63640267e-04\n",
      " 5.65090898e-04 5.63844026e-04 5.63456308e-04 5.64467608e-04\n",
      " 5.64222465e-04 5.64754583e-04 5.64929850e-04 5.65286265e-04\n",
      " 5.65430499e-04 5.63667198e-04 5.65626702e-04 5.64021108e-04\n",
      " 5.64700608e-04 5.64977572e-04 5.63340778e-04 5.64455379e-04\n",
      " 5.65270893e-04 5.65877805e-04 5.64394056e-04 5.64421790e-04\n",
      " 5.64329845e-04 5.64697997e-04 5.63708681e-04 6.12154340e-04\n",
      " 5.65160817e-04 5.65069850e-04 5.64310561e-04 5.64952089e-04\n",
      " 5.64912795e-04 5.65063963e-04 5.65726181e-04 5.65394665e-04\n",
      " 8.08196156e-04 5.64861198e-04 5.73856268e-04 7.85786326e-04\n",
      " 5.65402753e-04 5.65216854e-04 5.65206286e-04 5.64767826e-04\n",
      " 5.65461474e-04 5.64581194e-04 8.03714945e-04 5.65789214e-04\n",
      " 5.64550553e-04 5.65606105e-04 5.63447296e-04 5.63662350e-04\n",
      " 5.65630691e-04 5.64693987e-04 5.63068099e-04 5.64556914e-04\n",
      " 5.65151918e-04 5.64163678e-04 5.65302300e-04 5.65724829e-04\n",
      " 5.64648097e-04 5.65026904e-04 5.64751518e-04 5.65683754e-04\n",
      " 5.62989985e-04 5.64290381e-04 5.64345364e-04 5.65526077e-04\n",
      " 5.64790976e-04 5.65395383e-04 5.65116035e-04 5.65342139e-04\n",
      " 5.65751726e-04 5.65040266e-04 5.65857009e-04 5.65011585e-04\n",
      " 5.65180047e-04 5.64390637e-04 5.64308476e-04 5.36342452e-04\n",
      " 4.15877721e-04 5.65866948e-04 5.64928155e-04 5.65178806e-04\n",
      " 5.64109784e-04 8.64504474e-04 5.65004652e-04 5.64837100e-04\n",
      " 5.65856006e-04 5.64146740e-04 5.65741939e-04 5.65186904e-04\n",
      " 4.38922875e-04 5.65429442e-04 6.79439849e-04 5.64259394e-04\n",
      " 5.64567479e-04 5.65281829e-04 5.65146882e-04 5.55179969e-04\n",
      " 5.64806583e-04 5.65066745e-04 5.65450473e-04 5.65845774e-04\n",
      " 5.64315023e-04 5.91392756e-04 5.64622062e-04 5.65746372e-04\n",
      " 1.14315057e-03 1.11151015e-03 9.90294297e-04 1.03238971e-03\n",
      " 1.18411082e-03 1.14628472e-03 1.12615677e-03 1.05693214e-03\n",
      " 1.08229893e-03 1.14249919e-03 1.15158707e-03 1.15001591e-03\n",
      " 1.12483201e-03 1.10721760e-03 1.15563659e-03 9.86465761e-04\n",
      " 1.04766645e-03 8.92452320e-04 1.13307403e-03 8.95437058e-04\n",
      " 1.07492476e-03 1.10916914e-03 1.13228836e-03 1.16619282e-03\n",
      " 1.09328001e-03 1.07790973e-03 1.14922219e-03 9.30768721e-04\n",
      " 1.16673841e-03 1.11201578e-03 9.91649573e-04 9.92079130e-04\n",
      " 3.06296102e-04 1.04964595e-03 1.10280583e-03 1.02230097e-03\n",
      " 1.06866569e-03 1.18151491e-03 9.77464795e-04 1.00123369e-03\n",
      " 1.16343701e-03 9.34727084e-04 1.17550883e-03 1.15629468e-03\n",
      " 1.15900439e-03 9.48758122e-04 8.68646617e-04 1.17382096e-03\n",
      " 1.10379874e-03 5.65216596e-04 1.01890818e-03 1.13963310e-03\n",
      " 1.05788421e-03 8.83230459e-04 7.42045053e-04 1.18065184e-03\n",
      " 1.14060957e-03 1.06979303e-03 1.12268117e-03 1.13622414e-03\n",
      " 1.02368121e-03 1.14452029e-03 1.10582238e-03 1.02768786e-03\n",
      " 5.63905415e-04 1.15818234e-03 1.11513093e-03 9.64186791e-04\n",
      " 5.65521612e-04 1.13082341e-03 1.07885856e-03 9.18456054e-04\n",
      " 1.11680043e-03 1.00105093e-03 1.17057733e-03 8.79298069e-04\n",
      " 1.16698407e-03 1.07208617e-03 1.15807603e-03 1.11880162e-03\n",
      " 1.17993522e-03 1.02475244e-03 8.73787045e-04 1.06466665e-03\n",
      " 1.18933445e-03 1.14689050e-03 1.15512375e-03 1.08107230e-03\n",
      " 1.13051115e-03 1.09326683e-03 1.08955883e-03 1.02329831e-03\n",
      " 1.11073852e-03 1.14153423e-03 1.05499786e-03 1.05504580e-03\n",
      " 1.01841675e-03 1.07504194e-03 1.12736532e-03 1.17226636e-03\n",
      " 1.15078925e-03 1.01368146e-03 1.18519154e-03 1.10784739e-03\n",
      " 1.12697462e-03 1.15766323e-03 1.14201018e-03 1.03652347e-03\n",
      " 1.10298858e-03 9.26724095e-04 9.21239932e-04 9.19555613e-04\n",
      " 1.13981974e-03 1.11824167e-03 1.11344830e-03 9.46647181e-04\n",
      " 9.52245110e-04 1.03773791e-03 1.13303576e-03 9.06211804e-04\n",
      " 1.02759311e-03 1.10650459e-03 1.07530431e-03 1.15907649e-03\n",
      " 9.47620139e-04 1.16916552e-03 1.01055530e-03 1.01867241e-03\n",
      " 1.14599639e-03 1.07091203e-03 1.15634453e-03 9.52480063e-04\n",
      " 1.10972222e-03 1.13315761e-03 9.66093959e-04 3.44865577e-04\n",
      " 1.13044572e-03 1.09020095e-03 3.88176269e-04 5.42940932e-05\n",
      " 1.17685588e-03 1.10963238e-03 1.09971835e-03 1.12559745e-03\n",
      " 8.89304680e-04 9.62367202e-04 1.12885891e-03 1.12721505e-03\n",
      " 1.09125268e-03 1.12594144e-03 8.97173323e-04 1.09603447e-03\n",
      " 1.14539852e-03 1.08858428e-03 1.15350831e-03 1.15237532e-03\n",
      " 1.15108520e-03 8.66827103e-04 1.10231775e-03 8.14811939e-04\n",
      " 1.16425473e-03 1.12516744e-03 9.79124971e-04 1.05643663e-03\n",
      " 9.18758890e-04 1.13305259e-03 1.01839714e-03 8.81522702e-04\n",
      " 1.17332196e-03 9.14064325e-04 1.14722363e-03 1.07590714e-03\n",
      " 9.54909828e-04 1.01190213e-03 1.05114840e-03 1.08594441e-03\n",
      " 1.06895101e-03 1.10341590e-03 1.10118917e-03 9.82127431e-04\n",
      " 1.02273765e-03 1.13351101e-03 8.86684465e-04 2.55842715e-04\n",
      " 1.04861171e-03 1.12952352e-03 1.08168336e-03 1.06790617e-03\n",
      " 1.02945776e-03 1.14447965e-03 1.04632251e-03 1.11515420e-03\n",
      " 9.46905600e-04 1.11929516e-03 9.81094537e-04 1.01050065e-03\n",
      " 1.12802929e-03 1.10777233e-03 1.03375004e-03 1.08277720e-03] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(nn2.forward(nn2.weights,x.T)[0][0][:100],'\\n')\n",
    "print(nn2.forward(nn2.weights,x.T)[0][0][100:200],'\\n')\n",
    "print(nn2.forward(nn2.weights,x.T)[0][0][200:],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 : 0.99 False\n",
      "200 : 0.925 False\n",
      "300 : 0.9266666666666666 False\n",
      "400 : 0.9025 False\n",
      "500 : 0.878 False\n",
      "600 : 0.89 False\n",
      "700 : 0.8885714285714286 False\n",
      "800 : 0.89 False\n",
      "900 : 0.8966666666666666 False\n",
      "1000 : 0.903 False\n",
      "1100 : 0.8981818181818182 False\n",
      "1200 : 0.8991666666666667 False\n",
      "1300 : 0.8992307692307693 False\n",
      "1400 : 0.9021428571428571 False\n",
      "1500 : 0.9066666666666666 False\n",
      "1600 : 0.9125 False\n",
      "1700 : 0.9164705882352941 False\n",
      "1800 : 0.9205555555555556 False\n",
      "1900 : 0.9236842105263158 False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-2133.3492049562165"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_hmc={\n",
    "       'num_samples':2000,\n",
    "       'step_size':1e-2, \n",
    "       'L':20,\n",
    "       'init': nn2.weights,\n",
    "       'burn':.1, \n",
    "       'thin':2,\n",
    "}\n",
    "\n",
    "\n",
    "def log_prior(W):\n",
    "    Sigma=25*np.eye(nn2.D)\n",
    "    D_bayes=Sigma.shape[0]\n",
    "    Sigma_inv= np.linalg.inv(Sigma)\n",
    "    Sigma_det = np.linalg.det(Sigma)\n",
    "    constant_W = -0.5 * (D_bayes * np.log(2 * np.pi) + np.log(Sigma_det))\n",
    "    exponential_W = -0.5 * np.diag(np.dot(np.dot(W, Sigma_inv), W.T))\n",
    "    log_p_W = constant_W + exponential_W\n",
    "    return log_p_W\n",
    "\n",
    "def log_likelihood(W):\n",
    "    D_bayes=len(y.reshape((-1,1)))\n",
    "    sigma_y=0.5\n",
    "    constant = (-np.log(sigma_y) - 0.5 * np.log(2 * np.pi)) * D_bayes\n",
    "    #print(constant)\n",
    "    exponential = (-0.5 * sigma_y**-2 * np.sum((y.reshape((1, 1, D_bayes)) - (nn2.forward(W, x.T)))**2, axis=2).flatten()).mean()\n",
    "    #print(exponential)\n",
    "    return constant + exponential\n",
    "\n",
    "q=hmc(log_prior, log_likelihood, **params_hmc)\n",
    "\n",
    "\n",
    "log_likelihood(nn2.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "q_=np.asarray(q).T\n",
    "plt.plot(range(len(q_[0])),q_[0] , color='r')\n",
    "plt.title('BNN posterior')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "###relu activation\n",
    "activation_fn_type = 'relu'\n",
    "activation_fn = lambda x: np.maximum(np.zeros(x.shape), x)\n",
    "\n",
    "\n",
    "###neural network model design choices\n",
    "width = 5\n",
    "hidden_layers = 2\n",
    "input_dim = 2\n",
    "output_dim = 3\n",
    "\n",
    "architecture = {'width': width,\n",
    "               'hidden_layers': hidden_layers,\n",
    "               'input_dim': input_dim,\n",
    "               'output_dim': output_dim,\n",
    "               'activation_fn_type': 'relu',\n",
    "               'activation_fn_params': 'rate=1',\n",
    "               'prior': 'normal',\n",
    "               'prior_parameters':{'mean': np.array([1, 2]), 'covariance_matrix': np.eye(2)},\n",
    "               'likelihood': 'logistic',\n",
    "               'likelihood_parameters': {},\n",
    "               'activation_fn': activation_fn}\n",
    "\n",
    "#set random state to make the experiments replicable\n",
    "rand_state = 0\n",
    "random = np.random.RandomState(rand_state)\n",
    "\n",
    "#instantiate a Feedforward neural network object\n",
    "nlm = NLM(architecture, random=random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 lower bound 12742.956496065595; gradient mag: 25.23026904129423\n",
      "Iteration 100 lower bound 12742.876824189658; gradient mag: 38.52264512345793\n",
      "Iteration 200 lower bound 12742.837934021889; gradient mag: 38.68473706887483\n",
      "Iteration 300 lower bound 12741.48259335079; gradient mag: 53.0836878462019\n",
      "Iteration 400 lower bound 12740.908834195212; gradient mag: 70.41640336147029\n",
      "Iteration 500 lower bound 12740.42704604445; gradient mag: 44.35391190282769\n",
      "Iteration 600 lower bound 12739.829821843945; gradient mag: 40.94904310163851\n",
      "Iteration 700 lower bound 12739.224413104517; gradient mag: 61.80345815290504\n",
      "Iteration 800 lower bound 12738.620482154354; gradient mag: 20.393157313092196\n",
      "Iteration 900 lower bound 12738.236635508934; gradient mag: 38.62184494845143\n",
      "Iteration 1000 lower bound 12737.922366567878; gradient mag: 21.995794413501056\n",
      "Iteration 1100 lower bound 12737.679342453508; gradient mag: 73.72140846412928\n",
      "Iteration 1200 lower bound 12737.41494859452; gradient mag: 27.99126584867738\n",
      "Iteration 1300 lower bound 12736.949476930937; gradient mag: 32.477899218430544\n",
      "Iteration 1400 lower bound 12736.093762874596; gradient mag: 36.060277337867156\n",
      "Iteration 1500 lower bound 12735.596402040163; gradient mag: 117.52730685976033\n",
      "Iteration 1600 lower bound 12735.222939253097; gradient mag: 81.99925495759702\n",
      "Iteration 1700 lower bound 12734.909321236542; gradient mag: 44.06467620757653\n",
      "Iteration 1800 lower bound 12734.697559542754; gradient mag: 90.77187683373272\n",
      "Iteration 1900 lower bound 12734.4322423314; gradient mag: 51.157769378795464\n",
      "Iteration 2000 lower bound 12734.203096847765; gradient mag: 47.38598517467246\n",
      "Iteration 2100 lower bound 12733.997344938442; gradient mag: 31.96114504877205\n",
      "Iteration 2200 lower bound 12733.808992649514; gradient mag: 20.976358109603687\n",
      "Iteration 2300 lower bound 12733.637848907061; gradient mag: 61.94835661342279\n",
      "Iteration 2400 lower bound 12733.450962269293; gradient mag: 33.748376646830465\n",
      "Iteration 2500 lower bound 12733.294360790525; gradient mag: 169.7102408001529\n",
      "Iteration 2600 lower bound 12733.109153352181; gradient mag: 21.54680318900394\n",
      "Iteration 2700 lower bound 12732.972710951064; gradient mag: 75.57964458083518\n",
      "Iteration 2800 lower bound 12732.852329682584; gradient mag: 171.79260644699696\n",
      "Iteration 2900 lower bound 12732.724596753196; gradient mag: 164.5996456182612\n",
      "Iteration 3000 lower bound 12732.587226546506; gradient mag: 28.330720913256688\n",
      "Iteration 3100 lower bound 12732.467547865708; gradient mag: 111.51361327311068\n",
      "Iteration 3200 lower bound 12732.322029436673; gradient mag: 39.34761502654247\n",
      "Iteration 3300 lower bound 12732.255895999871; gradient mag: 98.1109310295277\n",
      "Iteration 3400 lower bound 12732.16310708501; gradient mag: 211.72113244353847\n",
      "Iteration 3500 lower bound 12732.04990884305; gradient mag: 21.643473717424637\n",
      "Iteration 3600 lower bound 12731.963804142371; gradient mag: 74.46597451307933\n",
      "Iteration 3700 lower bound 12731.87211624745; gradient mag: 20.29364115588538\n",
      "Iteration 3800 lower bound 12731.789909310575; gradient mag: 24.56988227877554\n",
      "Iteration 3900 lower bound 12731.72621394318; gradient mag: 33.13288004202935\n",
      "Iteration 4000 lower bound 12731.636390438396; gradient mag: 16.318258800054974\n",
      "Iteration 4100 lower bound 12731.57791616327; gradient mag: 194.04161762746648\n",
      "Iteration 4200 lower bound 12731.508780832048; gradient mag: 58.17927502099466\n",
      "Iteration 4300 lower bound 12731.45396156607; gradient mag: 86.89328740836648\n",
      "Iteration 4400 lower bound 12731.393389605706; gradient mag: 86.71651618835284\n",
      "Iteration 4500 lower bound 12731.309628663304; gradient mag: 27.69598339293788\n",
      "Iteration 4600 lower bound 12731.261086905211; gradient mag: 19.985037580857323\n",
      "Iteration 4700 lower bound 12731.207192637878; gradient mag: 62.16352956484647\n",
      "Iteration 4800 lower bound 12731.173129437655; gradient mag: 98.87007856506783\n",
      "Iteration 4900 lower bound 12731.116110926152; gradient mag: 82.05775713621915\n",
      "Iteration 5000 lower bound 12731.049880794808; gradient mag: 16.081298237639157\n",
      "Iteration 5100 lower bound 12731.004346571033; gradient mag: 16.089998009836926\n",
      "Iteration 5200 lower bound 12730.988843937761; gradient mag: 96.41889055384503\n",
      "Iteration 5300 lower bound 12730.924310329472; gradient mag: 64.90767456507362\n",
      "Iteration 5400 lower bound 12729.835743679067; gradient mag: 96.22803631294825\n",
      "Iteration 5500 lower bound 12729.601505591327; gradient mag: 94.47983617866518\n",
      "Iteration 5600 lower bound 12729.483289285252; gradient mag: 36.92910187595118\n",
      "Iteration 5700 lower bound 12729.371889381468; gradient mag: 70.24386836573974\n",
      "Iteration 5800 lower bound 12729.246696029217; gradient mag: 39.77650842466165\n",
      "Iteration 5900 lower bound 12729.156804667193; gradient mag: 72.09140914772274\n",
      "Iteration 6000 lower bound 12729.052949437426; gradient mag: 32.038423097834425\n",
      "Iteration 6100 lower bound 12729.026100115982; gradient mag: 150.4878219573049\n",
      "Iteration 6200 lower bound 12728.896231428975; gradient mag: 162.2678687755842\n",
      "Iteration 6300 lower bound 12728.816751267404; gradient mag: 72.08941540349055\n",
      "Iteration 6400 lower bound 12728.816704560544; gradient mag: 189.27078708594857\n",
      "Iteration 6500 lower bound 12727.504139397908; gradient mag: 127.39158131797466\n",
      "Iteration 6600 lower bound 12726.375938606823; gradient mag: 126.39287107933505\n",
      "Iteration 6700 lower bound 12725.765988666364; gradient mag: 144.4602573424953\n",
      "Iteration 6800 lower bound 12725.24976107941; gradient mag: 182.03944785752324\n",
      "Iteration 6900 lower bound 12724.741562154179; gradient mag: 135.13023522589916\n",
      "Iteration 7000 lower bound 12724.363641572447; gradient mag: 66.85503979827945\n",
      "Iteration 7100 lower bound 12724.137480335317; gradient mag: 165.53306623154236\n",
      "Iteration 7200 lower bound 12723.70909036313; gradient mag: 141.23628413379748\n",
      "Iteration 7300 lower bound 12723.421571520901; gradient mag: 207.7459726295334\n",
      "Iteration 7400 lower bound 12723.123502786244; gradient mag: 142.01089482266835\n",
      "Iteration 7500 lower bound 12722.828727289372; gradient mag: 77.40635556390554\n",
      "Iteration 7600 lower bound 12722.617976625086; gradient mag: 131.54654934403646\n",
      "Iteration 7700 lower bound 12722.423783363345; gradient mag: 98.06274476060729\n",
      "Iteration 7800 lower bound 12722.019756996875; gradient mag: 212.90747333110187\n",
      "Iteration 7900 lower bound 12721.113422371596; gradient mag: 151.19543402316114\n",
      "Iteration 8000 lower bound 12720.835946185405; gradient mag: 154.87252948697667\n",
      "Iteration 8100 lower bound 12720.732373344623; gradient mag: 152.06886691281096\n",
      "Iteration 8200 lower bound 12720.526301188676; gradient mag: 202.0470867955817\n",
      "Iteration 8300 lower bound 12719.630642251755; gradient mag: 208.51679198269275\n",
      "Iteration 8400 lower bound 12719.181854150735; gradient mag: 210.6205523920443\n",
      "Iteration 8500 lower bound 12718.991480049383; gradient mag: 155.98859246645517\n",
      "Iteration 8600 lower bound 12718.731064767322; gradient mag: 188.16757219159805\n",
      "Iteration 8700 lower bound 12718.25768855353; gradient mag: 195.90120114767865\n",
      "Iteration 8800 lower bound 12715.981840307879; gradient mag: 294.2762527480632\n",
      "Iteration 8900 lower bound 12715.667924582121; gradient mag: 304.8809414563027\n",
      "Iteration 9000 lower bound 12715.302431612825; gradient mag: 284.41796168909485\n",
      "Iteration 9100 lower bound 12715.115633406143; gradient mag: 170.60379081177123\n",
      "Iteration 9200 lower bound 12714.92217930708; gradient mag: 138.0549676621772\n",
      "Iteration 9300 lower bound 12714.840897600301; gradient mag: 132.46827822598388\n",
      "Iteration 9400 lower bound 12714.664323968947; gradient mag: 159.28562222407913\n",
      "Iteration 9500 lower bound 12714.642093776474; gradient mag: 105.82720832915089\n",
      "Iteration 9600 lower bound 12714.594115557196; gradient mag: 340.0472469027615\n",
      "Iteration 9700 lower bound 12714.384310078927; gradient mag: 113.15797175306417\n",
      "Iteration 9800 lower bound 12714.39650757756; gradient mag: 355.9563930020444\n",
      "Iteration 9900 lower bound 12714.27402871984; gradient mag: 116.94156368843962\n",
      "Iteration 10000 lower bound 12714.219576623065; gradient mag: 180.05379235432852\n",
      "Iteration 10100 lower bound 12714.13406179847; gradient mag: 359.06398215062205\n",
      "Iteration 10200 lower bound 12714.10940221733; gradient mag: 174.68271270009456\n",
      "Iteration 10300 lower bound 12714.054303613353; gradient mag: 109.77764212984931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10400 lower bound 12713.951004943803; gradient mag: 178.2388980947958\n",
      "Iteration 10500 lower bound 12714.021127554563; gradient mag: 368.85121010803067\n",
      "Iteration 10600 lower bound 12713.87198049348; gradient mag: 122.12080818594332\n",
      "Iteration 10700 lower bound 12713.912070108434; gradient mag: 427.89727133396315\n",
      "Iteration 10800 lower bound 12713.766301149528; gradient mag: 414.24627035795527\n",
      "Iteration 10900 lower bound 12713.727386543998; gradient mag: 98.0826963698317\n",
      "Iteration 11000 lower bound 12713.803471347766; gradient mag: 126.62774789584302\n",
      "Iteration 11100 lower bound 12713.56837256366; gradient mag: 108.87271808112293\n",
      "Iteration 11200 lower bound 12713.588519522702; gradient mag: 413.24869120533\n",
      "Iteration 11300 lower bound 12713.50832277852; gradient mag: 150.45586262100244\n",
      "Iteration 11400 lower bound 12713.512358205875; gradient mag: 135.48159415155067\n",
      "Iteration 11500 lower bound 12713.474793515237; gradient mag: 141.98064124444707\n",
      "Iteration 11600 lower bound 12713.600862572075; gradient mag: 140.61465850218025\n",
      "Iteration 11700 lower bound 12713.344045996977; gradient mag: 446.91733375461973\n",
      "Iteration 11800 lower bound 12713.3846018605; gradient mag: 192.3370710771347\n",
      "Iteration 11900 lower bound 12713.282679578671; gradient mag: 186.654647847982\n",
      "Iteration 12000 lower bound 12713.2010807955; gradient mag: 86.6078794872676\n",
      "Iteration 12100 lower bound 12713.225138233627; gradient mag: 120.60619454163658\n",
      "Iteration 12200 lower bound 12713.192763392824; gradient mag: 156.5905987620145\n",
      "Iteration 12300 lower bound 12713.147013260503; gradient mag: 92.0720659941652\n",
      "Iteration 12400 lower bound 12713.120649902132; gradient mag: 79.14749129484458\n",
      "Iteration 12500 lower bound 12713.058946196534; gradient mag: 223.1424599833348\n",
      "Iteration 12600 lower bound 12713.124179218623; gradient mag: 122.884163564391\n",
      "Iteration 12700 lower bound 12713.029997097537; gradient mag: 102.62332293972905\n",
      "Iteration 12800 lower bound 12713.133258463035; gradient mag: 99.63598882454545\n",
      "Iteration 12900 lower bound 12713.055079973701; gradient mag: 132.05696479259885\n",
      "Iteration 13000 lower bound 12713.048060010564; gradient mag: 96.58056475517239\n",
      "Iteration 13100 lower bound 12712.95745700891; gradient mag: 100.87351104331435\n",
      "Iteration 13200 lower bound 12712.887431292364; gradient mag: 69.2523249960793\n",
      "Iteration 13300 lower bound 12712.875802712259; gradient mag: 86.10993313175197\n",
      "Iteration 13400 lower bound 12712.844702319351; gradient mag: 80.47396546766872\n",
      "Iteration 13500 lower bound 12712.865970081748; gradient mag: 86.06570037891238\n",
      "Iteration 13600 lower bound 12712.794807958682; gradient mag: 68.90303868303218\n",
      "Iteration 13700 lower bound 12712.743278462314; gradient mag: 64.46632909325407\n",
      "Iteration 13800 lower bound 12712.75178611229; gradient mag: 79.65774340897205\n",
      "Iteration 13900 lower bound 12712.720379333889; gradient mag: 85.9683489950802\n",
      "Iteration 14000 lower bound 12712.766833802565; gradient mag: 84.53349449534122\n",
      "Iteration 14100 lower bound 12712.715882121913; gradient mag: 86.80028722920731\n",
      "Iteration 14200 lower bound 12712.706577884204; gradient mag: 83.42134274114362\n",
      "Iteration 14300 lower bound 12712.676438876035; gradient mag: 81.77962687483772\n",
      "Iteration 14400 lower bound 12712.625811674663; gradient mag: 78.69371780811002\n",
      "Iteration 14500 lower bound 12712.640858293355; gradient mag: 87.83039848675624\n",
      "Iteration 14600 lower bound 12712.560124942876; gradient mag: 104.77453836187719\n",
      "Iteration 14700 lower bound 12712.559284123974; gradient mag: 110.4611467244817\n",
      "Iteration 14800 lower bound 12712.506069795656; gradient mag: 80.7765876770228\n",
      "Iteration 14900 lower bound 12712.557606308237; gradient mag: 114.51217537648148\n"
     ]
    }
   ],
   "source": [
    "###define design choices in gradient descent\n",
    "params = {'step_size':1e-3, \n",
    "          'max_iteration':15000, \n",
    "          'random_restarts':1}\n",
    "\n",
    "#fit my neural network to minimize MSE on the given data\n",
    "#nlm.fit_MLE(x.T, y.reshape(1,-1), params)\n",
    "nlm.fit_MLE(x.T, y.reshape(3,-1), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.83544809e-42, 8.83199202e-16, 1.71965044e-10, 4.54158409e-16,\n",
       "       1.00380719e-46, 1.24746415e-51, 2.11028461e-65, 2.72093556e-48,\n",
       "       1.37467072e-12, 6.15690059e-05, 2.64806687e-26, 1.12287625e-13,\n",
       "       9.83015125e-27, 2.63491273e-43, 5.53678901e-24, 2.96955615e-17,\n",
       "       7.21997766e-09, 2.97425415e-14, 5.28135615e-04, 2.08210283e-06,\n",
       "       5.55447325e-14, 8.64994780e-20, 9.13665316e-04, 3.33177704e-15,\n",
       "       6.52536253e-19, 1.24326667e-32, 6.16161806e-42, 4.75732440e-26,\n",
       "       7.12127523e-29, 7.40925895e-25, 1.30057587e-47, 1.96722559e-70,\n",
       "       1.86777906e-12, 3.53016140e-05, 9.45229425e-27, 2.93325956e-10,\n",
       "       3.45192098e-13, 2.02090843e-26, 4.59656478e-27, 3.47049794e-16,\n",
       "       8.56725883e-07, 1.06183737e-18, 2.39249818e-27, 1.91773849e-17,\n",
       "       1.82627055e-26, 6.78112693e-24, 1.79293897e-26, 6.58044384e-26,\n",
       "       2.33722821e-55, 9.86670155e-22, 2.29976450e-16, 1.10117653e-47,\n",
       "       4.78972975e-09, 6.71921874e-16, 1.90884422e-06, 2.57544317e-29,\n",
       "       2.92214967e-62, 2.75427279e-27, 1.01540465e-34, 1.32049171e-38,\n",
       "       2.86204868e-05, 7.01761573e-23, 1.25208703e-04, 1.50669542e-16,\n",
       "       1.20976273e-10, 3.37232961e-51, 2.41590623e-54, 3.38546052e-23,\n",
       "       2.31183567e-20, 9.01572860e-22, 4.69108705e-16, 6.70952112e-04,\n",
       "       6.84358301e-04, 3.47336553e-25, 1.49446995e-11, 2.84426608e-11,\n",
       "       5.70882058e-06, 5.89576967e-05, 3.38823852e-35, 3.25679682e-10,\n",
       "       1.34497832e-46, 1.50961773e-13, 8.02176805e-07, 3.18292377e-42,\n",
       "       2.11480196e-60, 4.37956140e-39, 4.04981480e-18, 9.10605748e-38,\n",
       "       1.36184130e-35, 3.23782537e-07, 1.62603442e-36, 1.20282366e-31,\n",
       "       1.11756459e-34, 1.47333418e-38, 2.24252874e-10, 9.36856072e-34,\n",
       "       2.51258577e-33, 1.34817557e-36, 1.97365963e-18, 9.94317013e-26,\n",
       "       1.13674118e-27, 6.35418595e-16, 1.26326395e-38, 4.98990696e-47,\n",
       "       1.21749107e-43, 2.24665110e-42, 2.03986276e-36, 3.11355415e-23,\n",
       "       1.07044895e-14, 2.63630091e-47, 1.81722690e-36, 3.90027687e-35,\n",
       "       7.11150366e-17, 5.08156073e-53, 8.83731069e-40, 5.74321236e-04,\n",
       "       9.58462998e-08, 1.08445762e-16, 2.68315886e-54, 3.53093375e-77,\n",
       "       6.57231258e-30, 6.50082084e-16, 3.19472205e-44, 6.56531142e-09,\n",
       "       4.63422704e-29, 1.51956690e-24, 1.36351083e-06, 2.18998835e-40,\n",
       "       2.26836412e-25, 5.41684616e-26, 7.04857467e-36, 5.32740037e-08,\n",
       "       1.26470599e-19, 7.74305393e-59, 5.62903960e-20, 8.72071894e-11,\n",
       "       7.01949113e-06, 7.28997122e-21, 7.00875619e-08, 1.21009133e-04,\n",
       "       8.31693262e-30, 3.94049317e-11, 2.71136083e-43, 8.36506710e-07,\n",
       "       7.93893675e-29, 1.43436119e-05, 3.16841043e-29, 1.42088409e-35,\n",
       "       1.05988185e-48, 6.02404168e-04, 1.24569948e-06, 1.38820960e-07,\n",
       "       1.06061968e-12, 1.54095151e-26, 5.02694991e-36, 1.85509394e-45,\n",
       "       1.15098195e-20, 1.23336749e-43, 4.29919144e-05, 4.14901467e-04,\n",
       "       2.66144227e-29, 4.38317699e-20, 1.48180677e-38, 2.76009425e-05,\n",
       "       2.13819517e-47, 9.51711933e-54, 4.63214205e-24, 1.15056688e-27,\n",
       "       2.44536687e-50, 9.57594855e-04, 8.59321046e-13, 3.84490442e-23,\n",
       "       7.94098403e-30, 2.76908387e-28, 3.29291027e-05, 3.52147571e-09,\n",
       "       4.48348309e-49, 8.23705273e-60, 1.88339988e-51, 2.64510436e-36,\n",
       "       7.07687575e-43, 5.20004700e-18, 5.68260235e-04, 1.48098180e-29,\n",
       "       5.12067950e-49, 1.61445043e-24, 1.96298662e-27, 1.05440264e-05,\n",
       "       5.41675671e-26, 2.31156418e-46, 7.35698477e-13, 2.95808466e-25,\n",
       "       1.04176722e-57, 3.31754201e-13, 1.83104084e-30, 1.85557207e-38,\n",
       "       6.76163287e-33, 2.45115959e-38, 3.70095299e-55, 1.09503524e-05,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 6.12674914e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 1.01918472e-03, 1.00969687e-03,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 1.02363056e-03, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 7.02878283e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 8.80719112e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 1.04550624e-03,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       5.55277458e-04, 5.55277458e-04, 5.55277458e-04, 5.55277458e-04,\n",
       "       1.10438235e-03, 9.70650821e-04, 1.11288536e-03, 1.12245736e-03,\n",
       "       1.10084342e-03, 1.08880949e-03, 9.01824321e-04, 1.10577469e-03,\n",
       "       1.11799521e-03, 1.10857956e-03, 1.10732732e-03, 1.12460613e-03,\n",
       "       1.11372777e-03, 1.10623234e-03, 1.12777868e-03, 1.11015851e-03,\n",
       "       1.04812710e-03, 1.00679294e-03, 1.12282926e-03, 8.74429633e-04,\n",
       "       1.13288095e-03, 1.10545501e-03, 1.11002874e-03, 1.11231483e-03,\n",
       "       1.09928804e-03, 1.12692564e-03, 1.10554349e-03, 1.02103286e-03,\n",
       "       1.11243576e-03, 1.11194546e-03, 1.11197180e-03, 1.11257338e-03,\n",
       "       6.11183995e-04, 1.11574990e-03, 1.11210654e-03, 1.13075496e-03,\n",
       "       1.05468019e-03, 1.10996750e-03, 1.12446667e-03, 1.12692250e-03,\n",
       "       1.07711266e-03, 9.91220020e-04, 1.10368119e-03, 1.12100711e-03,\n",
       "       1.11657539e-03, 1.03846726e-03, 1.12148333e-03, 1.10961767e-03,\n",
       "       1.10803880e-03, 1.03325557e-03, 1.11927119e-03, 1.13678955e-03,\n",
       "       1.13574141e-03, 8.92613483e-04, 5.21539478e-04, 1.10531320e-03,\n",
       "       1.11277674e-03, 1.13269772e-03, 1.10414855e-03, 1.10578891e-03,\n",
       "       1.11381473e-03, 1.11319173e-03, 1.09457296e-03, 1.10692223e-03,\n",
       "       1.00474741e-03, 1.09980287e-03, 1.09905108e-03, 1.09097825e-03,\n",
       "       1.01528747e-03, 1.10688125e-03, 1.21955473e-03, 9.46403548e-04,\n",
       "       1.09616004e-03, 1.11499676e-03, 1.11012479e-03, 1.00860524e-03,\n",
       "       1.10865281e-03, 1.13756667e-03, 1.11352729e-03, 1.11048257e-03,\n",
       "       1.10028387e-03, 1.11067742e-03, 1.01022024e-03, 1.10960545e-03,\n",
       "       1.10515167e-03, 8.91608365e-04, 1.10618500e-03, 1.10874045e-03,\n",
       "       1.10832596e-03, 1.06783730e-03, 1.05673928e-03, 1.12908188e-03,\n",
       "       1.11719357e-03, 1.10922231e-03, 1.12145313e-03, 1.10635785e-03,\n",
       "       1.11125774e-03, 1.06067167e-03, 1.11822633e-03, 1.10165077e-03,\n",
       "       1.10353226e-03, 1.14078981e-03, 1.10078262e-03, 1.10668509e-03,\n",
       "       1.09774630e-03, 1.10119116e-03, 1.10803075e-03, 1.10072016e-03,\n",
       "       1.10449624e-03, 1.00944875e-03, 9.53249302e-04, 9.67292598e-04,\n",
       "       1.11985340e-03, 1.12847252e-03, 1.10865841e-03, 1.03052199e-03,\n",
       "       1.11595835e-03, 1.10666497e-03, 1.10861507e-03, 9.07979100e-04,\n",
       "       1.10560618e-03, 1.10561030e-03, 1.09922223e-03, 1.11419309e-03,\n",
       "       1.03024828e-03, 1.10886359e-03, 1.12406225e-03, 1.04279273e-03,\n",
       "       1.09165484e-03, 1.05570195e-03, 1.10696897e-03, 1.01187472e-03,\n",
       "       1.10559575e-03, 1.06542267e-03, 1.09624204e-03, 2.14701951e-04,\n",
       "       1.09861457e-03, 1.04507455e-03, 5.06244630e-04, 5.76639260e-04,\n",
       "       1.10857287e-03, 1.09724705e-03, 1.11052836e-03, 1.11713821e-03,\n",
       "       1.11403196e-03, 1.08273766e-03, 1.11071295e-03, 1.10561003e-03,\n",
       "       1.33445436e-03, 1.11509941e-03, 8.84150031e-04, 1.10142993e-03,\n",
       "       1.07138971e-03, 1.10766323e-03, 1.09861209e-03, 1.11369356e-03,\n",
       "       1.11491609e-03, 7.95567719e-04, 1.10964248e-03, 6.21449524e-04,\n",
       "       1.10267203e-03, 1.10462412e-03, 1.11584732e-03, 1.05460100e-03,\n",
       "       1.01710843e-03, 1.09821135e-03, 1.12716644e-03, 8.33548674e-04,\n",
       "       1.11369810e-03, 9.72358121e-04, 1.10450577e-03, 1.09946074e-03,\n",
       "       1.01637488e-03, 1.11841113e-03, 1.12382596e-03, 1.11206204e-03,\n",
       "       1.10458134e-03, 1.10731971e-03, 1.11747146e-03, 1.03525390e-03,\n",
       "       1.11280045e-03, 1.11631363e-03, 8.48063018e-04, 6.63958559e-04,\n",
       "       1.11077939e-03, 1.10918065e-03, 1.26813490e-03, 1.13239438e-03,\n",
       "       1.11432310e-03, 1.09723325e-03, 1.03602287e-03, 1.10531786e-03,\n",
       "       1.02871580e-03, 1.06651734e-03, 1.11965326e-03, 1.11713929e-03,\n",
       "       1.09931506e-03, 1.10812099e-03, 1.11020853e-03, 1.10429846e-03])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_hmc={\n",
    "       'num_samples':2000,\n",
    "       'step_size':1e-2, \n",
    "       'L':20,\n",
    "       'init': nlm.weights,\n",
    "       'burn':.1, \n",
    "       'thin':2,}\n",
    "\n",
    "nlm.forward(nlm.weights, x.T)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 63)\n",
      "[[[ 8.13247077  1.629539    3.44835104 ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  1.4144595   1.51391366\n",
      "    1.2719105 ]\n",
      "  [14.25172137 10.80294046 11.16547419 ...  1.77435123  1.36291273\n",
      "    2.22798707]]] (1, 5, 600)\n",
      "[[ 2.43504153  0.90469757  2.09587105 ... -0.38379057 -0.25698593\n",
      "  -1.10258657]\n",
      " [ 2.58546245  2.27212216  1.28687207 ... -0.25224376 -0.50370283\n",
      "   0.51680035]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (1,63) and (1,5,600) not aligned: 63 (dim 1) != 5 (dim 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b5dd9002dc73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_NLM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhmc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams_hmc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/Fall/Experiments/Neural_Network.py\u001b[0m in \u001b[0;36mfit_NLM\u001b[0;34m(self, x_train, y_train, hmc, params_hmc)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mlog_prior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_log_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prior_distribution'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prior_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mlog_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'likelihood_distribution'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'likelihood_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhmc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_likelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams_hmc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/Fall/Experiments/Hamiltonian_MC.py\u001b[0m in \u001b[0;36mhmc\u001b[0;34m(log_prior, log_likelihood, num_samples, step_size, L, init, burn, thin)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m# half-step update for momentum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mp_step_t_half\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_proposal\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep_size\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad_U\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_proposal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0;31m# full step update for position\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mq_proposal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mstep_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp_step_t_half\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/autograd/wrap_util.py\u001b[0m in \u001b[0;36mnary_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0munary_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munary_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnary_op_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnary_op_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnary_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnary_operator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/autograd/differential_operators.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0marguments\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbut\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0minstead\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     should be scalar-valued. The gradient has the same type as the argument.\"\"\"\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         raise TypeError(\"Grad only applies to real scalar-output functions. \"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/autograd/core.py\u001b[0m in \u001b[0;36mmake_vjp\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstart_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVJPNode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mend_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_node\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mend_node\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(start_node, fun, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mstart_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mend_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_box\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_box\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstart_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/autograd/wrap_util.py\u001b[0m in \u001b[0;36munary_f\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0msubargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubvals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msubargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/Fall/Experiments/Hamiltonian_MC.py\u001b[0m in \u001b[0;36mU\u001b[0;34m(W)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \"\"\"\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlog_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlog_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/Fall/Experiments/Bayesian_pdf.py\u001b[0m in \u001b[0;36mlog_logistic\u001b[0;34m(W)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmapped_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mdot_product\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapped_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_product\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1e-15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mf_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mparents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mboxed_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0margnums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m   \u001b[0;32min\u001b[0m \u001b[0mboxed_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_wrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mf_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_autograd_primitive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (1,63) and (1,5,600) not aligned: 63 (dim 1) != 5 (dim 1)"
     ]
    }
   ],
   "source": [
    "print(nlm.weights.shape)\n",
    "nlm.fit_NLM(x.T, y.reshape(1,-1),hmc,params_hmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
